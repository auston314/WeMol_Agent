{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d1912d-ddd6-483b-8df7-81a377625a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your own Mistral API key here\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"NX1TKuFMtLERziU9xYXGM0cu202ZaXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fa0e2fb-7ad4-4a0b-bc5d-9ae90b8fe38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting entire PDF ---\n",
      "Starting PDF processing for: 'sample.pdf'...\n",
      "start doc processing\n",
      "An unexpected error occurred: 6 validation errors for Unmarshaller\n",
      "body.FileChunk.file_id\n",
      "  Field required [type=missing, input_value={'type': 'document_file',...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.FileChunk.type\n",
      "  Input should be 'file' [type=literal_error, input_value='document_file', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n",
      "body.ImageURLChunk.image_url\n",
      "  Field required [type=missing, input_value={'type': 'document_file',...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.ImageURLChunk.type\n",
      "  Input should be 'image_url' [type=literal_error, input_value='document_file', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n",
      "body.DocumentURLChunk.document_url\n",
      "  Field required [type=missing, input_value={'type': 'document_file',...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.DocumentURLChunk.type\n",
      "  Input should be 'document_url' [type=literal_error, input_value='document_file', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from mistralai import Mistral\n",
    "\n",
    "def pdf_to_markdown(\n",
    "    pdf_path: str,\n",
    "    output_markdown_path: str,\n",
    "    image_folder_name: str = \"images\",\n",
    "    start_page: int = None,  # New parameter: starting page for conversion (inclusive)\n",
    "    end_page: int = None     # New parameter: ending page for conversion (inclusive)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to Markdown using Mistral OCR, saving extracted images locally.\n",
    "    Markdown image links will be updated to reference these local image files.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the input PDF file.\n",
    "        output_markdown_path (str): The path where the output Markdown file will be saved.\n",
    "        image_folder_name (str): The name of the folder to save extracted images.\n",
    "                                  This folder will be created relative to the script's execution directory.\n",
    "        start_page (int, optional): The starting page number for OCR processing (1-indexed).\n",
    "                                    If None, processing starts from the first page.\n",
    "        end_page (int, optional): The ending page number for OCR processing (1-indexed).\n",
    "                                  If None, processing goes to the last page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the Mistral API key from environment variables\n",
    "        api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"Error: MISTRAL_API_KEY environment variable not set. Please set it before running.\")\n",
    "            return\n",
    "\n",
    "        # Initialize the Mistral client\n",
    "        client = Mistral(api_key=api_key)\n",
    "\n",
    "        print(f\"Starting PDF processing for: '{pdf_path}'...\")\n",
    "        if start_page is not None and end_page is not None:\n",
    "            print(f\"Processing pages from {start_page} to {end_page}...\")\n",
    "        elif start_page is not None:\n",
    "            print(f\"Processing from page {start_page} to the end...\")\n",
    "        elif end_page is not None:\n",
    "            print(f\"Processing from the beginning to page {end_page}...\")\n",
    "\n",
    "\n",
    "        # Open the PDF file in binary read mode\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            # Prepare document parameters, including page range if specified\n",
    "            print(\"start doc processing\")\n",
    "            document_params = {\n",
    "                \"type\": \"document_file\",\n",
    "                \"document_file\": f  # Pass the file object directly\n",
    "            }\n",
    "            if start_page is not None:\n",
    "                document_params[\"start_page\"] = start_page\n",
    "            if end_page is not None:\n",
    "                document_params[\"end_page\"] = end_page\n",
    "\n",
    "            # Call the Mistral OCR API to process the document\n",
    "            # 'document_file' type is used for local file uploads\n",
    "            # 'include_image_base64=True' ensures image data is returned\n",
    "            ocr_response = client.ocr.process(\n",
    "                model=\"mistral-ocr-latest\",\n",
    "                document=document_params, # Use the updated document_params\n",
    "                include_image_base64=True\n",
    "            )\n",
    "\n",
    "            print(\"After API call\")\n",
    "\n",
    "        if not ocr_response:\n",
    "            print(\"Error: No response received from Mistral OCR. The API call might have failed or returned empty.\")\n",
    "            return\n",
    "\n",
    "        # Extract markdown content and image data from the OCR response\n",
    "        markdown_content = ocr_response.markdown\n",
    "        extracted_images = ocr_response.images\n",
    "\n",
    "        # Create the directory for saving images if it doesn't exist\n",
    "        if not os.path.exists(image_folder_name):\n",
    "            os.makedirs(image_folder_name)\n",
    "            print(f\"Created image folder: '{image_folder_name}'\")\n",
    "\n",
    "        # Dictionary to map Mistral image IDs to their new local filenames\n",
    "        image_id_to_filename = {}\n",
    "\n",
    "        # Process and save extracted images\n",
    "        if extracted_images:\n",
    "            print(f\"Found {len(extracted_images)} images. Saving them to '{image_folder_name}'...\")\n",
    "            for img_data in extracted_images:\n",
    "                image_id = img_data.id\n",
    "                image_base64 = img_data.image_base64\n",
    "\n",
    "                if image_base64:\n",
    "                    try:\n",
    "                        # Construct a filename for the image (assuming PNG format)\n",
    "                        image_filename = f\"{image_id}.png\"\n",
    "                        image_full_path = os.path.join(image_folder_name, image_filename)\n",
    "                        \n",
    "\n",
    "                        # Decode the base64 image data and write it to a file\n",
    "                        with open(image_full_path, \"wb\") as img_file:\n",
    "                            img_file.write(base64.b64decode(image_base64))\n",
    "\n",
    "                        # Store the mapping for later markdown modification\n",
    "                        image_id_to_filename[image_id] = image_filename\n",
    "                        print(f\"Saved image: '{image_full_path}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving image '{image_id}': {e}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Image '{image_id}' has no base64 data and could not be saved.\")\n",
    "        else:\n",
    "            print(\"No images were extracted from the PDF.\")\n",
    "\n",
    "        # Modify markdown content to reference local image paths\n",
    "        if markdown_content:\n",
    "            print(\"Adjusting image references in markdown content...\")\n",
    "            for image_id, filename in image_id_to_filename.items():\n",
    "                # Regular expression to find Markdown image links like `![alt text](image_id)`\n",
    "                # `re.escape(image_id)` is used to handle special characters in image_id if any.\n",
    "                # `(.*?)` captures the alt text (non-greedy).\n",
    "                # `\\\\1` in the replacement refers to the captured alt text.\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[(.*?)\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'![\\\\1]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "                # Also handle cases where there might be no alt text, e.g., `![]({image_id})`\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'[]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "\n",
    "            # Save the modified markdown content to the specified output file\n",
    "            with open(output_markdown_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown_content)\n",
    "            print(f\"Markdown content saved to: '{output_markdown_path}'\")\n",
    "        else:\n",
    "            print(\"No markdown content was extracted from the PDF.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The PDF file '{pdf_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        # For more detailed debugging, uncomment the following lines:\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT:\n",
    "    # 1. Install the Mistral AI library: pip install mistralai\n",
    "    # 2. Set your Mistral API key as an environment variable named MISTRAL_API_KEY.\n",
    "    #    - On Linux/macOS: export MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On Windows (Command Prompt): set MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On Windows (PowerShell): $env:MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    # 3. Replace 'path/to/your/document.pdf' with the actual path to your PDF file.\n",
    "    #    You can download a sample PDF, for example, from an arXiv paper:\n",
    "    #    https://arxiv.org/pdf/2201.04234.pdf (save it locally as 'sample.pdf')\n",
    "\n",
    "    # Define your input and output paths\n",
    "    input_pdf_file = \"sample.pdf\"  # Replace with your PDF file path\n",
    "    output_md_file = \"output.md\"\n",
    "    output_image_folder = \"images\" # Folder where images will be saved\n",
    "\n",
    "    # Example 1: Convert the entire PDF\n",
    "    print(\"--- Converting entire PDF ---\")\n",
    "    pdf_to_markdown(input_pdf_file, output_md_file, output_image_folder)\n",
    "\n",
    "    # # Example 2: Convert a specific page range (e.g., pages 1 to 3)\n",
    "    # print(\"\\n--- Converting pages 1 to 3 ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_pages_1_3.md\", output_image_folder, start_page=1, end_page=3)\n",
    "\n",
    "    # # Example 3: Convert from a specific page to the end (e.g., from page 2 onwards)\n",
    "    # print(\"\\n--- Converting from page 2 to end ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_from_page_2.md\", output_image_folder, start_page=2)\n",
    "\n",
    "    # # Example 4: Convert up to a specific page (e.g., up to page 5)\n",
    "    # print(\"\\n--- Converting up to page 5 ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_up_to_page_5.md\", output_image_folder, end_page=5)\n",
    "\n",
    "    # print(\"\\nProcess completed. Check the generated markdown files and image folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d48e113e-5189-49ba-a4da-063422792c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting entire PDF ---\n",
      "Starting PDF processing for: 'sample.pdf'...\n",
      "An unexpected error occurred: Ocr.process() got an unexpected keyword argument 'document_file'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from mistralai import Mistral\n",
    "\n",
    "def pdf_to_markdown(\n",
    "    pdf_path: str,\n",
    "    output_markdown_path: str,\n",
    "    image_folder_name: str = \"images\",\n",
    "    start_page: int = None,  # New parameter: starting page for conversion (inclusive)\n",
    "    end_page: int = None     # New parameter: ending page for conversion (inclusive)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to Markdown using Mistral OCR, saving extracted images locally.\n",
    "    Markdown image links will be updated to reference these local image files.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the input PDF file.\n",
    "        output_markdown_path (str): The path where the output Markdown file will be saved.\n",
    "        image_folder_name (str): The name of the folder to save extracted images.\n",
    "                                  This folder will be created relative to the script's execution directory.\n",
    "        start_page (int, optional): The starting page number for OCR processing (1-indexed).\n",
    "                                    If None, processing starts from the first page.\n",
    "        end_page (int, optional): The ending page number for OCR processing (1-indexed).\n",
    "                                  If None, processing goes to the last page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the Mistral API key from environment variables\n",
    "        api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"Error: MISTRAL_API_KEY environment variable not set. Please set it before running.\")\n",
    "            return\n",
    "\n",
    "        # Initialize the Mistral client\n",
    "        client = Mistral(api_key=api_key)\n",
    "\n",
    "        print(f\"Starting PDF processing for: '{pdf_path}'...\")\n",
    "        if start_page is not None and end_page is not None:\n",
    "            print(f\"Processing pages from {start_page} to {end_page}...\")\n",
    "        elif start_page is not None:\n",
    "            print(f\"Processing from page {start_page} to the end...\")\n",
    "        elif end_page is not None:\n",
    "            print(f\"Processing from the beginning to page {end_page}...\")\n",
    "\n",
    "\n",
    "        # Open the PDF file in binary read mode\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            # Call the Mistral OCR API to process the document\n",
    "            # When uploading a local file, use 'document_file' keyword argument directly.\n",
    "            # 'start_page' and 'end_page' are also passed as direct keyword arguments.\n",
    "            ocr_response = client.ocr.process(\n",
    "                model=\"mistral-ocr-latest\",\n",
    "                document_file=f, # Pass the file object directly here\n",
    "                start_page=start_page, # Pass start_page directly\n",
    "                end_page=end_page,     # Pass end_page directly\n",
    "                include_image_base64=True\n",
    "            )\n",
    "\n",
    "        if not ocr_response:\n",
    "            print(\"Error: No response received from Mistral OCR. The API call might have failed or returned empty.\")\n",
    "            return\n",
    "\n",
    "        # Extract markdown content and image data from the OCR response\n",
    "        markdown_content = ocr_response.markdown\n",
    "        extracted_images = ocr_response.images\n",
    "\n",
    "        # Create the directory for saving images if it doesn't exist\n",
    "        if not os.path.exists(image_folder_name):\n",
    "            os.makedirs(image_folder_name)\n",
    "            print(f\"Created image folder: '{image_folder_name}'\")\n",
    "\n",
    "        # Dictionary to map Mistral image IDs to their new local filenames\n",
    "        image_id_to_filename = {}\n",
    "\n",
    "        # Process and save extracted images\n",
    "        if extracted_images:\n",
    "            print(f\"Found {len(extracted_images)} images. Saving them to '{image_folder_name}'...\")\n",
    "            for img_data in extracted_images:\n",
    "                image_id = img_data.id\n",
    "                image_base64 = img_data.image_base64\n",
    "\n",
    "                if image_base64:\n",
    "                    try:\n",
    "                        # Construct a filename for the image (assuming PNG format)\n",
    "                        image_filename = f\"{image_id}.png\"\n",
    "                        image_full_path = os.path.join(image_folder_name, image_filename)\n",
    "\n",
    "                        # Decode the base64 image data and write it to a file\n",
    "                        with open(image_full_path, \"wb\") as img_file:\n",
    "                            img_file.write(base64.b64decode(image_base64))\n",
    "\n",
    "                        # Store the mapping for later markdown modification\n",
    "                        image_id_to_filename[image_id] = image_filename\n",
    "                        print(f\"Saved image: '{image_full_path}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving image '{image_id}': {e}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Image '{image_id}' has no base64 data and could not be saved.\")\n",
    "        else:\n",
    "            print(\"No images were extracted from the PDF.\")\n",
    "\n",
    "        # Modify markdown content to reference local image paths\n",
    "        if markdown_content:\n",
    "            print(\"Adjusting image references in markdown content...\")\n",
    "            for image_id, filename in image_id_to_filename.items():\n",
    "                # Regular expression to find Markdown image links like `![alt text](image_id)`\n",
    "                # `re.escape(image_id)` is used to handle special characters in image_id if any.\n",
    "                # `(.*?)` captures the alt text (non-greedy).\n",
    "                # `\\\\1` in the replacement refers to the captured alt text.\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[(.*?)\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'![\\\\1]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "                # Also handle cases where there might be no alt text, e.g., `![]({image_id})`\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'[]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "\n",
    "            # Save the modified markdown content to the specified output file\n",
    "            with open(output_markdown_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown_content)\n",
    "            print(f\"Markdown content saved to: '{output_markdown_path}'\")\n",
    "        else:\n",
    "            print(\"No markdown content was extracted from the PDF.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The PDF file '{pdf_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        # For more detailed debugging, uncomment the following lines:\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT:\n",
    "    # 1. Install the Mistral AI library: pip install mistralai\n",
    "    # 2. Set your Mistral API key as an environment variable named MISTRAL_API_KEY.\n",
    "    #    - On Linux/macOS: export MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On Windows (Command Prompt): set MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On Windows (PowerShell): $env:MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    # 3. Replace 'path/to/your/document.pdf' with the actual path to your PDF file.\n",
    "    #    You can download a sample PDF, for example, from an arXiv paper:\n",
    "    #    https://arxiv.org/pdf/2201.04234.pdf (save it locally as 'sample.pdf')\n",
    "\n",
    "    # Define your input and output paths\n",
    "    input_pdf_file = \"sample.pdf\"  # Replace with your PDF file path\n",
    "    output_md_file = \"output.md\"\n",
    "    output_image_folder = \"extracted_images\" # Folder where images will be saved\n",
    "\n",
    "    # Example 1: Convert the entire PDF\n",
    "    print(\"--- Converting entire PDF ---\")\n",
    "    pdf_to_markdown(input_pdf_file, output_md_file, output_image_folder)\n",
    "\n",
    "    # # Example 2: Convert a specific page range (e.g., pages 1 to 3)\n",
    "    # print(\"\\n--- Converting pages 1 to 3 ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_pages_1_3.md\", output_image_folder, start_page=1, end_page=3)\n",
    "\n",
    "    # # Example 3: Convert from a specific page to the end (e.g., from page 2 onwards)\n",
    "    # print(\"\\n--- Converting from page 2 to end ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_from_page_2.md\", output_image_folder, start_page=2)\n",
    "\n",
    "    # # Example 4: Convert up to a specific page (e.g., up to page 5)\n",
    "    # print(\"\\n--- Converting up to page 5 ---\")\n",
    "    # pdf_to_markdown(input_pdf_file, \"output_up_to_page_5.md\", output_image_folder, end_page=5)\n",
    "\n",
    "    # print(\"\\nProcess completed. Check the generated markdown files and image folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91b77796-d436-4f90-9827-b2a0bd77b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting entire PDF ---\n",
      "Starting PDF processing for: 'sample.pdf'...\n",
      "An unexpected error occurred: 5 validation errors for Unmarshaller\n",
      "body.FileChunk.file_id\n",
      "  Field required [type=missing, input_value={'type': 'file', 'data': ...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.ImageURLChunk.image_url\n",
      "  Field required [type=missing, input_value={'type': 'file', 'data': ...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.ImageURLChunk.type\n",
      "  Input should be 'image_url' [type=literal_error, input_value='file', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n",
      "body.DocumentURLChunk.document_url\n",
      "  Field required [type=missing, input_value={'type': 'file', 'data': ...ader name='sample.pdf'>}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "body.DocumentURLChunk.type\n",
      "  Input should be 'document_url' [type=literal_error, input_value='file', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from mistralai import Mistral\n",
    "\n",
    "def pdf_to_markdown(\n",
    "    pdf_path: str,\n",
    "    output_markdown_path: str,\n",
    "    image_folder_name: str = \"images\",\n",
    "    start_page: int = None,  # New parameter: starting page for conversion (inclusive)\n",
    "    end_page: int = None     # New parameter: ending page for conversion (inclusive)\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to Markdown using Mistral OCR, saving extracted images locally.\n",
    "    Markdown image links will be updated to reference these local image files.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the input PDF file.\n",
    "        output_markdown_path (str): The path where the output Markdown file will be saved.\n",
    "        image_folder_name (str): The name of the folder to save extracted images.\n",
    "                                  This folder will be created relative to the script's execution directory.\n",
    "        start_page (int, optional): The starting page number for OCR processing (1-indexed).\n",
    "                                    If None, processing starts from the first page.\n",
    "        end_page (int, optional): The ending page number for OCR processing (1-indexed).\n",
    "                                  If None, processing goes to the last page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the Mistral API key from environment variables\n",
    "        api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"Error: MISTRAL_API_KEY environment variable not set. Please set it before running.\")\n",
    "            return\n",
    "\n",
    "        # Initialize the Mistral client\n",
    "        client = Mistral(api_key=api_key)\n",
    "\n",
    "        print(f\"Starting PDF processing for: '{pdf_path}'...\")\n",
    "        if start_page is not None and end_page is not None:\n",
    "            print(f\"Processing pages from {start_page} to {end_page}...\")\n",
    "        elif start_page is not None:\n",
    "            print(f\"Processing from page {start_page} to the end...\")\n",
    "        elif end_page is not None:\n",
    "            print(f\"Processing from the beginning to page {end_page}...\")\n",
    "\n",
    "\n",
    "        # Open the PDF file in binary read mode\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            # Prepare the document dictionary, including page range if specified\n",
    "            document_payload = {\n",
    "                \"type\": \"file\",  # Correct type for local file upload\n",
    "                \"data\": f        # Pass the file object here\n",
    "            }\n",
    "            if start_page is not None:\n",
    "                document_payload[\"start_page\"] = start_page\n",
    "            if end_page is not None:\n",
    "                document_payload[\"end_page\"] = end_page\n",
    "\n",
    "            # Call the Mistral OCR API to process the document\n",
    "            # The 'document' parameter should be a dictionary containing file data and page range.\n",
    "            ocr_response = client.ocr.process(\n",
    "                model=\"mistral-ocr-latest\",\n",
    "                document=document_payload, # Pass the constructed dictionary here\n",
    "                include_image_base64=True\n",
    "            )\n",
    "\n",
    "        if not ocr_response:\n",
    "            print(\"Error: No response received from Mistral OCR. The API call might have failed or returned empty.\")\n",
    "            return\n",
    "\n",
    "        # Extract markdown content and image data from the OCR response\n",
    "        markdown_content = ocr_response.markdown\n",
    "        extracted_images = ocr_response.images\n",
    "\n",
    "        # Create the directory for saving images if it doesn't exist\n",
    "        if not os.path.exists(image_folder_name):\n",
    "            os.makedirs(image_folder_name)\n",
    "            print(f\"Created image folder: '{image_folder_name}'\")\n",
    "\n",
    "        # Dictionary to map Mistral image IDs to their new local filenames\n",
    "        image_id_to_filename = {}\n",
    "\n",
    "        # Process and save extracted images\n",
    "        if extracted_images:\n",
    "            print(f\"Found {len(extracted_images)} images. Saving them to '{image_folder_name}'...\")\n",
    "            for img_data in extracted_images:\n",
    "                image_id = img_data.id\n",
    "                image_base64 = img_data.image_base64\n",
    "\n",
    "                if image_base64:\n",
    "                    try:\n",
    "                        # Construct a filename for the image (assuming PNG format)\n",
    "                        image_filename = f\"{image_id}.png\"\n",
    "                        image_full_path = os.path.join(image_folder_name, image_filename)\n",
    "\n",
    "                        # Decode the base64 image data and write it to a file\n",
    "                        with open(image_full_path, \"wb\") as img_file:\n",
    "                            img_file.write(base64.b64decode(image_base64))\n",
    "\n",
    "                        # Store the mapping for later markdown modification\n",
    "                        image_id_to_filename[image_id] = image_filename\n",
    "                        print(f\"Saved image: '{image_full_path}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving image '{image_id}': {e}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Image '{image_id}' has no base64 data and could not be saved.\")\n",
    "        else:\n",
    "            print(\"No images were extracted from the PDF.\")\n",
    "\n",
    "        # Modify markdown content to reference local image paths\n",
    "        if markdown_content:\n",
    "            print(\"Adjusting image references in markdown content...\")\n",
    "            for image_id, filename in image_id_to_filename.items():\n",
    "                # Regular expression to find Markdown image links like `![alt text](image_id)`\n",
    "                # `re.escape(image_id)` is used to handle special characters in image_id if any.\n",
    "                # `(.*?)` captures the alt text (non-greedy).\n",
    "                # `\\\\1` in the replacement refers to the captured alt text.\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[(.*?)\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'![\\\\1]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "                # Also handle cases where there might be no alt text, e.g., `![]({image_id})`\n",
    "                markdown_content = re.sub(\n",
    "                    rf'\\!\\[\\]\\({re.escape(image_id)}\\)',\n",
    "                    rf'[]({image_folder_name}/{filename})',\n",
    "                    markdown_content\n",
    "                )\n",
    "\n",
    "            # Save the modified markdown content to the specified output file\n",
    "            with open(output_markdown_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown_content)\n",
    "            print(f\"Markdown content saved to: '{output_markdown_path}'\")\n",
    "        else:\n",
    "            print(\"No markdown content was extracted from the PDF.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The PDF file '{pdf_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        # For more detailed debugging, uncomment the following lines:\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT:\n",
    "    # 1. Install the Mistral AI library: pip install mistralai\n",
    "    # 2. Set your Mistral API key as an environment variable named MISTRAL_API_KEY.\n",
    "    #    - On Linux/macOS: export MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On Windows (Command Prompt): set MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    #    - On PowerShell: $env:MISTRAL_API_KEY=\"your_api_key_here\"\n",
    "    # 3. Replace 'path/to/your/document.pdf' with the actual path to your PDF file.\n",
    "    #    You can download a sample PDF, for example, from an arXiv paper:\n",
    "    #    https://arxiv.org/pdf/2201.04234.pdf (save it locally as 'sample.pdf')\n",
    "\n",
    "    # Define your input and output paths\n",
    "    input_pdf_file = \"sample.pdf\"  # Replace with your PDF file path\n",
    "    output_md_file = \"output.md\"\n",
    "    output_image_folder = \"extracted_images\" # Folder where images will be saved\n",
    "\n",
    "    # Example 1: Convert the entire PDF\n",
    "    print(\"--- Converting entire PDF ---\")\n",
    "    pdf_to_markdown(input_pdf_file, output_md_file, output_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f0724a-db38-412b-a9f7-9f10edc54ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter path to PDF file:  sample.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: sample.pdf\n",
      "Output directory: .\n",
      "Images directory: images\n",
      "Uploading PDF file...\n",
      "‚ùå Error during conversion: 1 validation error for Unmarshaller\n",
      "body\n",
      "  Input should be a valid dictionary or instance of File [type=model_type, input_value=<_io.BufferedReader name='sample.pdf'>, input_type=BufferedReader]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "‚ùå Error: 1 validation error for Unmarshaller\n",
      "body\n",
      "  Input should be a valid dictionary or instance of File [type=model_type, input_value=<_io.BufferedReader name='sample.pdf'>, input_type=BufferedReader]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from mistralai import Mistral\n",
    "import re\n",
    "\n",
    "class PDFToMarkdownConverter:\n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize the PDF to Markdown converter with Mistral OCR\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): Mistral API key. If None, will use MISTRAL_API_KEY environment variable\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or os.environ.get(\"MISTRAL_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API key is required. Set MISTRAL_API_KEY environment variable or pass api_key parameter.\")\n",
    "        \n",
    "        self.client = Mistral(api_key=self.api_key)\n",
    "    \n",
    "    def convert_pdf_to_markdown(self, pdf_path, output_dir=None):\n",
    "        \"\"\"\n",
    "        Convert a PDF file to markdown with images saved in a separate folder\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            output_dir (str): Directory to save output files. If None, uses PDF file directory\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (markdown_content, markdown_file_path, images_saved)\n",
    "        \"\"\"\n",
    "        pdf_path = Path(pdf_path)\n",
    "        \n",
    "        if not pdf_path.exists():\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "        \n",
    "        # Set up output directory\n",
    "        if output_dir is None:\n",
    "            output_dir = pdf_path.parent\n",
    "        else:\n",
    "            output_dir = Path(output_dir)\n",
    "        \n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create images folder\n",
    "        images_dir = output_dir / \"images\"\n",
    "        images_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Base name for output files\n",
    "        base_name = pdf_path.stem\n",
    "        \n",
    "        print(f\"Processing PDF: {pdf_path}\")\n",
    "        print(f\"Output directory: {output_dir}\")\n",
    "        print(f\"Images directory: {images_dir}\")\n",
    "        \n",
    "        try:\n",
    "            # First, upload the PDF file\n",
    "            print(\"Uploading PDF file...\")\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                upload_response = self.client.files.upload(\n",
    "                    file=file,\n",
    "                    purpose=\"fine-tune\"  # or another valid purpose\n",
    "                )\n",
    "            \n",
    "            file_id = upload_response.id\n",
    "            print(f\"File uploaded with ID: {file_id}\")\n",
    "            \n",
    "            # Process PDF with Mistral OCR using the uploaded file\n",
    "            print(\"Processing PDF with Mistral OCR...\")\n",
    "            ocr_response = self.client.ocr.process(\n",
    "                model=\"mistral-ocr-latest\",\n",
    "                document={\n",
    "                    \"type\": \"file\",\n",
    "                    \"file_id\": file_id\n",
    "                },\n",
    "                include_image_base64=True\n",
    "            )\n",
    "            \n",
    "            # Extract markdown content\n",
    "            markdown_content = ocr_response.markdown\n",
    "            \n",
    "            # Process and save images\n",
    "            images_saved = 0\n",
    "            if hasattr(ocr_response, 'images') and ocr_response.images:\n",
    "                images_saved = self._save_images(ocr_response.images, images_dir, base_name)\n",
    "                \n",
    "                # Update markdown to reference local images\n",
    "                markdown_content = self._update_image_references(markdown_content, images_dir.name)\n",
    "            \n",
    "            # Save markdown file\n",
    "            markdown_file_path = output_dir / f\"{base_name}.md\"\n",
    "            with open(markdown_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(markdown_content)\n",
    "            \n",
    "            print(f\"‚úÖ Conversion completed!\")\n",
    "            print(f\"üìÑ Markdown saved: {markdown_file_path}\")\n",
    "            print(f\"üñºÔ∏è  Images saved: {images_saved}\")\n",
    "            \n",
    "            # Clean up uploaded file\n",
    "            try:\n",
    "                self.client.files.delete(file_id)\n",
    "                print(f\"üßπ Cleaned up uploaded file: {file_id}\")\n",
    "            except Exception as cleanup_error:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Could not clean up uploaded file: {cleanup_error}\")\n",
    "            \n",
    "            return markdown_content, markdown_file_path, images_saved\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during conversion: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _save_images(self, images, images_dir, base_name):\n",
    "        \"\"\"\n",
    "        Save base64 encoded images to the images directory\n",
    "        \n",
    "        Args:\n",
    "            images (list): List of image data from OCR response\n",
    "            images_dir (Path): Directory to save images\n",
    "            base_name (str): Base name for image files\n",
    "            \n",
    "        Returns:\n",
    "            int: Number of images saved\n",
    "        \"\"\"\n",
    "        images_saved = 0\n",
    "        \n",
    "        for i, image_data in enumerate(images):\n",
    "            try:\n",
    "                # Handle different possible image data structures\n",
    "                if isinstance(image_data, dict):\n",
    "                    if 'base64' in image_data:\n",
    "                        base64_data = image_data['base64']\n",
    "                        # Get format from metadata or default to png\n",
    "                        image_format = image_data.get('format', 'png')\n",
    "                    elif 'data' in image_data:\n",
    "                        base64_data = image_data['data']\n",
    "                        image_format = image_data.get('format', 'png')\n",
    "                    else:\n",
    "                        base64_data = str(image_data)\n",
    "                        image_format = 'png'\n",
    "                else:\n",
    "                    base64_data = str(image_data)\n",
    "                    image_format = 'png'\n",
    "                \n",
    "                # Clean base64 data (remove data URL prefix if present)\n",
    "                if base64_data.startswith('data:'):\n",
    "                    base64_data = base64_data.split(',', 1)[1]\n",
    "                \n",
    "                # Generate filename\n",
    "                image_filename = f\"{base_name}_image_{i+1:03d}.{image_format}\"\n",
    "                image_path = images_dir / image_filename\n",
    "                \n",
    "                # Decode and save image\n",
    "                image_bytes = base64.b64decode(base64_data)\n",
    "                with open(image_path, 'wb') as f:\n",
    "                    f.write(image_bytes)\n",
    "                \n",
    "                images_saved += 1\n",
    "                print(f\"üíæ Saved image: {image_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Could not save image {i+1}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return images_saved\n",
    "    \n",
    "    def _update_image_references(self, markdown_content, images_folder_name):\n",
    "        \"\"\"\n",
    "        Update image references in markdown to point to local images folder\n",
    "        \n",
    "        Args:\n",
    "            markdown_content (str): Original markdown content\n",
    "            images_folder_name (str): Name of the images folder\n",
    "            \n",
    "        Returns:\n",
    "            str: Updated markdown content\n",
    "        \"\"\"\n",
    "        # Pattern to match various image reference formats\n",
    "        patterns = [\n",
    "            r'!\\[([^\\]]*)\\]\\(([^)]+)\\)',  # ![alt](url)\n",
    "            r'<img[^>]+src=[\"\\']([^\"\\']+)[\"\\'][^>]*>',  # HTML img tags\n",
    "        ]\n",
    "        \n",
    "        updated_content = markdown_content\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            def replace_image_ref(match):\n",
    "                if pattern.startswith('!'):\n",
    "                    # Markdown format\n",
    "                    alt_text = match.group(1)\n",
    "                    original_url = match.group(2)\n",
    "                    \n",
    "                    # Generate local image reference\n",
    "                    # This is a simplified approach - in practice, you'd need to map\n",
    "                    # the original references to the saved images\n",
    "                    local_ref = f\"{images_folder_name}/image_{hash(original_url) % 1000:03d}.png\"\n",
    "                    return f\"![{alt_text}]({local_ref})\"\n",
    "                else:\n",
    "                    # HTML format - keep as is for now\n",
    "                    return match.group(0)\n",
    "            \n",
    "            updated_content = re.sub(pattern, replace_image_ref, updated_content)\n",
    "        \n",
    "        return updated_content\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the PDF to Markdown converter\n",
    "    \"\"\"\n",
    "    # Initialize converter\n",
    "    converter = PDFToMarkdownConverter()\n",
    "    \n",
    "    # Example usage\n",
    "    pdf_file = input(\"Enter path to PDF file: \").strip()\n",
    "    \n",
    "    if not pdf_file:\n",
    "        print(\"No file specified. Using example...\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Convert PDF to markdown\n",
    "        markdown_content, markdown_file, images_count = converter.convert_pdf_to_markdown(pdf_file)\n",
    "        \n",
    "        print(f\"\\nüéâ Success! Converted '{pdf_file}' to markdown\")\n",
    "        print(f\"üìÅ Output: {markdown_file}\")\n",
    "        print(f\"üñºÔ∏è  Images extracted: {images_count}\")\n",
    "        \n",
    "        # Optionally display first few lines of markdown\n",
    "        print(f\"\\nüìù First 300 characters of markdown:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(markdown_content[:300] + \"...\" if len(markdown_content) > 300 else markdown_content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98199784-b00a-4e3e-8294-9258d41590f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def save_images(images, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved_files = []\n",
    "    for img in images:\n",
    "        img_filename = img.id  # unique name like \"img-0.jpeg\"\n",
    "        filepath = os.path.join(output_dir, img_filename)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(base64.b64decode(img.image_base64))\n",
    "        saved_files.append(img_filename)\n",
    "    return saved_files\n",
    "\n",
    "def pdf_to_markdown(pdf_path, md_output=\"sample.md\", img_dir=\"images\"):\n",
    "    load_dotenv()\n",
    "    api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "    client = Mistral(api_key=api_key)\n",
    "\n",
    "    # Encode PDF to base64 data URI\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        pdf_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    data_uri = f\"data:application/pdf;base64,{pdf_b64}\"\n",
    "\n",
    "    resp = client.ocr.process(\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        document={\"type\": \"document_url\", \"document_url\": data_uri},\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    total_md = \"\"\n",
    "    with open(md_output, \"w\", encoding=\"utf-8\") as md:\n",
    "        for page in resp.pages:\n",
    "            saved = save_images(page.images or [], img_dir)\n",
    "\n",
    "            # rewrite image links to include folder prefix\n",
    "            md_text = page.markdown\n",
    "            for fname in saved:\n",
    "                md_text = md_text.replace(f\"({fname})\", f\"({img_dir}/{fname})\")\n",
    "\n",
    "            md.write(md_text + \"\\n\\n\")\n",
    "            total_md += \"\\n\\n\"+md_text\n",
    "\n",
    "    print(f\"‚úÖ Output saved to '{md_output}', with images in '{img_dir}/'\")\n",
    "\n",
    "    return total_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae310d85-c33a-4c8f-9b77-7e988273f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output saved to 'sample.md', with images in 'images/'\n",
      "Total time =  18.76445508003235\n",
      "\n",
      "\n",
      "# Leveraging Unlabeled Data to Predict Out-of-Distribution Performance \n",
      "\n",
      "Saurabh Garg*<br>Carnegie Mellon University<br>sgarg2@andrew.cmu.edu Sivaraman Balakrishnan<br>Carnegie Mellon University<br>sbalakri@andrew.cmu.edu Zachary C. Lipton<br>Carnegie Mellon University<br>zlipton@andrew.cmu.edu\n",
      "\n",
      "## Behnam Neyshabur\n",
      "\n",
      "Google Research, Blueshift team neyshabur@google.com\n",
      "\n",
      "## Hanie Sedghi\n",
      "\n",
      "Google Research, Brain team hsedghi@google.com\n",
      "\n",
      "## ABSTRACT\n",
      "\n",
      "Real-world machine learning deployments are characterized by mismatches between the source (training) and target (test) distributions that may cause performance drops. In this work, we investigate methods for predicting the target domain accuracy using only labeled source data and unlabeled target data. We propose Average Thresholded Confidence (ATC), a practical method that learns a threshold on the model's confidence, predicting accuracy as the fraction of unlabeled examples for which model confidence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). In our experiments, ATC estimates target performance $2-4 \\times$ more accurately than prior methods. We also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efficacy of any method rests upon (perhaps unstated) assumptions on the nature of the shift. Finally, analyzing our method on some toy distributions, we provide insights concerning when it works ${ }^{1}$.\n",
      "\n",
      "## 1 INTRODUCTION\n",
      "\n",
      "Machine learning models deployed in the real world typically encounter examples from previously unseen distributions. While the IID assumption enables us to evaluate models using held-out data from the source distribution (from which training data is sampled), this estimate is no longer valid in presence of a distribution shift. Moreover, under such shifts, model accuracy tends to degrade (Szegedy et al., 2014; Recht et al., 2019; Koh et al., 2021). Commonly, the only data available to the practitioner are a labeled training set (source) and unlabeled deployment-time data which makes the problem more difficult. In this setting, detecting shifts in the distribution of covariates is known to be possible (but difficult) in theory (Ramdas et al., 2015), and in practice (Rabanser et al., 2018). However, producing an optimal predictor using only labeled source and unlabeled target data is well-known to be impossible absent further assumptions (Ben-David et al., 2010; Lipton et al., 2018).\n",
      "\n",
      "Two vital questions that remain are: (i) the precise conditions under which we can estimate a classifier's target-domain accuracy; and (ii) which methods are most practically useful. To begin, the straightforward way to assess the performance of a model under distribution shift would be to collect labeled (target domain) examples and then to evaluate the model on that data. However, collecting fresh labeled data from the target distribution is prohibitively expensive and time-consuming, especially if the target distribution is non-stationary. Hence, instead of using labeled data, we aim to use unlabeled data from the target distribution, that is comparatively abundant, to predict model performance. Note that in this work, our focus is not to improve performance on the target but, rather, to estimate the accuracy on the target for a given classifier.\n",
      "\n",
      "[^0]\n",
      "[^0]:    * Work done in part while Saurabh Garg was interning at Google\n",
      "    ${ }^{1}$ Code is available at https://github.com/saurabhgarg1996/ATC_code.\n",
      "\n",
      "![img-0.jpeg](images/img-0.jpeg)\n",
      "\n",
      "Figure 1: Illustration of our proposed method ATC. Left: using source domain validation data, we identify a threshold on a score (e.g. negative entropy) computed on model confidence such that fraction of examples above the threshold matches the validation set accuracy. ATC estimates accuracy on unlabeled target data as the fraction of examples with the score above the threshold. Interestingly, this threshold yields accurate estimates on a wide set of target distributions resulting from natural and synthetic shifts. Right: Efficacy of ATC over previously proposed approaches on our testbed with a post-hoc calibrated model. To obtain errors on the same scale, we rescale all errors with Average Confidence (AC) error. Lower estimation error is better. See Table 1 for exact numbers and comparison on various types of distribution shift. See Sec. 5 for details on our testbed.\n",
      "\n",
      "Recently, numerous methods have been proposed for this purpose (Deng & Zheng, 2021; Chen et al., 2021b; Jiang et al., 2021; Deng et al., 2021; Guillory et al., 2021). These methods either require calibration on the target domain to yield consistent estimates (Jiang et al., 2021; Guillory et al., 2021) or additional labeled data from several target domains to learn a linear regression function on a distributional distance that then predicts model performance (Deng et al., 2021; Deng & Zheng, 2021; Guillory et al., 2021). However, methods that require calibration on the target domain typically yield poor estimates since deep models trained and calibrated on source data are not, in general, calibrated on a (previously unseen) target domain (Ovadia et al., 2019). Besides, methods that leverage labeled data from target domains rely on the fact that unseen target domains exhibit strong linear correlation with seen target domains on the underlying distance measure and, hence, can be rendered ineffective when such target domains with labeled data are unavailable (in Sec. 5.1 we demonstrate such a failure on a real-world distribution shift problem). Therefore, throughout the paper, we assume access to labeled source data and only unlabeled data from target domain(s).\n",
      "\n",
      "In this work, we first show that absent assumptions on the source classifier or the nature of the shift, no method of estimating accuracy will work generally (even in non-contrived settings). To estimate accuracy on target domain perfectly, we highlight that even given perfect knowledge of the labeled source distribution (i.e., $p_{s}(x, y)$) and unlabeled target distribution (i.e., $p_{t}(x)$), we need restrictions on the nature of the shift such that we can uniquely identify the target conditional $p_{t}(y | x)$. Thus, in general, identifying the accuracy of the classifier is as hard as identifying the optimal predictor.\n",
      "\n",
      "Second, motivated by the superiority of methods that use maximum softmax probability (or logit) of a model for Out-Of-Distribution (OOD) detection (Hendrycks & Gimpel, 2016; Hendrycks et al., 2019), we propose a simple method that leverages softmax probability to predict model performance. Our method, Average Thresholded Confidence (ATC), learns a threshold on a score (e.g., maximum confidence or negative entropy) of model confidence on validation source data and predicts target domain accuracy as the fraction of unlabeled target points that receive a score above that threshold. ATC selects a threshold on validation source data such that the fraction of source examples that receive the score above the threshold match the accuracy of those examples. Our primary contribution in ATC is the proposal of obtaining the threshold and observing its efficacy on (practical) accuracy estimation. Importantly, our work takes a step forward in positively answering the question raised in Deng & Zheng (2021); Deng et al. (2021) about a practical strategy to select a threshold that enables accuracy prediction with thresholded model confidence.\n",
      "\n",
      "ATC is simple to implement with existing frameworks, compatible with arbitrary model classes, and dominates other contemporary methods. Across several model architectures on a range of benchmark vision and language datasets, we verify that ATC outperforms prior methods by at least $2-4 \\times$ in predicting target accuracy on a variety of distribution shifts. In particular, we consider shifts due to common corruptions (e.g., ImageNet-C), natural distribution shifts due to dataset reproduction (e.g., ImageNet-v2, ImageNet-R), shifts due to novel subpopulations (e.g., BREEDS), and distribution shifts faced in the wild (e.g., WILDS).\n",
      "\n",
      "As a starting point for theory development, we investigate ATC on a simple toy model that models distribution shift with varying proportions of the population with spurious features, as in Nagarajan et al. (2020). Finally, we note that although ATC achieves superior performance in our empirical evaluation, like all methods, it must fail (returns inconsistent estimates) on certain types of distribution shifts, per our impossibility result.\n",
      "\n",
      "# 2 Prior Work \n",
      "\n",
      "Out-of-distribution detection. The main goal of OOD detection is to identify previously unseen examples, i.e., samples out of the support of training distribution. To accomplish this, modern methods utilize confidence or features learned by a deep network trained on some source data. Hendrycks \\& Gimpel (2016); Geifman \\& El-Yaniv (2017) used the confidence score of an (already) trained deep model to identify OOD points. Lakshminarayanan et al. (2016) use entropy of an ensemble model to evaluate prediction uncertainty on OOD points. To improve OOD detection with model confidence, Liang et al. (2017) propose to use temperature scaling and input perturbations. Jiang et al. (2018) propose to use scores based on the relative distance of the predicted class to the second class. Recently, residual flow-based methods were used to obtain a density model for OOD detection (Zhang et al., 2020). Ji et al. (2021) proposed a method based on subfunction error bounds to compute unreliability per sample. Refer to Ovadia et al. (2019); Ji et al. (2021) for an overview and comparison of methods for prediction uncertainty on OOD data.\n",
      "\n",
      "Predicting model generalization. Understanding generalization capabilities of overparameterized models on in-distribution data using conventional machine learning tools has been a focus of a long line of work; representative research includes Neyshabur et al. (2015; 2017); Neyshabur (2017); Neyshabur et al. (2018); Dziugaite \\& Roy (2017); Bartlett et al. (2017); Zhou et al. (2018); Long \\& Sedghi (2019); Nagarajan \\& Kolter (2019a). At a high level, this line of research bounds the generalization gap directly with complexity measures calculated on the trained model. However, these bounds typically remain numerically loose relative to the true generalization error (Zhang et al., 2016; Nagarajan \\& Kolter, 2019b). On the other hand, another line of research departs from complexitybased approaches to use unseen unlabeled data to predict in-distribution generalization (Platanios et al., 2016; 2017; Garg et al., 2021; Jiang et al., 2021).\n",
      "\n",
      "Relevant to our work are methods for predicting the error of a classifier on OOD data based on unlabeled data from the target (OOD) domain. These methods can be characterized into two broad categories: (i) Methods which explicitly predict correctness of the model on individual unlabeled points (Deng \\& Zheng, 2021; Jiang et al., 2021; Deng et al., 2021; Chen et al., 2021a); and (ii) Methods which directly obtain an estimate of error with unlabeled OOD data without making a point-wise prediction (Chen et al., 2021b; Guillory et al., 2021; Chuang et al., 2020).\n",
      "\n",
      "To achieve a consistent estimate of the target accuracy, Jiang et al. (2021); Guillory et al. (2021) require calibration on target domain. However, these methods typically yield poor estimates as deep models trained and calibrated on some source data are seldom calibrated on previously unseen domains (Ovadia et al., 2019). Additionally, Deng \\& Zheng (2021); Guillory et al. (2021) derive model-based distribution statistics on unlabeled target set that correlate with the target accuracy and propose to use a subset of labeled target domains to learn a (linear) regression function that predicts model performance. However, there are two drawbacks with this approach: (i) the correlation of these distribution statistics can vary substantially as we consider different nature of shifts (refer to Sec. 5.1, where we empirically demonstrate this failure); (ii) even if there exists a (hypothetical) statistic with strong correlations, obtaining labeled target domains (even simulated ones) with strong correlations would require significant a priori knowledge about the nature of shift that, in general, might not be available before models are deployed in the wild. Nonetheless, in our work, we only assume access to labeled data from the source domain presuming no access to labeled target domains or information about how to simulate them.\n",
      "\n",
      "Moreover, unlike the parallel work of Deng et al. (2021), we do not focus on methods that alter the training on source data to aid accuracy prediction on the target data. Chen et al. (2021b) propose an importance re-weighting based approach that leverages (additional) information about the axis along which distribution is shifting in form of ‚Äúslicing functions‚Äù. In our work, we make comparisons with importance re-weighting baseline from Chen et al. (2021b) as we do not have any additional information about the axis along which the distribution is shifting.\n",
      "\n",
      "# 3 Problem Setup \n",
      "\n",
      "Notation. By $\\llbracket \\cdot \\rrbracket$, and $\\langle\\cdot, \\cdot\\rangle$ we denote the Euclidean norm and inner product, respectively. For a vector $v \\in \\mathbb{R}^{d}$, we use $v_{j}$ to denote its $j^{\\text {th }}$ entry, and for an event $E$ we let $\\mathbb{I}[E]$ denote the binary indicator of the event.\n",
      "\n",
      "Suppose we have a multi-class classification problem with the input domain $\\mathcal{X} \\subseteq \\mathbb{R}^{d}$ and label space $\\mathcal{Y}=\\{1,2, \\ldots, k\\}$. For binary classification, we use $\\mathcal{Y}=\\{0,1\\}$. By $\\mathcal{D}^{\\mathrm{S}}$ and $\\mathcal{D}^{\\mathrm{T}}$, we denote source and target distribution over $\\mathcal{X} \\times \\mathcal{Y}$. For distributions $\\mathcal{D}^{\\mathrm{S}}$ and $\\mathcal{D}^{\\mathrm{T}}$, we define $p_{\\mathrm{S}}$ or $p_{\\mathrm{T}}$ as the corresponding probability density (or mass) functions. A dataset $S:=\\left\\{\\left(x_{i}, y_{i}\\right)\\right\\}_{i=1}^{n} \\sim\\left(\\mathcal{D}^{\\mathrm{S}}\\right)^{n}$ contains $n$ points sampled i.i.d. from $\\mathcal{D}^{\\mathrm{S}}$. Let $\\mathcal{F}$ be a class of hypotheses mapping $\\mathcal{X}$ to $\\Delta^{k-1}$ where $\\Delta^{k-1}$ is a simplex in $k$ dimensions. Given a classifier $f \\in \\mathcal{F}$ and datum $(x, y)$, we denote the 0-1 error (i.e., classification error) on that point by $\\mathcal{E}(f(x), y):=\\mathbb{I}\\left[y \\notin \\arg \\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]$. Given a model $f \\in \\mathcal{F}$, our goal in this work is to understand the performance of $f$ on $\\mathcal{D}^{\\mathrm{T}}$ without access to labeled data from $\\mathcal{D}^{\\mathrm{T}}$. Note that our goal is not to adapt the model to the target data. Concretely, we aim to predict accuracy of $f$ on $\\mathcal{D}^{\\mathrm{T}}$. Throughout this paper, we assume we have access to the following: (i) model $f$; (ii) previously-unseen (validation) data from $\\mathcal{D}^{\\mathrm{S}}$; and (iii) unlabeled data from target distribution $\\mathcal{D}^{\\mathrm{T}}$.\n",
      "\n",
      "### 3.1 Accuracy Estimation: Possibility and Impossibility Results\n",
      "\n",
      "First, we investigate the question of when it is possible to estimate the target accuracy of an arbitrary classifier, even given knowledge of the full source distribution $p_{s}(x, y)$ and target marginal $p_{t}(x)$. Absent assumptions on the nature of shift, estimating target accuracy is impossible. Even given access to $p_{s}(x, y)$ and $p_{t}(x)$, the problem is fundamentally unidentifiable because $p_{t}(y \\mid x)$ can shift arbitrarily. In the following proposition, we show that absent assumptions on the classifier $f$ (i.e., when $f$ can be any classifier in the space of all classifiers on $\\mathcal{X}$ ), we can estimate accuracy on the target data iff assumptions on the nature of the shift, together with $p_{s}(x, y)$ and $p_{t}(x)$, uniquely identify the (unknown) target conditional $p_{t}(y \\mid x)$. We relegate proofs from this section to App. A.\n",
      "Proposition 1. Absent further assumptions, accuracy on the target is identifiable iff $p_{t}(y \\mid x)$ is uniquely identified given $p_{s}(x, y)$ and $p_{t}(x)$.\n",
      "\n",
      "Proposition 1 states that we need enough constraints on nature of shift such that $p_{s}(x, y)$ and $p_{t}(x)$ identifies unique $p_{t}(y \\mid x)$. It also states that under some assumptions on the nature of the shift, we can hope to estimate the model's accuracy on target data. We will illustrate this on two common assumptions made in domain adaptation literature: (i) covariate shift (Heckman, 1977; Shimodaira, 2000) and (ii) label shift (Saerens et al., 2002; Zhang et al., 2013; Lipton et al., 2018). Under covariate shift assumption, that the target marginal support $\\operatorname{supp}\\left(p_{t}(x)\\right)$ is a subset of the source marginal support $\\operatorname{supp}\\left(p_{s}(x)\\right)$ and that the conditional distribution of labels given inputs does not change within support, i.e., $p_{s}(y \\mid x)=p_{t}(y \\mid x)$, which, trivially, identifies a unique target conditional $p_{t}(y \\mid x)$. Under label shift, the reverse holds, i.e., the class-conditional distribution does not change $\\left(p_{s}(x \\mid y)=p_{t}(x \\mid y)\\right)$ and, again, information about $p_{t}(x)$ uniquely determines the target conditional $p_{t}(y \\mid x)$ (Lipton et al., 2018; Garg et al., 2020). In these settings, one can estimate an arbitrary classifier's accuracy on the target domain either by using importance re-weighting with the ratio $p_{t}(x) / p_{s}(x)$ in case of covariate shift or by using importance re-weighting with the ratio $p_{t}(y) / p_{s}(y)$ in case of label shift. While importance ratios in the former case can be obtained directly when $p_{t}(x)$ and $p_{s}(x)$ are known, the importance ratios in the latter case can be obtained by using techniques from Saerens et al. (2002); Lipton et al. (2018); Azizzadenesheli et al. (2019); Alexandari et al. (2019). In App. B,we explore accuracy estimation in the setting of these shifts and present extensions to generalized notions of label shift (Tachet des Combes et al., 2020) and covariate shift (Rojas-Carulla et al., 2018).\n",
      "\n",
      "As a corollary of Proposition 1, we now present a simple impossibility result, demonstrating that no single method can work for all families of distribution shift.\n",
      "\n",
      "Corollary 1. Absent assumptions on the classifier $f$, no method of estimating accuracy will work in all scenarios, i.e., for different nature of distribution shifts.\n",
      "\n",
      "Intuitively, this result states that every method of estimating accuracy on target data is tied up with some assumption on the nature of the shift and might not be useful for estimating accuracy under a different assumption on the nature of the shift. For illustration, consider a setting where we have access to distribution $p_{s}(x, y)$ and $p_{t}(x)$. Additionally, assume that the distribution can shift only due to covariate shift or label shift without any knowledge about which one. Then Corollary 1 says that it is impossible to have a single method that will simultaneously for both label shift and covariate shift as in the following example (we spell out the details in App. A):\n",
      "\n",
      "Example 1. Assume binary classification with $p_{s}(x)=\\alpha \\cdot \\phi\\left(\\mu_{1}\\right)+(1-\\alpha) \\cdot \\phi\\left(\\mu_{2}\\right)$, $p_{s}(x \\mid y=0)=\\phi\\left(\\mu_{1}\\right), p_{s}(x \\mid y=1)=\\phi\\left(\\mu_{2}\\right)$, and $p_{t}(x)=\\beta \\cdot \\phi\\left(\\mu_{1}\\right)+(1-\\beta) \\cdot \\phi\\left(\\mu_{2}\\right)$ where $\\phi(\\mu)=\\mathcal{N}(\\mu, 1), \\alpha, \\beta \\in(0,1)$, and $\\alpha \\neq \\beta$. Error of a classifier $f$ on target data is given by $\\mathcal{E}_{1}=\\mathbb{E}_{(x, y) \\sim p_{s}(x, y)}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq y]\\right]$ under covariate shift and by $\\mathcal{E}_{2}=$ $\\mathbb{E}_{(x, y) \\sim p_{s}(x, y)}\\left[\\left(\\frac{\\beta}{\\alpha} \\mathbb{I}[y=0]+\\frac{1-\\beta}{1-\\alpha} \\mathbb{I}[y=1]\\right) \\mathbb{I}[f(x) \\neq y]\\right]$ under label shift. In App. A, we show that $\\mathcal{E}_{1} \\neq \\mathcal{E}_{2}$ for all $f$. Thus, given access to $p_{s}(x, y)$, and $p_{t}(x)$, any method that consistently estimates error of a classifer under covariate shift will give an incorrect estimate of error under label shift and vice-versa. The reason is that the same $p_{t}(x)$ and $p_{s}(x, y)$ can correspond to error $\\mathcal{E}_{1}$ (under covariate shift) or error $\\mathcal{E}_{2}$ (under label shift) and determining which scenario one faces requires further assumptions on the nature of shift.\n",
      "\n",
      "# 4 Predicting accuracy with Average Thresholded Confidence \n",
      "\n",
      "In this section, we present our method ATC that leverages a black box classifier $f$ and (labeled) validation source data to predict accuracy on target domain given access to unlabeled target data. Throughout the discussion, we assume that the classifier $f$ is fixed.\n",
      "Before presenting our method, we introduce some terminology. Define a score function $s: \\Delta^{k-1} \\rightarrow$ $\\mathbb{R}$ that takes in the softmax prediction of the function $f$ and outputs a scalar. We want a score function such that if the score function takes a high value at a datum $(x, y)$ then $f$ is likely to be correct. In this work, we explore two such score functions: (i) Maximum confidence, i.e., $s(f(x))=\\max _{j \\in \\mathcal{Y}} f_{j}(x)$; and (ii) Negative Entropy, i.e., $s(f(x))=\\sum_{j} f_{j}(x) \\log \\left(f_{j}(x)\\right)$. Our method identifies a threshold $t$ on source data $\\mathcal{D}^{\\mathrm{S}}$ such that the expected number of points that obtain a score less than $t$ match the error of $f$ on $\\mathcal{D}^{\\mathrm{S}}$, i.e.,\n",
      "\n",
      "$$\n",
      "\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{S}}}[\\mathbb{I}[s(f(x))<t]]=\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{\\mathrm{S}}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\n",
      "$$\n",
      "\n",
      "and then our error estimate $\\operatorname{ATC}_{\\mathcal{D}^{\\mathrm{T}}}(s)$ on the target domain $\\mathcal{D}^{\\mathrm{T}}$ is given by the expected number of target points that obtain a score less than $t$, i.e.,\n",
      "\n",
      "$$\n",
      "\\operatorname{ATC}_{\\mathcal{D}^{\\mathrm{T}}}(s)=\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{T}}}[\\mathbb{I}[s(f(x))<t]]\n",
      "$$\n",
      "\n",
      "In short, in (1), ATC selects a threshold on the score function such that the error in the source domain matches the expected number of points that receive a score below $t$ and in (2), ATC predicts error on the target domain as the fraction of unlabeled points that obtain a score below that threshold $t$. Note that, in principle, there exists a different threshold $t^{\\prime}$ on the target distribution $\\mathcal{D}^{\\mathrm{T}}$ such that (1) is satisfied on $\\mathcal{D}^{\\mathrm{T}}$. However, in our experiments, the same threshold performs remarkably well. The main empirical contribution of our work is to show that the threshold obtained with (1) might be used effectively in condunction with modern deep networks in a wide range of settings to estimate error on the target data. In practice, to obtain the threshold with ATC, we minimize the difference between the expression on two sides of (1) using finite samples. In the next section, we show that ATC precisely predicts accuracy on the OOD data on the desired line $y=x$. In App. C, we discuss an alternate interpretation of the method and make connections with OOD detection methods.\n",
      "\n",
      "## 5 EXPERIMENTS\n",
      "\n",
      "We now empirical evaluate ATC and compare it with existing methods. In each of our main experiment, keeping the underlying model fixed, we vary target datasets and make a prediction\n",
      "\n",
      "![img-1.jpeg](images/img-1.jpeg)\n",
      "\n",
      "Figure 2: Scatter plot of predicted accuracy versus (true) OOD accuracy. Each point denotes a different OOD dataset, all evaluated with the same DenseNet121 model. We only plot the best three methods. With ATC (ours), we refer to ATC-NE. We observe that ATC significantly outperforms other methods and with ATC, we recover the desired line $y=x$ with a robust linear fit. Aggregated estimation error in Table 1 and plots for other datasets and architectures in App. H.\n",
      "of the target accuracy with various methods given access to only unlabeled data from the target. Unless noted otherwise, all models are trained only on samples from the source distribution with the main exception of pre-training on a different distribution. We use labeled examples from the target distribution to only obtain true error estimates.\n",
      "\n",
      "Datasets. First, we consider synthetic shifts induced due to different visual corruptions (e.g., shot noise, motion blur etc.) under ImageNet-C (Hendrycks \\& Dietterich, 2019). Next, we consider natural shifts due to differences in the data collection process of ImageNet (Russakovsky et al., 2015), e.g, ImageNetv2 (Recht et al., 2019). We also consider images with artistic renditions of object classes, i.e., ImageNet-R (Hendrycks et al., 2021) and ImageNet-Sketch (Wang et al., 2019). Note that renditions dataset only contains a subset 200 classes from ImageNet. To include renditions dataset in our testbed, we include results on ImageNet restricted to these 200 classes (which we call ImageNet-200) along with full ImageNet.\n",
      "\n",
      "Second, we consider BREEDS (Santurkar et al., 2020) to assess robustness to subpopulation shifts, in particular, to understand how accuracy estimation methods behave when novel subpopulations not observed during training are introduced. BREEDS leverages class hierarchy in ImageNet to create 4 datasets ENTITY-13, ENTITY-30, LIVING-17, NON-LIVING-26. We focus on natural and synthetic shifts as in ImageNet on same and different subpopulations in BREEDs. Third, from WILDS (Koh et al., 2021) benchmark, we consider FMoW-WILDS (Christie et al., 2018), RxRx1-WILDS (Taylor et al., 2019), Amazon-WILDS (Ni et al., 2019), CivilComments-WILDS (Borkan et al., 2019) to consider distribution shifts faced in the wild.\n",
      "\n",
      "Finally, similar to ImageNet, we consider (i) synthetic shifts (CIFAR-10-C) due to common corruptions; and (ii) natural shift (i.e., CIFARv2 (Recht et al., 2018)) on CIFAR-10 (Krizhevsky \\& Hinton, 2009). On CIFAR-100, we just have synthetic shifts due to common corruptions. For completeness, we also consider natural shifts on MNIST (LeCun et al., 1998) as in the prior work (Deng \\& Zheng, 2021). We use three real shifted datasets, i.e., USPS (Hull, 1994), SVHN (Netzer et al., 2011) and QMNIST (Yadav \\& Bottou, 2019). We give a detailed overview of our setup in App. F.\n",
      "\n",
      "Architectures and Evaluation. For ImageNet, BREEDS, CIFAR, FMoW-WILDS, RxRx1-WILDS datasets, we use DenseNet121 (Huang et al., 2017) and ResNet50 (He et al., 2016) architectures. For Amazon-WILDS and CivilComments-WILDS, we fine-tune a DistilBERT-base-uncased (Sanh et al., 2019) model. For MNIST, we train a fully connected multilayer perceptron. We use standard training with benchmarked hyperparameters. To compare methods, we report average absolute difference between the true accuracy on the target data and the estimated accuracy on the same unlabeled examples. We refer to this metric as Mean Absolute estimation Error (MAE). Along with MAE, we also show scatter plots to visualize performance at individual target sets. Refer to App. G for additional details on the setup.\n",
      "\n",
      "Methods With ATC-NE, we denote ATC with negative entropy score function and with ATC-MC, we denote ATC with maximum confidence score function. For all methods, we implement post-hoc calibration on validation source data with Temperature Scaling (TS; Guo et al. (2017)). Below we briefly discuss baselines methods compared in our work and relegate details to App. E.\n",
      "\n",
      "| Dataset | Shift | IM |  | AC |  | DOC |  | GDE | ATC-MC (Ours) |  | ATC-NE (Ours) |  |\n",
      "| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
      "|  |  | Pre T | Post T | Pre T | Post T | Pre T | Post T | Post T | Pre T | Post T | Pre T | Post T |\n",
      "| CIFAR10 | Natural | 6.60 | 5.74 | 9.88 | 6.89 | 7.25 | 6.07 | 4.77 | 3.21 | 3.02 | 2.99 | 2.85 |\n",
      "|  | Synthetic | 12.33 | 10.20 | 16.50 | 11.91 | 13.87 | 11.08 | 6.55 | 4.65 | 4.25 | 4.21 | 3.87 |\n",
      "| CIFAR100 | Synthetic | 13.69 | 11.51 | 23.61 | 13.10 | 14.60 | 10.14 | 9.85 | 5.50 | 4.75 | 4.72 | 4.94 |\n",
      "| ImageNet200 | Natural | 12.37 | 8.19 | 22.07 | 8.61 | 15.17 | 7.81 | 5.13 | 4.37 | 2.04 | 3.79 | 1.45 |\n",
      "|  | Synthetic | 19.86 | 12.94 | 32.44 | 13.35 | 25.02 | 12.38 | 5.41 | 5.93 | 3.09 | 5.00 | 2.68 |\n",
      "| ImageNet | Natural | 7.77 | 6.50 | 18.13 | 6.02 | 8.13 | 5.76 | 6.23 | 3.88 | 2.17 | 2.06 | 0.80 |\n",
      "|  | Synthetic | 13.39 | 10.12 | 24.62 | 8.51 | 13.55 | 7.90 | 6.32 | 3.34 | 2.53 | 2.61 | 4.89 |\n",
      "| FMoW-WILDS | Natural | 5.53 | 4.31 | 33.53 | 12.84 | 5.94 | 4.45 | 5.74 | 3.06 | 2.70 | 3.02 | 2.72 |\n",
      "| RxRx1-WILDS | Natural | 5.80 | 5.72 | 7.90 | 4.84 | 5.98 | 5.98 | 6.03 | 4.66 | 4.56 | 4.41 | 4.47 |\n",
      "| Amazon-WILDS | Natural | 2.40 | 2.29 | 8.01 | 2.38 | 2.40 | 2.28 | 17.87 | 1.65 | 1.62 | 1.60 | 1.59 |\n",
      "| CivilCom.-WILDS | Natural | 12.64 | 10.80 | 16.76 | 11.03 | 13.31 | 10.99 | 16.65 |  |  | 7.14 |  |\n",
      "| MNIST | Natural | 18.48 | 15.99 | 21.17 | 14.81 | 20.19 | 14.56 | 24.42 | 5.02 | 2.40 | 3.14 | 3.50 |\n",
      "| EnTITY-13 | Same | 16.23 | 11.14 | 24.97 | 10.88 | 19.08 | 10.47 | 10.71 | 5.39 | 3.88 | 4.58 | 4.19 |\n",
      "|  | Novel | 28.53 | 22.02 | 38.33 | 21.64 | 32.43 | 21.22 | 20.61 | 13.58 | 10.28 | 12.25 | 6.63 |\n",
      "| EnTITY-30 | Same | 18.59 | 14.46 | 28.82 | 14.30 | 21.63 | 13.46 | 12.92 | 9.12 | 7.75 | 8.15 | 7.64 |\n",
      "|  | Novel | 32.34 | 26.85 | 44.02 | 26.27 | 36.82 | 25.42 | 23.16 | 17.75 | 14.30 | 15.60 | 10.57 |\n",
      "| NonLIVING-26 | Same | 18.66 | 17.17 | 26.39 | 16.14 | 19.86 | 15.58 | 16.63 | 10.87 | 10.24 | 10.07 | 10.26 |\n",
      "|  | Novel | 33.43 | 31.53 | 41.66 | 29.87 | 35.13 | 29.31 | 29.56 | 21.70 | 20.12 | 19.08 | 18.26 |\n",
      "| LIVING-17 | Same | 12.63 | 11.05 | 18.32 | 10.46 | 14.43 | 10.14 | 9.87 | 4.57 | 3.95 | 3.81 | 4.21 |\n",
      "|  | Novel | 29.03 | 26.96 | 35.67 | 26.11 | 31.73 | 25.73 | 23.53 | 16.15 | 14.49 | 12.97 | 11.39 |\n",
      "\n",
      "Table 1: Mean Absolute estimation Error (MAE) results for different datasets in our setup grouped by the nature of shift. 'Same' refers to same subpopulation shifts and 'Novel' refers novel subpopulation shifts. We include details about the target sets considered in each shift in Table 2. Post T denotes use of TS calibration on source. Across all datasets, we observe that ATC achieves superior performance (lower MAE is better). For language datasets, we use DistilBERT-base-uncased, for vision dataset we report results with DenseNet model with the exception of MNIST where we use FCN. We include results on other architectures in App. H. For GDE post T and pre T estimates match since TS doesn't alter the argmax prediction. Results reported by aggregating MAE numbers over 4 different seeds. We include results with standard deviation values in Table 3.\n",
      "\n",
      "Average Confidence (AC). Error is estimated as the expected value of the maximum softmax confidence on the target data, i.e, $\\mathrm{AC}_{\\mathcal{D}^{\\mathrm{T}}}=\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{T}}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]$.\n",
      "Difference Of Confidence (DOC). We estimate error on target by subtracting difference of confidences on source and target (as a surrogate to distributional distance Guillory et al. (2021)) from the error on source distribution, i.e, $\\operatorname{DOC}_{\\mathcal{D}^{\\mathrm{T}}}=\\mathbb{E}_{x \\sim \\mathcal{D}^{0}}\\left[\\mathbb{I}\\left[\\arg \\max _{j \\in \\mathcal{Y}} f_{j}(x) \\neq y\\right]\\right]+\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{T}}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]-$ $\\mathbb{E}_{x \\sim \\mathcal{D}^{0}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]$. This is referred to as DOC-Feat in (Guillory et al., 2021).\n",
      "\n",
      "Importance re-weighting (IM). We estimate the error of the classifier with importance re-weighting of 0-1 error in the pushforward space of the classifier. This corresponds to MANDOLIN using one slice based on the underlying classifier confidence Chen et al. (2021b).\n",
      "\n",
      "Generalized Disagreement Equality (GDE). Error is estimated as the expected disagreement of two models (trained on the same training set but with different randomization) on target data (Jiang et al., 2021), i.e., $\\operatorname{GDE}_{\\mathcal{D}^{\\mathrm{T}}}=\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{T}}}\\left[\\mathbb{I}\\left[f(x) \\neq f^{\\prime}(x)\\right]\\right]$ where $f$ and $f^{\\prime}$ are the two models. Note that GDE requires two models trained independently, doubling the computational overhead while training.\n",
      "\n",
      "# 5.1 RESULTS \n",
      "\n",
      "In Table 1, we report MAE results aggregated by the nature of the shift in our testbed. In Fig. 2 and Fig. 1(right), we show scatter plots for predicted accuracy versus OOD accuracy on several datasets. We include scatter plots for all datasets and parallel results with other architectures in App. H. In App. H.1, we also perform ablations on CIFAR using a pre-trained model and observe that pre-training doesn't change the efficacy of ATC.\n",
      "\n",
      "![img-2.jpeg](images/img-2.jpeg)\n",
      "\n",
      "Figure 3: Left: Predicted accuracy with DOC on Living17 BREEDS dataset. We observe a substantial gap in the linear fit of same and different subpopulations highlighting poor correlation. Middle: After fitting a robust linear model for DOC on same subpopulation, we show predicted accuracy on different subpopulations with fine-tuned DOC (i.e., DOC (w/ fit)) and compare with ATC without any regression model, i.e., ATC (w/o fit). While observe substantial improvements in MAE from 24.41 with DOC (w/o fit) to 13.26 with DOC (w/ fit), ATC (w/o fit) continues to outperform even DOC (w/ fit) with MAE 10.22. We show parallel results with other BREEDS datasets in App. H.2. Right : Empirical validation of our toy model. We show that ATC perfectly estimates target performance as we vary the degree of spurious correlation in target. ' $\\times$ ' represents accuracy on source.\n",
      "\n",
      "We predict accuracy on the target data before and after calibration with TS. First, we observe that both ATC-NE and ATC-MC (even without TS) obtain significantly lower MAE when compared with other methods (even with TS). Note that with TS we observe substantial improvements in MAE for all methods. Overall, ATC-NE (with TS) typically achieves the smallest MAE improving by more than $2 \\times$ on CIFAR and by $3-4 \\times$ on ImageNet over GDE (the next best alternative to ATC). Alongside, we also observe that a linear fit with robust regression (Siegel, 1982) on the scatter plot recovers a line close to $x=y$ for ATC-NE with TS while the line is far away from $x=y$ for other methods (Fig. 2 and Fig. 1(right)). Remarkably, MAE is in the range of $0.4-5.8$ with ATC for CIFAR, ImageNet, MNIST, and Wilds. However, MAE is much higher on BREEDS benchmark with novel subpopulations. While we observe a small MAE (i.e., comparable to our observations on other datasets) on BREEDS with natural and synthetic shifts from the same sub-population, MAE on shifts with novel population is significantly higher with all methods. Note that even on novel populations, ATC continues to dominate all other methods across all datasets in BREEDS.\n",
      "\n",
      "Additionally, for different subpopulations in BREEDS setup, we observe a poor linear correlation of the estimated performance with the actual performance as shown in Fig. 3 (left)(we notice a similar gap in the linear fit for all other methods). Hence in such a setting, we would expect methods that fine-tune a regression model on labeled target examples from shifts with one subpopulation will perform poorly on shifts with different subpopulations. Corroborating this intuition, next, we show that even after fitting a regression model for DOC on natural and synthetic shifts with source subpopulations, ATC without regression model continues to outperform DOC with regression model on shifts with novel subpopulation.\n",
      "\n",
      "Fitting a regression model on BREEDS with DOC. Using label target data from natural and synthetic shifts for the same subpopulation (same as source), we fit a robust linear regression model (Siegel, 1982) to fine-tune DOC as in Guillory et al. (2021). We then evaluate the fine-tuned DOC (i.e., DOC with linear model) on natural and synthetic shifts from novel subpopulations on BREEDS benchmark. Although we observe significant improvements in the performance of finetuned DOC when compared with DOC (without any fine-tuning), ATC without any regression model continues to perform better (or similar) to that of fine-tuned DOC on novel subpopulations (Fig. 3 (middle)). Refer to App. H. 2 for details and Table 5 for MAE on BREEDS with regression model.\n",
      "\n",
      "# 6 Investigating ATC on Toy Model \n",
      "\n",
      "In this section, we propose and analyze a simple theoretical model that distills empirical phenomena from the previous section and highlights efficacy of ATC. Here, our aim is not to obtain a general model that captures complicated real distributions on high dimensional input space as the images in ImageNet. Instead to further our understanding, we focus on an easy-to-learn binary classification task from Nagarajan et al. (2020) with linear classifiers, that is rich enough to exhibit some of the same phenomena as with deep networks on real data distributions.\n",
      "\n",
      "Consider a easy-to-learn binary classification problem with two features $x=\\left[x_{\\text {inv }}, x_{\\text {sp }}\\right] \\in \\mathbb{R}^{2}$ where $x_{\\text {inv }}$ is fully predictive invariant feature with a margin $\\gamma>0$ and $x_{\\text {sp }} \\in\\{-1,1\\}$ is a spurious feature (i.e., a feature that is correlated but not predictive of the true label). Conditional on $y$, the distribution over $x_{\\text {inv }}$ is given as follows: $x_{\\text {inv }}|(y=1) \\sim U[\\gamma, c]$ and $x_{\\text {inv }}|(y=0) \\sim U[-c,-\\gamma]$, where $c$ is a fixed constant greater than $\\gamma$. For simplicity, we assume that label distribution on source is uniform on $\\{-1,1\\} . x_{\\text {sp }}$ is distributed such that $P_{s}\\left[x_{\\text {sp }} \\cdot(2 y-1)>0\\right]=p_{\\text {sp }}$, where $p_{\\text {sp }} \\in(0.5,1.0)$ controls the degree of spurious correlation. To model distribution shift, we simulate target data with different degree of spurious correlation, i.e., in target distribution $P_{t}\\left[x_{\\text {sp }} \\cdot(2 y-1)>0\\right]=p_{\\text {sp }}^{\\prime} \\in[0,1]$. Note that here we do not consider shifts in the label distribution but our result extends to arbitrary shifts in the label distribution as well.\n",
      "\n",
      "In this setup, we examine linear sigmoid classifiers of the form $f(x)=\\left[\\frac{1}{1+e^{w^{T} x}}, \\frac{e^{w^{T} x}}{1+e^{w^{T} x}}\\right]$ where $w=\\left[w_{\\text {inv }}, w_{\\text {sp }}\\right] \\in \\mathbb{R}^{2}$. While there exists a linear classifier with $w=[1,0]$ that correctly classifies all the points with a margin $\\gamma$, Nagarajan et al. (2020) demonstrated that a linear classifier will typically have a dependency on the spurious feature, i.e., $w_{\\text {sp }} \\neq 0$. They show that due to geometric skews, despite having positive dependencies on the invariant feature, a max-margin classifier trained on finite samples relies on the spurious feature. Refer to App. D for more details on these skews. In our work, we show that given a linear classifier that relies on the spurious feature and achieves a non-trivial performance on the source (i.e., $w_{\\text {inv }}>0$ ), ATC with maximum confidence score function consistently estimates the accuracy on the target distribution.\n",
      "Theorem 1 (Informal). Given any classifier with $w_{\\text {inv }}>0$ in the above setting, the threshold obtained in (1) together with ATC as in (2) with maximum confidence score function obtains a consistent estimate of the target accuracy.\n",
      "\n",
      "Consider a classifier that depends positively on the spurious feature (i.e., $w_{\\text {sp }}>0$ ). Then as the spurious correlation decreases in the target data, the classifier accuracy on the target will drop and vice-versa if the spurious correlation increases on the target data. Theorem 1 shows that the threshold identified with ATC as in (1) remains invariant as the distribution shifts and hence ATC as in (2) will correctly estimate the accuracy with shifting distributions. Next, we illustrate Theorem 1 by simulating the setup empirically. First we pick a arbitrary classifier (which can also be obtained by training on source samples), tune the threshold on hold-out source examples and predict accuracy with different methods as we shift the distribution by varying the degree of spurious correlation.\n",
      "\n",
      "Empirical validation and comparison with other methods. Fig. 3(right) shows that as the degree of spurious correlation varies, our method accurately estimates the target performance where all other methods fail to accurately estimate the target performance. Understandably, due to poor calibration of the sigmoid linear classifier AC, DOC and GDE fail. While in principle IM can perfectly estimate the accuracy on target in this case, we observe that it is highly sensitive to the number bins and choice of histogram binning (i.e., uniform mass or equal width binning). We elaborate more on this in App. D.\n",
      "\n",
      "Biased estimation with ATC. Now we discuss changes in the above setup where ATC yields inconsistent estimates. We assumed that both in source and target $x_{\\text {inv }}|y=1$ is uniform between $[\\gamma, c]$ and $x \\mid y=-1$ is uniform between $[-c,-\\gamma]$. Shifting the support of target class conditional $p_{t}\\left(x_{\\text {inv }} \\mid y\\right)$ may introduce a bias in ATC estimates, e.g., shrinking the support to $c_{1}(<c)$ (while maintaining uniform distribution) in the target will lead to an over-estimation of the target performance with ATC. In App. D.1, we elaborate on this failure and present a general (but less interpretable) classifier dependent distribution shift condition where ATC is guaranteed to yield consistent estimates.\n",
      "\n",
      "# 7 CONCLUSION AND FUTURE WORK \n",
      "\n",
      "In this work, we proposed ATC, a simple method for estimating target domain accuracy based on unlabeled target (and labeled source data). ATC achieves remarkably low estimation error on several synthetic and natural shift benchmarks in our experiments. Notably, our work draws inspiration from recent state-of-the-art methods that use softmax confidences below a certain threshold for OOD detection (Hendrycks \\& Gimpel, 2016; Hendrycks et al., 2019) and takes a step forward in answering questions raised in Deng \\& Zheng (2021) about the practicality of threshold based methods.\n",
      "Our distribution shift toy model justifies ATC on an easy-to-learn binary classification task. In our experiments, we also observe that calibration significantly improves estimation with ATC. Since in binary classification, post hoc calibration with TS does not change the effective threshold, in future work, we hope to extend our theoretical model to multi-class classification to understand the efficacy\n",
      "\n",
      "of calibration. Our theory establishes that a classifier's accuracy is not, in general identified, from labeled source and unlabeled target data alone, absent considerable additional constraints on the target conditional $p_{t}(y \\mid x)$. In light of this finding, we also hope to extend our understanding beyond the simple theoretical toy model to characterize broader sets of conditions under which ATC might be guaranteed to obtain consistent estimates. Finally, we should note that while ATC outperforms previous approaches, it still suffers from large estimation error on datasets with novel populations, e.g., BreEDS. We hope that our findings can lay the groundwork for future work for improving accuracy estimation on such datasets.\n",
      "\n",
      "Reproducibility Statement Our code to reproduce all the results is available at https:// github.com/saurabhgarg1996/ATC_code. We have been careful to ensure that our results are reproducible. We have stored all models and logged all hyperparameters and seeds to facilitate reproducibility. Note that throughout our work, we do not perform any hyperparameter tuning, instead, using benchmarked hyperparameters and training procedures to make our results easy to reproduce. While, we have not released code yet, the appendix provides all the necessary details to replicate our experiments and results.\n",
      "\n",
      "# ACKNOWLEDGEMENT \n",
      "\n",
      "Authors would like to thank Ariel Kleiner and Sammy Jerome as the problem formulation and motivation of this paper was highly influenced by initial discussions with them.\n",
      "\n",
      "## REFERENCES\n",
      "\n",
      "Amr Alexandari, Anshul Kundaje, and Avanti Shrikumar. Adapting to label shift with bias-corrected calibration. In arXiv preprint arXiv:1901.06852, 2019.\n",
      "\n",
      "Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar. Regularized learning for domain adaptation under label shifts. In International Conference on Learning Representations (ICLR), 2019.\n",
      "\n",
      "Peter L Bartlett, Dylan J Foster, and Matus J Telgarsky. Spectrally-normalized margin bounds for neural networks. In Advances in neural information processing systems, pp. 6240-6249, 2017.\n",
      "\n",
      "Shai Ben-David, Tyler Lu, Teresa Luu, and D√°vid P√°l. Impossibility Theorems for Domain Adaptation. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2010.\n",
      "\n",
      "Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced metrics for measuring unintended bias with real data for text classification. In Companion Proceedings of The 2019 World Wide Web Conference, 2019.\n",
      "\n",
      "Jiefeng Chen, Frederick Liu, Besim Avci, Xi Wu, Yingyu Liang, and Somesh Jha. Detecting errors and estimating accuracy on unlabeled data with self-training ensembles. Advances in Neural Information Processing Systems, 34:14980-14992, 2021a.\n",
      "\n",
      "Mayee Chen, Karan Goel, Nimit S Sohoni, Fait Poms, Kayvon Fatahalian, and Christopher R√©. Mandoline: Model evaluation under distribution shift. In International Conference on Machine Learning, pp. 1617-1629. PMLR, 2021b.\n",
      "\n",
      "Gordon Christie, Neil Fendley, James Wilson, and Ryan Mukherjee. Functional map of the world. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018.\n",
      "\n",
      "Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka. Estimating generalization under distribution shifts via domain-invariant representations. arXiv preprint arXiv:2007.03511, 2020.\n",
      "\n",
      "Weijian Deng and Liang Zheng. Are labels always necessary for classifier accuracy evaluation? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. $15069-15078,2021$.\n",
      "\n",
      "Weijian Deng, Stephen Gould, and Liang Zheng. What does rotation prediction tell us about classifier accuracy under varying testing environments? arXiv preprint arXiv:2106.05961, 2021.\n",
      "\n",
      "Gintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. arXiv preprint arXiv:1703.11008, 2017.\n",
      "\n",
      "Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, and Zachary C Lipton. A unified view of label shift estimation. arXiv preprint arXiv:2003.07554, 2020.\n",
      "\n",
      "Saurabh Garg, Sivaraman Balakrishnan, J Zico Kolter, and Zachary C Lipton. Ratt: Leveraging unlabeled data to guarantee generalization. arXiv preprint arXiv:2105.00303, 2021.\n",
      "\n",
      "Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. arXiv preprint arXiv:1705.08500, 2017.\n",
      "\n",
      "Devin Guillory, Vaishaal Shankar, Sayna Ebrahimi, Trevor Darrell, and Ludwig Schmidt. Predicting with confidence on unseen distributions. arXiv preprint arXiv:2107.03315, 2021.\n",
      "\n",
      "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning (ICML), 2017.\n",
      "\n",
      "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. In Computer Vision and Pattern Recognition (CVPR), 2016.\n",
      "\n",
      "James J Heckman. Sample Selection Bias as a Specification Error (With an Application to the Estimation of Labor Supply Functions), 1977.\n",
      "\n",
      "Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.\n",
      "\n",
      "Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\n",
      "\n",
      "Dan Hendrycks, Steven Basart, Mantas Mazeika, Mohammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. Scaling out-of-distribution detection for real-world settings. arXiv preprint arXiv:1911.11132, 2019.\n",
      "\n",
      "Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. ICCV, 2021.\n",
      "\n",
      "Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700-4708, 2017.\n",
      "\n",
      "Jonathan J. Hull. A database for handwritten text recognition research. IEEE Transactions on pattern analysis and machine intelligence, 16(5):550-554, 1994.\n",
      "\n",
      "Xu Ji, Razvan Pascanu, Devon Hjelm, Andrea Vedaldi, Balaji Lakshminarayanan, and Yoshua Bengio. Predicting unreliable predictions by shattering a neural network. arXiv preprint arXiv:2106.08365, 2021.\n",
      "\n",
      "Heinrich Jiang, Been Kim, Melody Y Guan, and Maya R Gupta. To trust or not to trust a classifier. In NeurIPS, pp. 5546-5557, 2018.\n",
      "\n",
      "Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, and J Zico Kolter. Assessing generalization of sgd via disagreement. arXiv preprint arXiv:2106.13799, 2021.\n",
      "\n",
      "Diederik P Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv Preprint arXiv:1412.6980, 2014.\n",
      "\n",
      "Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton A. Earnshaw, Imran S. Haque, Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. WILDS: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning (ICML), 2021.\n",
      "\n",
      "Alex Krizhevsky and Geoffrey Hinton. Learning Multiple Layers of Features from Tiny Images. Technical report, Citeseer, 2009.\n",
      "\n",
      "Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016.\n",
      "\n",
      "Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 1998.\n",
      "\n",
      "Shiyu Liang, Yixuan Li, and Rayadurgam Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. arXiv preprint arXiv:1706.02690, 2017.\n",
      "\n",
      "Zachary C Lipton, Yu-Xiang Wang, and Alex Smola. Detecting and Correcting for Label Shift with Black Box Predictors. In International Conference on Machine Learning (ICML), 2018.\n",
      "\n",
      "Philip M Long and Hanie Sedghi. Generalization bounds for deep convolutional neural networks. arXiv preprint arXiv:1905.12600, 2019.\n",
      "\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.\n",
      "\n",
      "Vaishnavh Nagarajan and J Zico Kolter. Deterministic pac-bayesian generalization bounds for deep networks via generalizing noise-resilience. arXiv preprint arXiv:1905.13344, 2019a.\n",
      "\n",
      "Vaishnavh Nagarajan and J Zico Kolter. Uniform convergence may be unable to explain generalization in deep learning. In Advances in Neural Information Processing Systems, pp. 11615-11626, 2019b.\n",
      "\n",
      "Vaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur. Understanding the failure modes of out-of-distribution generalization. arXiv preprint arXiv:2010.15775, 2020.\n",
      "\n",
      "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In Advances in Neural Information Processing Systems (NIPS), 2011.\n",
      "\n",
      "Behnam Neyshabur. Implicit regularization in deep learning. arXiv preprint arXiv:1709.01953, 2017.\n",
      "Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. Norm-based capacity control in neural networks. In Conference on Learning Theory, pp. 1376-1401, 2015.\n",
      "\n",
      "Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. Exploring generalization in deep learning. arXiv preprint arXiv:1706.08947, 2017.\n",
      "\n",
      "Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, and Nathan Srebro. The role of over-parametrization in generalization of neural networks. In International Conference on Learning Representations, 2018.\n",
      "\n",
      "Jianmo Ni, Jiacheng Li, and Julian McAuley. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019.\n",
      "\n",
      "Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua V Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift. arXiv preprint arXiv:1906.02530, 2019.\n",
      "\n",
      "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems 32, 2019.\n",
      "\n",
      "Emmanouil A Platanios, Hoifung Poon, Tom M Mitchell, and Eric Horvitz. Estimating accuracy from unlabeled data: A probabilistic logic approach. arXiv preprint arXiv:1705.07086, 2017.\n",
      "\n",
      "Emmanouil Antonios Platanios, Avinava Dubey, and Tom Mitchell. Estimating accuracy from unlabeled data: A bayesian approach. In International Conference on Machine Learning, pp. 1416-1425. PMLR, 2016.\n",
      "\n",
      "Stephan Rabanser, Stephan G√ºnnemann, and Zachary C Lipton. Failing loudly: An empirical study of methods for detecting dataset shift. arXiv preprint arXiv:1810.11953, 2018.\n",
      "\n",
      "Aaditya Ramdas, Sashank Jakkam Reddi, Barnab√°s P√≥czos, Aarti Singh, and Larry A Wasserman. On the Decreasing Power of Kernel and Distance Based Nonparametric Hypothesis Tests in High Dimensions. In Association for the Advancement of Artificial Intelligence (AAAI), 2015.\n",
      "\n",
      "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do cifar-10 classifiers generalize to cifar-10? arXiv preprint arXiv:1806.00451, 2018.\n",
      "\n",
      "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International Conference on Machine Learning, pp. 5389-5400. PMLR, 2019.\n",
      "\n",
      "Mateo Rojas-Carulla, Bernhard Sch√∂lkopf, Richard Turner, and Jonas Peters. Invariant models for causal transfer learning. The Journal of Machine Learning Research, 19(1):1309-1342, 2018.\n",
      "\n",
      "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):211-252, 2015.\n",
      "\n",
      "Marco Saerens, Patrice Latinne, and Christine Decaestecker. Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure. Neural Computation, 2002.\n",
      "\n",
      "Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. ArXiv, abs/1910.01108, 2019.\n",
      "\n",
      "Shibani Santurkar, Dimitris Tsipras, and Aleksander Madry. Breeds: Benchmarks for subpopulation shift. arXiv preprint arXiv:2008.04859, 2020.\n",
      "\n",
      "Hidetoshi Shimodaira. Improving Predictive Inference Under Covariate Shift by Weighting the Log-Likelihood Function. Journal of Statistical Planning and Inference, 2000.\n",
      "\n",
      "Andrew F Siegel. Robust regression using repeated medians. Biometrika, 69(1):242-244, 1982.\n",
      "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing Properties of Neural Networks. In International Conference on Learning Representations (ICLR), 2014.\n",
      "\n",
      "Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey J Gordon. Domain adaptation with conditional distribution matching and generalized label shift. Advances in Neural Information Processing Systems, 33, 2020.\n",
      "J. Taylor, B. Earnshaw, B. Mabey, M. Victors, and J. Yosinski. Rxrx1: An image set for cellular morphological variation across many experimental batches. In International Conference on Learning Representations (ICLR), 2019.\n",
      "\n",
      "Antonio Torralba, Rob Fergus, and William T. Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 30(11):1958-1970, 2008.\n",
      "\n",
      "Haohan Wang, Songwei Ge, Zachary Lipton, and Eric P Xing. Learning robust global representations by penalizing local predictive power. In Advances in Neural Information Processing Systems, pp. $10506-10518,2019$.\n",
      "\n",
      "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R√©mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38-45. Association for Computational Linguistics, 2020.\n",
      "\n",
      "Chhavi Yadav and L√©on Bottou. Cold case: The lost mnist digits. In Advances in Neural Information Processing Systems 32, 2019.\n",
      "\n",
      "Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.\n",
      "\n",
      "Hongjie Zhang, Ang Li, Jie Guo, and Yanwen Guo. Hybrid models for open set recognition. In European Conference on Computer Vision, pp. 102-117. Springer, 2020.\n",
      "\n",
      "Kun Zhang, Bernhard Sch√∂lkopf, Krikamol Muandet, and Zhikun Wang. Domain Adaptation Under Target and Conditional Shift. In International Conference on Machine Learning (ICML), 2013.\n",
      "\n",
      "Wenda Zhou, Victor Veitch, Morgane Austern, Ryan P Adams, and Peter Orbanz. Non-vacuous generalization bounds at the imagenet scale: a pac-bayesian compression approach. arXiv preprint arXiv:1804.05862, 2018.\n",
      "\n",
      "# APPENDIX \n",
      "\n",
      "## A Proofs from Sec. 3\n",
      "\n",
      "Before proving results from Sec. 3, we introduce some notations. Define $\\mathcal{E}(f(x), y):=$ $\\mathbb{I}\\left[y \\notin \\arg \\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]$. We express the population error on distribution $\\mathcal{D}$ as $\\mathcal{E}_{\\mathcal{D}}(f):=$ $\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}[\\mathcal{E}(f(x), y)]$.\n",
      "\n",
      "Proof of Proposition 1. Consider a binary classification problem. Assume $\\mathcal{P}$ be the set of possible target conditional distribution of labels given $p_{s}(x, y)$ and $p_{t}(x)$.\n",
      "The forward direction is simple. If $\\mathcal{P}=\\left\\{p_{t}(y \\mid x)\\right\\}$ is singleton given $p_{s}(x, y)$ and $p_{t}(x)$, then the error of any classifier $f$ on the target domain is identified and is given by\n",
      "\n",
      "$$\n",
      "\\mathcal{E}_{\\mathcal{D}^{T}}(f)=\\mathbb{E}_{x \\sim p_{t}(x), y \\sim p_{t}(y \\mid x)}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\n",
      "$$\n",
      "\n",
      "For the reverse direction assume that given $p_{t}(x)$ and $p_{s}(x, y)$, we have two possible distributions $\\mathcal{D}^{T}$ and $\\mathcal{D}^{T^{\\prime}}$ with $p_{t}(y \\mid x), p_{t}^{\\prime}(y \\mid x) \\in \\mathcal{P}$ such that on some $x$ with $p_{t}(x)>0$, we have $p_{t}(y \\mid x) \\neq p_{t}^{\\prime}(y \\mid x)$. Consider $\\mathcal{X}_{M}=\\left\\{x \\in \\mathcal{X} \\mid p_{t}(x)>0\\right.$ and $\\left.p_{t}(y=1 \\mid x) \\neq p_{t}^{\\prime}(y=1 \\mid x)\\right\\}$ be the set of all input covariates where the two distributions differ. We will now choose a classifier $f$ such that the error on the two distributions differ. On a subset $\\mathcal{X}_{M}^{1}=\\left\\{x \\in \\mathcal{X} \\mid p_{t}(x)>0\\right.$ and $\\left.p_{t}(y=1 \\mid x)>p_{t}^{\\prime}(y=1 \\mid x)\\right\\}$, assume $f(x)=0$ and on a subset $\\mathcal{X}_{M}^{2}=\\left\\{x \\in \\mathcal{X} \\mid p_{t}(x)>0\\right.$ and $\\left.p_{t}(y=1 \\mid x)<p_{t}^{\\prime}(y=1 \\mid x)\\right\\}$, assume $f(x)=1$. We will show that the error of $f$ on distribution with $p_{t}(y \\mid x)$ is strictly greater than the error of $f$ on distribution with $p_{t}^{\\prime}(y \\mid x)$. Formally,\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "& \\mathcal{E}_{\\mathcal{D}^{T}}(f)-\\mathcal{E}_{\\mathcal{D}^{T^{\\prime}}}(f) \\\\\n",
      "& =\\mathbb{E}_{x \\sim p_{t}(x), y \\sim p_{t}(y \\mid x)}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]-\\mathbb{E}_{x \\sim p_{t}(x), y \\sim p_{t}^{\\prime}(y \\mid x)}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right] \\\\\n",
      "& =\\int_{x \\in \\mathcal{X}_{M}} \\mathbb{I}[f(x) \\neq 0]\\left(p_{t}(y=0 \\mid x)-p_{t}^{\\prime}(y=0 \\mid x)\\right) p_{t}(x) d x \\\\\n",
      "& +\\int_{x \\in \\mathcal{X}_{M}} \\mathbb{I}[f(x) \\neq 1]\\left(p_{t}(y=1 \\mid x)-p_{t}^{\\prime}(y=1 \\mid x)\\right) p_{t}(x) d x \\\\\n",
      "& =\\int_{x \\in \\mathcal{X}_{M}^{2}}\\left(p_{t}(y=0 \\mid x)-p_{t}^{\\prime}(y=0 \\mid x)\\right) p_{t}(x) d x+\\int_{x \\in \\mathcal{X}_{M}^{1}}\\left(p_{t}(y=1 \\mid x)-p_{t}^{\\prime}(y=1 \\mid x)\\right) p_{t}(x) d x \\\\\n",
      "& >0,\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "where the last step follows by construction of the set $\\mathcal{X}_{M}^{1}$ and $\\mathcal{X}_{M}^{2}$. Since $\\mathcal{E}_{\\mathcal{D}^{T}}(f) \\neq \\mathcal{E}_{\\mathcal{D}^{T^{\\prime}}}(f)$, given the information of $p_{t}(x)$ and $p_{s}(x, y)$ it is impossible to distinguish the two values of the error with classifier $f$. Thus, we obtain a contradiction on the assumption that $p_{t}(y \\mid x) \\neq p_{t}^{\\prime}(y \\mid x)$. Hence, we must pose restrictions on the nature of shift such that $\\mathcal{P}$ is singleton to to identify accuracy on the target.\n",
      "\n",
      "Proof of Corollary 1. The corollary follows directly from Proposition 1. Since two different target conditional distribution can lead to different error estimates without assumptions on the classifier, no method can estimate two different quantities from the same given information. We illustrate this in Example 1 next.\n",
      "\n",
      "## B ESTIMATING ACCURACY IN COVARIATE SHIFT OR LABEL SHIFT\n",
      "\n",
      "Accuracy estimation under covariate shift assumption Under the assumption that $p_{t}(y \\mid x)=$ $p_{s}(y \\mid x)$, accuracy on the target domain can be estimated as follows:\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\mathcal{E}_{\\mathcal{D}^{t}}(f) & =\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\frac{p_{t}(x, y)}{p_{s}(x, y)} \\mathbb{I}[f(x) \\neq y]\\right] \\\\\n",
      "& =\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq y]\\right]\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "Given access to $p_{t}(x)$ and $p_{s}(x)$, one can directly estimate the expression in (6).\n",
      "Accuracy estimation under label shift assumption Under the assumption that $p_{t}(x \\mid y)=p_{s}(x \\mid y)$, accuracy on the target domain can be estimated as follows:\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\mathcal{E}_{\\mathcal{D}^{t}}(f) & =\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\frac{p_{t}(x, y)}{p_{s}(x, y)} \\mathbb{I}[f(x) \\neq y]\\right] \\\\\n",
      "& =\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\frac{p_{t}(y)}{p_{s}(y)} \\mathbb{I}[f(x) \\neq y]\\right]\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "Estimating importance ratios $p_{t}(x) / p_{s}(x)$ is straightforward under covariate shift assumption when the distributions $p_{t}(x)$ and $p_{s}(x)$ are known. For label shift, one can leverage moment matching approach called BBSE (Lipton et al., 2018) or likelihood minimization approach MLLS (Garg et al., 2020). Below we discuss the objective of MLLS:\n",
      "\n",
      "$$\n",
      "w=\\underset{w \\in \\mathcal{W}}{\\arg \\max } \\mathbb{E}_{x \\sim p_{t}(x)}\\left[\\log p_{s}(y \\mid x)^{T} w\\right]\n",
      "$$\n",
      "\n",
      "where $\\mathcal{W}=\\left\\{w \\mid \\forall y, w_{y} \\geqslant 0\\right.$ and $\\sum_{y=1}^{k} w_{y} p_{s}(y)=1\\}$. MLLS objective is guaranteed to obtain consistent estimates for the importance ratios $w^{*}(y)=p_{t}(y) / p_{s}(y)$ under the following condition.\n",
      "Theorem 2 (Theorem 1 (Garg et al., 2020)). If the distributions $\\{p(x) \\mid y): y=1, \\ldots, k\\}$ are strictly linearly independent, then $w^{*}$ is the unique maximizer of the MLLS objective (9).\n",
      "\n",
      "We refer interested reader to Garg et al. (2020) for details.\n",
      "Above results of accuracy estimation under label shift and covariate shift can be extended to a generalized label shift and covariate shift settings. Assume a function $h: \\mathcal{X} \\rightarrow \\mathcal{Z}$ such that $y$ is independent of $x$ given $h(x)$. In other words $h(x)$ contains all the information needed to predict label $y$. With help of $h$, we can extend estimation to following settings: (i) Generalized covariate shift, i.e., $p_{s}(y \\mid h(x))=p_{t}(y \\mid h(x))$ and $p_{s}(h(x))>0$ for all $x \\in \\mathcal{X}_{t}$; (ii) Generalized label shift, i.e., $p_{s}(h(x) \\mid y)=p_{t}(h(x) \\mid y)$ and $p_{s}(y)>0$ for all $y \\in \\mathcal{Y}_{t}$. By simply replacing $x$ with $h(x)$ in (6) and (9), we will obtain consistent error estimates under these generalized conditions.\n",
      "\n",
      "Proof of Example 1. Under covariate shift using (6), we get\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\mathcal{E}_{1} & =\\mathbb{E}_{(x, y) \\sim p_{s}(x, y)}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq y]\\right] \\\\\n",
      "& =\\mathbb{E}_{x \\sim p_{s}(x, y=0)}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq 0]\\right]+\\mathbb{E}_{x \\sim p_{s}(x, y=1)}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq 1]\\right] \\\\\n",
      "& =\\int \\mathbb{I}[f(x) \\neq 0] p_{t}(x) p_{s}(y=0 \\mid x) d x+\\int \\mathbb{I}[f(x) \\neq 1] p_{t}(x) p_{s}(y=1 \\mid x) d x\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "Under label shift using (8), we get\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\mathcal{E}_{2} & =\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\frac{p_{t}(y)}{p_{s}(y)} \\mathbb{I}[f(x) \\neq y]\\right] \\\\\n",
      "& =\\mathbb{E}_{x \\sim p_{s}(x, y=0)}\\left[\\frac{\\beta}{\\alpha} \\mathbb{I}[f(x) \\neq 0]\\right]+\\mathbb{E}_{x \\sim p_{s}(x, y=1)}\\left[\\frac{1-\\beta}{1-\\alpha} \\mathbb{I}[f(x) \\neq 1]\\right] \\\\\n",
      "& =\\int \\mathbb{I}[f(x) \\neq 0] \\frac{\\beta}{\\alpha} p_{s}(y=0 \\mid x) p_{s}(x) d x+\\int \\mathbb{I}[f(x) \\neq 1] \\frac{(1-\\beta)}{(1-\\alpha)} p_{s}(y=1 \\mid x) p_{s}(x) d x\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "Then $\\mathcal{E}_{1}-\\mathcal{E}_{2}$ is given by\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\mathcal{E}_{1}-\\mathcal{E}_{2} & =\\int \\mathbb{I}[f(x) \\neq 0] p_{s}(y=0 \\mid x)\\left[p_{t}(x)-\\frac{\\beta}{\\alpha} p_{s}(x)\\right] d x \\\\\n",
      "& +\\int \\mathbb{I}[f(x) \\neq 1] p_{s}(y=1 \\mid x)\\left[p_{t}(x)-\\frac{(1-\\beta)}{(1-\\alpha)} p_{s}(x)\\right] d x \\\\\n",
      "& =\\int \\mathbb{I}[f(x) \\neq 0] p_{s}(y=0 \\mid x) \\frac{(\\alpha-\\beta)}{\\alpha} \\phi\\left(\\mu_{2}\\right) d x \\\\\n",
      "& +\\int \\mathbb{I}[f(x) \\neq 1] p_{s}(y=1 \\mid x) \\frac{(\\alpha-\\beta)}{1-\\alpha} \\phi\\left(\\mu_{1}\\right) d x\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "If $\\alpha>\\beta$, then $\\mathcal{E}_{1}>\\mathcal{E}_{2}$ and if $\\alpha<\\beta$, then $\\mathcal{E}_{1}<\\mathcal{E}_{2}$. Since $\\mathcal{E}_{1} \\neq \\mathcal{E}_{2}$ for arbitrary $f$, given access to $p_{s}(x, y)$, and $p_{t}(x)$, any method that consistently estimates error under covariate shift will give an incorrect estimate under label shift and vice-versa. The reason being that the same $p_{t}(x)$ and $p_{s}(x, y)$ can correspond to error $\\mathcal{E}_{1}$ (under covariate shift) or error $\\mathcal{E}_{2}$ (under label shift) either of which is not discernable absent further assumptions on the nature of shift.\n",
      "\n",
      "# C Alternate interpretation of ATC \n",
      "\n",
      "Consider the following framework: Given a datum $(x, y)$, define a binary classification problem of whether the model prediction $\\arg \\max f(x)$ was correct or incorrect. In particular, if the model prediction matches the true label, then we assign a label 1 (positive) and conversely, if the model prediction doesn't match the true label then we assign a label 0 (negative).\n",
      "\n",
      "Our method can be interpreted as identifying examples for correct and incorrect prediction based on the value of the score function $s(f(x))$, i.e., if the score $s(f(x))$ is greater than or equal to the threshold $t$ then our method predicts that the classifier correctly predicted datum $(x, y)$ and vice-versa if the score is less than $t$. A method that can solve this task will perfectly estimate the target performance. However, such an expectation is unrealistic. Instead, ATC expects that most of the examples with score above threshold are correct and most of the examples below the threshold are incorrect. More importantly, ATC selects a threshold such that the number of falsely identified correct predictions match falsely identified incorrect predictions on source distribution, thereby balancing incorrect predictions. We expect useful estimates of accuracy with ATC if the threshold transfers to target, i.e. if the number of falsely identified correct predictions match falsely identified incorrect predictions on target. This interpretation relates our method to the OOD detection literature where Hendrycks \\& Gimpel (2016); Hendrycks et al. (2019) highlight that classifiers tend to assign higher confidence to in-distribution examples and leverage maximum softmax confidence (or logit) to perform OOD detection.\n",
      "\n",
      "## D Details on the Toy Model\n",
      "\n",
      "Skews observed in this toy model In Fig. 4, we illustrate the toy model used in our empirical experiment. In the same setup, we empirically observe that the margin on population with less density is large, i.e., margin is much greater than $\\gamma$ when the number of observed samples is small (in Fig. 4 (d)). Building on this observation, Nagarajan et al. (2020) showed in cases when margin decreases with number of samples, a max margin classifier trained on finite samples is bound to depend on the spurious features in such cases. They referred to this skew as geometric skew.\n",
      "\n",
      "Moreover, even when the number of samples are large so that we do not observe geometric skews, Nagarajan et al. (2020) showed that training for finite number of epochs, a linear classifier will have a non zero dependency on the spurious feature. They referred to this skew as statistical skew. Due both of these skews, we observe that a linear classifier obtained with training for finite steps on training data with finite samples, will have a non-zero dependency on the spurious feature. We refer interested reader to Nagarajan et al. (2020) for more details.\n",
      "\n",
      "Proof of Theorem 1 Recall, we consider a easy-to-learn binary classification problem with two features $x=\\left[x_{\\text {inv }}, x_{\\text {sp }}\\right] \\in \\mathbb{R}^{2}$ where $x_{\\text {inv }}$ is fully predictive invariant feature with a margin $\\gamma>0$ and $x_{\\text {sp }} \\in\\{-1,1\\}$ is a spurious feature (i.e., a feature that is correlated but not predictive of the true label). Conditional on $y$, the distribution over $x_{\\text {inv }}$ is given as follows:\n",
      "\n",
      "$$\n",
      "x_{\\text {inv }} \\mid y \\sim\\left\\{\\begin{array}{ll}\n",
      "U[\\gamma, c] & y=1 \\\\\n",
      "U[-c,-\\gamma] & y=-1\n",
      "\\end{array}\\right.\n",
      "$$\n",
      "\n",
      "where $c$ is a fixed constant greater than $\\gamma$. For simplicity, we assume that label distribution on source is uniform on $\\{-1,1\\}$. $x_{\\text {sp }}$ is distributed such that $P_{s}\\left[x_{\\text {sp }} \\cdot(2 y-1)>0\\right]=p_{\\text {sp }}$, where $p_{\\text {sp }} \\in(0.5,1.0)$ controls the degree of spurious correlation. To model distribution shift, we simulate target data with different degree of spurious correlation, i.e., in target distribution $P_{t}\\left[x_{\\text {sp }} \\cdot(2 y-1)>0\\right]=p_{\\text {sp }}^{\\prime} \\in[0,1]$. Note that here we do not consider shifts in the label distribution but our result extends to arbitrary shifts in the label distribution as well.\n",
      "\n",
      "![img-3.jpeg](images/img-3.jpeg)\n",
      "\n",
      "Figure 4: Illustration of toy model. (a) Source data at $n=100$. (b) Target data with $p_{\\mathrm{s}}^{\\prime}=0.5$. (b) Target data with $p_{\\mathrm{s}}^{\\prime}=0.9$. (c) Margin of $x_{\\text {inv }}$ in the minority group in source data. As sample size increases the margin saturates to true margin $\\gamma=0.1$.\n",
      "\n",
      "In this setup, we examine linear sigmoid classifiers of the form $f(x)=\\left[\\frac{1}{1+e^{w^{T} x}}, \\frac{e^{w^{T} x}}{1+e^{w^{T} x}}\\right]$ where $w=\\left[w_{\\text {inv }}, w_{\\text {sp }}\\right] \\in \\mathbb{R}^{2}$. We show that given a linear classifier that relies on the spurious feature and achieves a non-trivial performance on the source (i.e., $w_{\\text {inv }}>0$ ), ATC with maximum confidence score function consistently estimates the accuracy on the target distribution. Define $X_{M}=\\left\\{x \\mid x_{\\text {sp }}\\right.$. $\\left.(2 y-1)<0\\right\\}$ and $X_{C}=\\left\\{x \\mid x_{\\text {sp }} \\cdot(2 y-1)>0\\right\\}$. Notice that in target distributions, we are changing the fraction of examples in $X_{M}$ and $X_{C}$ but we are not changing the distribution of examples within individual set.\n",
      "Theorem 3. Given any classifier $f$ with $w_{\\text {inv }}>0$ in the above setting, assume that the threshold $t$ is obtained with finite sample approximation of (1), i.e., $t$ is selected such that ${ }^{2}$\n",
      "\n",
      "$$\n",
      "\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}\\left(x_{i}\\right)<t\\right]\\right]=\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}\\left(x_{i}\\right) \\neq y_{i}\\right]\\right]\n",
      "$$\n",
      "\n",
      "where $\\left\\{\\left(x_{i}, y_{i}\\right)\\right\\}_{i=1}^{n} \\sim\\left(\\mathcal{D}^{\\mathbb{1}}\\right)^{n}$ are $n$ samples from source distribution. Fix a $\\delta>0$. Assuming $n \\geqslant 2 \\log (4 / \\delta) /\\left(1-p_{s p}\\right)^{2}$, then the estimate of accuracy by ATC as in (2) satisfies the following with probability at least $1-\\delta$,\n",
      "\n",
      "$$\n",
      "\\left|\\mathbb{E}_{x \\sim \\mathcal{D}^{T}}[\\mathbb{I}[s(f(x))<t]]-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{T}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (8 / \\delta)}{n \\cdot c_{s p}}}\n",
      "$$\n",
      "\n",
      "where $\\mathcal{D}^{T}$ is any target distribution considered in our setting and $c_{s p}=\\left(1-p_{s p}\\right)$ if $w_{s p}>0$ and $c_{s p}=p_{s p}$ otherwise.\n",
      "\n",
      "[^0]\n",
      "[^0]:    ${ }^{2}$ Note that this is possible because a linear classifier with sigmoid activation assigns a unique score to each point in source distribution.\n",
      "\n",
      "Proof. First we consider the case of $w_{\\text {sp }}>0$. The proof follows in two simple steps. First we notice that the classifier will make an error only on some points in $X_{M}$ and the threshold $t$ will be selected such that the fraction of points in $X_{M}$ with maximum confidence less than the threshold $t$ will match the error of the classifier on $X_{M}$. Classifier with $w_{\\text {sp }}>0$ and $w_{\\text {inv }}>0$ will classify all the points in $X_{C}$ correctly. Second, since the distribution of points is not changing within $X_{M}$ and $X_{C}$, the same threshold continues to work for arbitrary shift in the fraction of examples in $X_{M}$, i.e., $p_{\\text {sp }}^{\\prime}$.\n",
      "\n",
      "Note that when $w_{\\text {sp }}>0$, the classifier makes no error on points in $X_{C}$ and makes an error on a subset $X_{\\text {err }}=\\left\\{x \\mid x_{\\text {sp }} \\cdot(2 y-1)<0 \\&\\left(w_{\\text {inv }} x_{\\text {inv }}+w_{\\text {sp }} x_{\\text {sp }}\\right) \\cdot(2 y-1) \\leqslant 0\\right\\}$ of $X_{M}$, i.e., $X_{\\text {err }} \\subseteq X_{M}$. Consider $X_{\\text {thres }}=\\left\\{x \\mid \\arg \\max _{y \\in \\mathcal{Y}} f_{y}(x) \\leqslant t\\right\\}$ as the set of points that obtain a score less than or equal to $t$. Now we will show that ATC chooses a threshold $t$ such that all points in $X_{C}$ gets a score above $t$, i.e., $X_{\\text {thres }} \\subseteq X_{M}$. First note that the score of points close to the true separator in $X_{C}$, i.e., at $x_{1}=(\\gamma, 1)$ and $x_{2}=(-\\gamma,-1)$ match. In other words, score at $x_{1}$ matches with the score of $x_{2}$ by symmetricity, i.e.,\n",
      "\n",
      "$$\n",
      "\\underset{y \\in \\mathcal{Y}}{\\arg \\max } f_{y}\\left(x_{1}\\right)=\\underset{y \\in \\mathcal{Y}}{\\arg \\max } f_{y}\\left(x_{2}\\right)=\\frac{e^{w_{\\text {inv }} \\gamma+w_{\\text {sp }}}}{\\left(1+e^{w_{\\text {inv }} \\gamma+w_{\\text {sp }}}\\right)}\n",
      "$$\n",
      "\n",
      "Hence, if $t \\geqslant \\arg \\max _{y \\in \\mathcal{Y}} f_{y}\\left(x_{1}\\right)$ then we will have $\\left|X_{\\text {err }}\\right|<\\left|X_{\\text {thres }}\\right|$ which is contradiction violating definition of $t$ as in (12). Thus $X_{\\text {thres }} \\subseteq X_{M}$.\n",
      "\n",
      "Now we will relate LHS and RHS of (12) with their expectations using Hoeffdings and DKW inequality to conclude (13). Using Hoeffdings' bound, we have with probability at least $1-\\delta / 4$\n",
      "\n",
      "$$\n",
      "\\left|\\sum_{i \\in X_{M}} \\frac{\\left[\\mathbb{I}\\left[\\arg \\max _{j \\in \\mathcal{Y}} f_{j}\\left(x_{i}\\right) \\neq y_{i}\\right]\\right]}{\\left|X_{M}\\right|}-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (8 / \\delta)}{2\\left|X_{M}\\right|}}\n",
      "$$\n",
      "\n",
      "With DKW inequality, we have with probability at least $1-\\delta / 4$\n",
      "\n",
      "$$\n",
      "\\left|\\sum_{i \\in X_{M}} \\frac{\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}\\left(x_{i}\\right)<t^{\\prime}\\right]\\right]}{\\left|X_{M}\\right|}-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)<t^{\\prime}\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (8 / \\delta)}{2\\left|X_{M}\\right|}}\n",
      "$$\n",
      "\n",
      "for all $t^{\\prime}>0$. Combining (15) and (16) at $t^{\\prime}=t$ with definition (12), we have with probability at least $1-\\delta / 2$\n",
      "\n",
      "$$\n",
      "\\left|\\mathbb{E}_{x \\sim \\mathcal{D}^{t}}[\\mathbb{I}[s(f(x))<t]]-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (8 / \\delta)}{2\\left|X_{M}\\right|}}\n",
      "$$\n",
      "\n",
      "Now for the case of $w_{\\text {sp }}<0$, we can use the same arguments on $X_{C}$. That is, since now all the error will be on points in $X_{C}$ and classifier will make no error $X_{M}$, we can show that threshold $t$ will be selected such that the fraction of points in $X_{C}$ with maximum confidence less than the threshold $t$ will match the error of the classifier on $X_{C}$. Again, since the distribution of points is not changing within $X_{M}$ and $X_{C}$, the same threshold continues to work for arbitrary shift in the fraction of examples in $X_{M}$, i.e., $p_{\\text {sp }}^{\\prime}$. Thus with similar arguments, we have\n",
      "\n",
      "$$\n",
      "\\left|\\mathbb{E}_{x \\sim \\mathcal{D}^{t}}[\\mathbb{I}[s(f(x))<t]]-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{t}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (8 / \\delta)}{2\\left|X_{C}\\right|}}\n",
      "$$\n",
      "\n",
      "Using Hoeffdings' bound, with probability at least $1-\\delta / 2$, we have\n",
      "\n",
      "$$\n",
      "\\left|X_{M}-n \\cdot\\left(1-p_{\\mathrm{sp}}\\right)\\right| \\leqslant \\sqrt{\\frac{n \\cdot \\log (4 / \\delta)}{2}}\n",
      "$$\n",
      "\n",
      "With probability at least $1-\\delta / 2$, we have\n",
      "\n",
      "$$\n",
      "\\left|X_{C}-n \\cdot p_{\\mathrm{sp}}\\right| \\leqslant \\sqrt{\\frac{n \\cdot \\log (4 / \\delta)}{2}}\n",
      "$$\n",
      "\n",
      "Combining (19) and (17), we get the desired result for $w_{\\text {sp }}>0$. For $w_{\\text {sp }}<0$, we combine (20) and (18) to get the desired result.\n",
      "\n",
      "![img-4.jpeg](images/img-4.jpeg)\n",
      "\n",
      "Figure 5: Failure of ATC in our toy model. Shifting the support of target class conditional $p_{t}\\left(x_{\\text {inv }} \\mid y\\right)$ may introduce a bias in ATC estimates, e.g., shrinking the support to $c_{1}(<c)$ (while maintaining uniform distribution) in the target leads to overestimation bias.\n",
      "\n",
      "Issues with IM in toy setting As described in App. E, we observe that IM is sensitive to binning strategy. In the main paper, we include IM result with uniform mass binning with 100 bins. Empirically, we observe that we recover the true performance with IM if we use equal width binning with number of bins greater than 5 .\n",
      "Biased estimation with ATC in our toy model We assumed that both in source and target $x_{\\text {inv }} \\mid y=1$ is uniform between $[\\gamma, c]$ and $x \\mid y=-1$ is uniform between $[-c,-\\gamma]$. Shifting the support of target class conditional $p_{t}\\left(x_{\\text {inv }} \\mid y\\right)$ may introduce a bias in ATC estimates, e.g., shrinking the support to $c_{1}(<c)$ (while maintaining uniform distribution) in the target will lead to an over-estimation of the target performance with ATC. We show this failure in Fig. 5. The reason being that with the same threshold that we see more examples falsely identified as correct as compared to examples falsely identified as incorrect.\n",
      "\n",
      "# D. 1 A MORE GENERAL RESULT \n",
      "\n",
      "Recall, for a given threshold $t$, we categorize an example $(x, y)$ as a falsely identified correct prediction (ficp) if the predicted label $\\widehat{y}=\\arg \\max f(x)$ is not the same as $y$ but the predicted score $f_{\\widehat{y}}(x)$ is greater than $t$. Similarly, an example is falsely identified incorrect prediction (fiip) if the predicted label $\\widehat{y}$ is the same as $y$ but the predicted score $f_{\\widehat{y}}(x)$ is less than $t$.\n",
      "In general, we believe that our method will obtain consistent estimates in scenarios where the relative distribution of covariates doesn't change among examples that are falsely identified as incorrect and examples that are falsely identified as correct. In other words, ATC is expected to work if the distribution shift is such that falsely identified incorrect predictions match falsely identified correct prediction.\n",
      "\n",
      "## D. 2 ATC PRODUCES CONSISTENT ESTIMATE ON SOURCE DISTRIBUTION\n",
      "\n",
      "Proposition 2. Given labeled validation data $\\left\\{\\left(x_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$ from a distribution $\\mathcal{D}^{S}$ and a model $f$, choose a threshold $t$ as in (1). Then for $\\delta>0$, with probability at least $1-\\delta$, we have\n",
      "\n",
      "$$\n",
      "\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)<t\\right]-\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right] \\leqslant 2 \\sqrt{\\frac{\\log (4 / \\delta)}{2 n}}\n",
      "$$\n",
      "\n",
      "Proof. The proof uses (i) Hoeffdings' inequality to relate the accuracy with expected accuracy; and (ii) DKW inequality to show the concentration of the estimated accuracy with our proposed method. Finally, we combine (i) and (ii) using the fact that at selected threshold $t$ the number of false positives is equal to the number of false negatives.\n",
      "Using Hoeffdings' bound, we have with probability at least $1-\\delta / 2$\n",
      "\n",
      "$$\n",
      "\\left|\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}\\left(x_{i}\\right) \\neq y_{i}\\right]\\right]-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x) \\neq y\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (4 / \\delta)}{2 n}}\n",
      "$$\n",
      "\n",
      "With DKW inequality, we have with probability at least $1-\\delta / 2$\n",
      "\n",
      "$$\n",
      "\\left|\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}\\left(x_{i}\\right)<t^{\\prime}\\right]\\right]-\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)<t^{\\prime}\\right]\\right]\\right| \\leqslant \\sqrt{\\frac{\\log (4 / \\delta)}{2 n}}\n",
      "$$\n",
      "\n",
      "for all $t^{\\prime}>0$. Finally by definition, we have\n",
      "\n",
      "$$\n",
      "\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}\\left(x_{i}\\right)<t^{\\prime}\\right]\\right]=\\sum_{i=1}^{n}\\left[\\mathbb{I}\\left[\\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}\\left(x_{i}\\right) \\neq y_{i}\\right]\\right]\n",
      "$$\n",
      "\n",
      "Combining (22), (23) at $t^{\\prime}=t$, and (24), we have the desired result.\n",
      "\n",
      "# E BASLINE METHODS \n",
      "\n",
      "Importance-re-weighting (IM) If we can estimate the importance-ratios $\\frac{p_{t}(x)}{p_{s}(x)}$ with just the unlabeled data from the target and validation labeled data from source, then we can estimate the accuracy as on target as follows:\n",
      "\n",
      "$$\n",
      "\\mathcal{E}_{\\mathcal{D}^{\\mathrm{T}}}(f)=\\mathbb{E}_{(x, y) \\sim \\mathcal{D}^{\\mathrm{d}}}\\left[\\frac{p_{t}(x)}{p_{s}(x)} \\mathbb{I}[f(x) \\neq y]\\right]\n",
      "$$\n",
      "\n",
      "As previously discussed, this is particularly useful in the setting of covariate shift (within support) where importance ratios estimation has been explored in the literature in the past. Mandolin (Chen et al., 2021b) extends this approach. They estimate importance-weights with use of extra supervision about the axis along which the distribution is shifting.\n",
      "In our work, we experiment with uniform mass binning and equal width binning with the number of bins in $[5,10,50]$. Overall, we observed that equal width binning works the best with 10 bins. Hence throughout this paper we perform equal width binning with 10 bins to include results with IM.\n",
      "Average Confidence (AC) If we expect the classifier to be argmax calibrated on the target then average confidence is equal to accuracy of the classifier. Formally, by definition of argmax calibration of $f$ on any distribution $\\mathcal{D}$, we have\n",
      "\n",
      "$$\n",
      "\\mathcal{E}_{\\mathcal{D}}(f)=\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\mathbb{I}\\left[y \\notin \\underset{j \\in \\mathcal{Y}}{\\arg \\max } f_{j}(x)\\right]\\right]=\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]\n",
      "$$\n",
      "\n",
      "Difference Of Confidence We estimate the error on target by subtracting difference of confidences on source and target (as a distributional distance (Guillory et al., 2021)) from expected error on source distribution, i.e, $\\operatorname{DOC}_{\\mathcal{D}^{\\mathrm{T}}}=\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{d}}}\\left[\\mathbb{I}\\left[\\arg \\max _{j \\in \\mathcal{Y}} f_{j}(x) \\neq y\\right]\\right]+\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{T}}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]-$ $\\mathbb{E}_{x \\sim \\mathcal{D}^{\\mathrm{d}}}\\left[\\max _{j \\in \\mathcal{Y}} f_{j}(x)\\right]$. This is referred to as DOC-Feat in (Guillory et al., 2021).\n",
      "Generalized Disagreement Equality (GDE) Jiang et al. (2021) proposed average disagreement of two models (trained on the same training set but with different initialization and/or different data ordering) as a approximate measure of accuracy on the underlying data, i.e.,\n",
      "\n",
      "$$\n",
      "\\mathcal{E}_{\\mathcal{D}}(f)=\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\mathbb{I}\\left[f(x) \\neq f^{\\prime}(x)\\right]\\right]\n",
      "$$\n",
      "\n",
      "They show that marginal calibration of the model is sufficient to have expected test error equal to the expected of average disagreement of two models where the latter expectation is also taken over the models used to calculate disagreement.\n",
      "\n",
      "## F Details on the Dataset Setup\n",
      "\n",
      "In our empirical evaluation, we consider both natural and synthetic distribution shifts. We consider shifts on ImageNet (Russakovsky et al., 2015), CIFAR Krizhevsky \\& Hinton (2009), FMoWWILDS (Christie et al., 2018), RxRx1-WILDS (Taylor et al., 2019), Amazon-WILDS (Ni et al., 2019), CivilComments-WILDS (Borkan et al., 2019), and MNIST LeCun et al. (1998) datasets.\n",
      "\n",
      "| Train (Source) | Valid (Source) | Evaluation (Target) |\n",
      "| :--: | :--: | :--: |\n",
      "| MNIST (train) | MNIST (valid) | USPS, SVHN and Q-MNIST |\n",
      "| CIFAR10 (train) | CIFAR10 (valid) | CIFAR10v2, 95 CIFAR10-C datasets (Fog and Motion blur, etc. ) |\n",
      "| CIFAR100 (train) | CIFAR100 (valid) | 95 CIFAR100-C datasets (Fog and Motion blur, etc. ) |\n",
      "| FMoW (2002-12) (train) | FMoW (2002-12) (valid) | FMoW $\\{(2013-15,2016-17) \\times$ <br> (All, Africa, Americas, Oceania, Asia, and Europe) $\\}$ |\n",
      "| RxRx1 (train) | RxRx1(id-val) | RxRx1 (id-test, OOD-val, OOD-test) |\n",
      "| Amazon (train) | Amazon (id-val) | Amazon (OOD-val, OOD-test) |\n",
      "| CivilComments (train) | CivilComments (id-val) | CiviComments (8 demographic identities male, female, LGBTQ, Christian, Muslim, other religions, Black, and White) |\n",
      "| ImageNet (train) | ImageNet (valid) | 3 ImageNetv2 datasets, ImageNet-Sketch, 95 ImageNet-C datasets |\n",
      "| ImageNet-200 (train) | ImageNet-200 (valid) | 3 ImageNet-200v2 datasets, ImageNet-R, ImageNet200-Sketch, 95 ImageNet200-C datasets |\n",
      "| BreEDS (train) | BreEDS (valid) | Same subpopulations as train but unseen images from natural and synthetic shifts in ImageNet, Novel subpopulations on natural and synthetic shifts |\n",
      "\n",
      "Table 2: Details of the test datasets considered in our evaluation.\n",
      "\n",
      "ImageNet setup. First, we consider synthetic shifts induced to simulate 19 different visual corruptions (e.g., shot noise, motion blur, pixelation etc.) each with 5 different intensities giving us a total of 95 datasets under ImageNet-C (Hendrycks \\& Dietterich, 2019). Next, we consider natural distribution shifts due to differences in the data collection process. In particular, we consider 3 ImageNetv2 (Recht et al., 2019) datasets each using a different strategy to collect test sets. We also evaluate performance on images with artistic renditions of object classes, i.e., ImageNet-R (Hendrycks et al., 2021) and ImageNet-Sketch (Wang et al., 2019) with hand drawn sketch images. Note that renditions dataset only contains 200 classes from ImageNet. Hence, in the main paper we include results on ImageNet restricted to these 200 classes, which we call as ImageNet-200, and relegate results on ImageNet with 1 k classes to appendix.\n",
      "\n",
      "We also consider BreEDS benchmark (Santurkar et al., 2020) in our evaluation to assess robustness to subpopulation shifts, in particular, to understand how accuracy estimation methods behave when novel subpopulations not observed during training are introduced. BreEDS leverages class hierarchy in ImageNet to repurpose original classes to be the subpopulations and defines a classification task on superclasses. Subpopulation shift is induced by directly making the subpopulations present in the training and test distributions disjoint. Overall, BreEDS benchmark contains 4 datasets EnTiTy-13, EnTiTy-30, Living-17, Non-Living-26, each focusing on different subtrees in the hierarchy. To generate BreEDS dataset on top of ImageNet, we use the open source library: https : //github.com/MadryLab/BREEDS-Benchmarks. We focus on natural and synthetic shifts as in ImageNet on same and different subpopulations in BREEDs. Thus for both the subpopulation (same or novel), we obtain a total of 99 target datasets.\n",
      "\n",
      "CIFAR setup. Similar to the ImageNet setup, we consider (i) synthetic shifts (CIFAR-10-C) due to common corruptions; and (ii) natural distribution shift (i.e., CIFARv2 (Recht et al., 2018; Torralba et al., 2008)) due to differences in data collection strategy on on CIFAR-10 (Krizhevsky \\& Hinton, 2009). On CIFAR-100, we just have synthetic shifts due to common corruptions.\n",
      "\n",
      "FMoW-WILDS setup. In order to consider distribution shifts faced in the wild, we consider FMoWWILDS (Koh et al., 2021; Christie et al., 2018) from WILDS benchmark, which contains satellite images taken in different geographical regions and at different times. We obtain 12 different OOD target sets by considering images between years 2013-2016 and 2016-2018 and by considering five geographical regions as subpopulations (Africa, Americas, Oceania, Asia, and Europe) separately and together.\n",
      "$R x R x 1-$ WILDS setup. Similar to FMoW, we consider RxRx1-WILDS (Taylor et al., 2019) from WILDS benchmark, which contains image of cells obtained by fluorescent microscopy and the task\n",
      "\n",
      "is to genetic treatments the cells received. We obtain 3 target datasets with shift induced by batch effects which make it difficult to draw conclusions from data across experimental batches.\n",
      "\n",
      "Amazon-Wilds setup. For natural language task, we consider Amazon-Wilds (Ni et al., 2019) dataset from Wilds benchmark, which contains review text and the task is get a corresponding star rating from 1 to 5 . We obtain 2 target datasets by considered shifts induced due to different set of reviewers than the training set.\n",
      "\n",
      "CivilComments-Wilds setup. We also consider CivilComments-Wilds (Borkan et al., 2019) from Wilds benchmark, which contains text comments and the task is to classify them for toxicity. We obtain 18 target datasets depending on whether a comment mentions each of the 8 demographic identities male, female, LGBTQ, Christian, Muslim, other religions, Black, and White.\n",
      "\n",
      "MNIST setup. For completeness, we also consider distribution shifts on MNIST (LeCun et al., 1998) digit classification as in the prior work (Deng \\& Zheng, 2021). We use three real shifted datasets, i.e., USPS (Hull, 1994), SVHN (Netzer et al., 2011) and QMNIST (Yadav \\& Bottou, 2019).\n",
      "\n",
      "# G Details on the Experimental Setup \n",
      "\n",
      "All experiments were run on NVIDIA Tesla V100 GPUs. We used PyTorch (Paszke et al., 2019) for experiments.\n",
      "\n",
      "Deep nets We consider a 4-layered MLP. The PyTorch code for 4-layer MLP is as follows:\n",
      "\n",
      "```\n",
      "nn.Sequential(nn.Flatten(),\n",
      "    nn.Linear(input_dim, 5000, bias=True),\n",
      "    nn.ReLU(),\n",
      "    nn.Linear(5000, 5000, bias=True),\n",
      "    nn.ReLU(),\n",
      "    nn.Linear(5000, 50, bias=True),\n",
      "    nn.ReLU(),\n",
      "    nn.Linear(50, num_label, bias=True)\n",
      "    )\n",
      "```\n",
      "\n",
      "We mainly experiment convolutional nets. In particular, we use ResNet18 (He et al., 2016), ResNet50, and DenseNet121 (Huang et al., 2017) architectures with their default implementation in PyTorch. Whenever we initial our models with pre-trained models, we again use default models in PyTorch.\n",
      "\n",
      "Hyperparameters and Training details As mentioned in the main text we do not alter the standard training procedures and hyperparameters for each task. We present results at final model, however, we observed that the same results extend to an early stopped model as well. For completeness, we include these details below:\n",
      "\n",
      "CIFAR10 and CIFAR100 We train DenseNet121 and ResNet18 architectures from scratch. We use SGD training with momentum of 0.9 for 300 epochs. We start with learning rate 0.1 and decay it by multiplying it with 0.1 every 100 epochs. We use a weight decay of $5^{-} 4$. We use batch size of 200. For CIFAR10, we also experiment with the same models pre-trained on ImageNet.\n",
      "\n",
      "ImageNet For training, we use Adam with a batch size of 64 and learning rate 0.0001 . Due to huge size of ImageNet, we could only train two models needed for GDE for 10 epochs. Hence, for relatively small scale experiments, we also perform experiments on ImageNet subset with 200 classes, which we call as ImageNet-200 with the same training procedure. These 200 classes are the same classes as in ImageNet-R dataset. This not only allows us to train ImageNet for 50 epochs but also allows us to use ImageNet-R in our testbed. On the both the datasets, we observe a similar superioriy with ATC. Note that all the models trained here were initialized with a pre-trained ImageNet model with the last layer replaced with random weights.\n",
      "FMoW-wilds For all experiments, we follow Koh et al. (2021) and use two architectures DenseNet121 and ResNet50, both pre-trained on ImageNet. We use the Adam optimizer (Kingma \\& $\\mathrm{Ba}, 2014$ ) with an initial learning rate of $10^{-4}$ that decays by 0.96 per epoch, and train for 50 epochs and with a batch size of 64 .\n",
      "\n",
      "RxRx1-WILDS For all experiments, we follow Koh et al. (2021) and use two architectures DenseNet121 and ResNet50, both pre-trained on ImageNet. We use Adam optimizer with a learning rate of $1 e-4$ and L2-regularization strength of $1 e-5$ with a batch size of 75 for 90 epochs. We linearly increase the learning rate for 10 epochs, then decreasing it following a cosine learning rate schedule. Finally, we pick the model that obtains highest in-distribution validation accuracy.\n",
      "\n",
      "Amazon-WILDS For all experiments, we follow Koh et al. (2021) and finetuned DistilBERT-base-uncased models (Sanh et al., 2019), using the implementation from Wolf et al. (2020), and with the following hyperparameter settings: batch size 8; learning rate $1 e-5$ with the AdamW optimizer (Loshchilov \\& Hutter, 2017); L2-regularization strength 0.01; 3 epochs with early stopping; and a maximum number of tokens of 512 .\n",
      "\n",
      "CivilComments-WILDS For all experiments, we follow Koh et al. (2021) and fine-tuned DistilBERT-base-uncased models (Sanh et al., 2019), using the implementation from Wolf et al. (2020) and with the following hyperparameter settings: batch size 16; learning rate $1 e-5$ with the AdamW optimizer (Loshchilov \\& Hutter, 2017) for 5 epochs; L2-regularization strength 0.01; and a maximum number of tokens of 300 .\n",
      "\n",
      "Living17 and Nonliving26 from BreEDS For training, we use SGD with a batch size of 128, weight decay of $10^{-4}$, and learning rate 0.1 . Models were trained until convergence. Models were trained for a total of 450 epochs, with 10 -fold learning rate drops every 150 epochs. Note that since we want to evaluate models for novel subpopulations no pre-training was used. We train two architectures DenseNet121 and ResNet50.\n",
      "\n",
      "Entity13 and Entity30 from BreEDS For training, we use SGD with a batch size of 128, weight decay of $10^{-4}$, and learning rate 0.1 . Models were trained until convergence. Models were trained for a total of 300 epochs, with 10 -fold learning rate drops every 100 epochs. Note that since we want to evaluate models for novel subpopulations no pre-training was used. We train two architectures DenseNet121 and ResNet50.\n",
      "\n",
      "MNIST For MNIST, we train a MLP described above with SGD with momentum 0.9 and learning rate 0.01 for 50 epochs. We use weight decay of $10^{-5}$ and batch size as 200.\n",
      "\n",
      "We have a single number for CivilComments because it is a binary classification task. For multiclass problems, ATC-NE and ATC-MC can lead to different ordering of examples when ranked with the corresponding scoring function. Temperature scaling on top can further alter the ordering of examples. The changed ordering of examples yields different thresholds and different accuracy estimates. However for binary classification, the two scoring functions are the same as entropy (i.e. $p \\log (p)+(1-p) \\log (p))$ has a one-to-one mapping to the max conf for $p \\in[0,1]$. Moreover, temperature scaling also doesn't change the order of points for binary classification problems. Hence for the binary classification problems, both the scoring functions with and without temperature scaling yield the same estimates. We have made this clear in the updated draft.\n",
      "\n",
      "Implementation for Temperature Scaling We use temperature scaling implementation from https://github.com/kundajelab/abstention. We use validation set (the same we use to obtain ATC threshold or DOC source error estimate) to tune a single temperature parameter.\n",
      "\n",
      "# G. 1 Details on Fig. 1 (Right) Setup \n",
      "\n",
      "For vision datasets, we train a DenseNet model with the exception of FCN model for MNIST dataset. For language datasets, we fine-tune a DistilBERT-base-uncased model. For each of these models, we use the exact same setup as described Sec. G. Importantly, to obtain errors on the same scale, we rescale all the errors by subtracting the error of Average Confidence method for each model. Results are reported as mean of the re-scaled errors over 4 seeds.\n",
      "\n",
      "# H SUPPLEMENTARY RESULTS \n",
      "\n",
      "## H. 1 CIFAR PRETRAINING Ablation\n",
      "\n",
      "![img-5.jpeg](images/img-5.jpeg)\n",
      "(a)\n",
      "\n",
      "Figure 6: Results with a pretrained DenseNet121 model on CIFAR10. We observe similar behaviour as that with a model trained from scratch.\n",
      "\n",
      "## H. 2 BREEDS RESULTS WITH REGRESSION MODEL\n",
      "\n",
      "![img-6.jpeg](images/img-6.jpeg)\n",
      "\n",
      "Figure 7: Scatter plots for DOC with linear fit. Results parallel to Fig. 3(Middle) on other BREEDS dataset.\n",
      "\n",
      "| Dataset | DOC (w/o fit) | DOC (w fit) | ATC-MC (Ours) (w/o fit) |\n",
      "| :--: | :--: | :--: | :--: |\n",
      "| LIVING-17 | 24.32 | 13.65 | 10.07 |\n",
      "| NonLIVING-26 | 29.91 | 18.13 | 19.37 |\n",
      "| ENTITY-13 | 22.18 | 8.63 | 8.01 |\n",
      "| ENTITY-30 | 24.71 | 12.28 | 10.21 |\n",
      "\n",
      "Table 5: Mean Absolute estimation Error (MAE) results for BREEDs datasets with novel populations in our setup. After fitting a robust linear model for DOC on same subpopulation, we show predicted accuracy on different subpopulations with fine-tuned DOC (i.e., DOC (w/ fit)) and compare with ATC without any regression model, i.e., ATC (w/o fit). While observe substantial improvements in MAE from DOC (w/o fit) to DOC (w/ fit), ATC (w/o fit) continues to outperform even DOC (w/ fit).\n",
      "\n",
      "![img-7.jpeg](images/img-7.jpeg)\n",
      "\n",
      "Figure 8: Scatter plot of predicted accuracy versus (true) OOD accuracy. For vision datasets except MNIST we use a DenseNet121 model. For MNIST, we use a FCN. For language datasets, we use DistillBert-base-uncased. Results reported by aggregating accuracy numbers over 4 different seeds.\n",
      "\n",
      "![img-8.jpeg](images/img-8.jpeg)\n",
      "\n",
      "Figure 9: Scatter plot of predicted accuracy versus (true) OOD accuracy for vision datasets except MNIST with a ResNet50 model. Results reported by aggregating MAE numbers over 4 different seeds.\n",
      "\n",
      "| Dataset | Shift | IM |  | AC |  | DOC |  | GDE | ATC-MC (Ours) |  | ATC-NE (Ours) |  |\n",
      "| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
      "|  |  | Pre T | Post T | Pre T | Post T | Pre T | Post T | Post T | Pre T | Post T | Pre T | Post T |\n",
      "| CIFAR10 | Natural | $\\begin{gathered} 6.60 \\\\ (0.35) \\end{gathered}$ | $\\begin{gathered} 5.74 \\\\ (0.30) \\end{gathered}$ | $\\begin{gathered} 9.88 \\\\ (0.16) \\end{gathered}$ | $\\begin{gathered} 6.89 \\\\ (0.13) \\end{gathered}$ | $\\begin{gathered} 7.25 \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} 6.07 \\\\ (0.16) \\end{gathered}$ | $\\begin{gathered} 4.77 \\\\ (0.13) \\end{gathered}$ | $\\begin{gathered} 3.21 \\\\ (0.49) \\end{gathered}$ | $\\begin{gathered} 3.02 \\\\ (0.40) \\end{gathered}$ | $\\begin{gathered} 2.99 \\\\ (0.37) \\end{gathered}$ | $\\begin{gathered} 2.85 \\\\ (0.29) \\end{gathered}$ |\n",
      "|  | Synthetic | $\\begin{gathered} 12.33 \\\\ (0.51) \\end{gathered}$ | $\\begin{gathered} 10.20 \\\\ (0.48) \\end{gathered}$ | $\\begin{gathered} 16.50 \\\\ (0.26) \\end{gathered}$ | $\\begin{gathered} 11.91 \\\\ (0.17) \\end{gathered}$ | $\\begin{gathered} 13.87 \\\\ (0.18) \\end{gathered}$ | $\\begin{gathered} 11.08 \\\\ (0.17) \\end{gathered}$ | $\\begin{gathered} 6.55 \\\\ (0.35) \\end{gathered}$ | $\\begin{gathered} 4.65 \\\\ (0.55) \\end{gathered}$ | $\\begin{gathered} 4.25 \\\\ (0.55) \\end{gathered}$ | $\\begin{gathered} 4.21 \\\\ (0.55) \\end{gathered}$ | $\\begin{gathered} 3.87 \\\\ (0.75) \\end{gathered}$ |\n",
      "| CIFAR100 | Synthetic | $\\begin{gathered} 13.69 \\\\ (0.55) \\end{gathered}$ | $\\begin{gathered} 11.51 \\\\ (0.41) \\end{gathered}$ | $\\begin{gathered} 23.61 \\\\ (1.16) \\end{gathered}$ | $\\begin{gathered} 13.10 \\\\ (0.80) \\end{gathered}$ | $\\begin{gathered} 14.60 \\\\ (0.77) \\end{gathered}$ | $\\begin{gathered} 10.14 \\\\ (0.64) \\end{gathered}$ | $\\begin{gathered} 9.85 \\\\ (0.57) \\end{gathered}$ | $\\begin{gathered} 5.50 \\\\ (0.70) \\end{gathered}$ | $\\begin{gathered} 4.75 \\\\ (0.73) \\end{gathered}$ | $\\begin{gathered} 4.72 \\\\ (0.74) \\end{gathered}$ | $\\begin{gathered} 4.94 \\\\ (0.74) \\end{gathered}$ |\n",
      "| ImageNet200 | Natural | $\\begin{gathered} 12.37 \\\\ (0.25) \\end{gathered}$ | $\\begin{gathered} 8.19 \\\\ (0.33) \\end{gathered}$ | $\\begin{gathered} 22.07 \\\\ (0.08) \\end{gathered}$ | $\\begin{gathered} 8.61 \\\\ (0.25) \\end{gathered}$ | $\\begin{gathered} 15.17 \\\\ (0.11) \\end{gathered}$ | $\\begin{gathered} 7.81 \\\\ (0.29) \\end{gathered}$ | $\\begin{gathered} 5.13 \\\\ (0.08) \\end{gathered}$ | $\\begin{gathered} 4.37 \\\\ (0.39) \\end{gathered}$ | $\\begin{gathered} 2.04 \\\\ (0.24) \\end{gathered}$ | $\\begin{gathered} 3.79 \\\\ (0.30) \\end{gathered}$ | $\\begin{gathered} 1.45 \\\\ (0.27) \\end{gathered}$ |\n",
      "|  | Synthetic | $\\begin{gathered} 19.86 \\\\ (1.38) \\end{gathered}$ | $\\begin{gathered} 12.94 \\\\ (1.81) \\end{gathered}$ | $\\begin{gathered} 32.44 \\\\ (1.00) \\end{gathered}$ | $\\begin{gathered} 13.35 \\\\ (1.30) \\end{gathered}$ | $\\begin{gathered} 25.02 \\\\ (1.10) \\end{gathered}$ | $\\begin{gathered} 12.38 \\\\ (1.38) \\end{gathered}$ | $\\begin{gathered} 5.41 \\\\ (0.89) \\end{gathered}$ | $\\begin{gathered} 5.93 \\\\ (1.38) \\end{gathered}$ | $\\begin{gathered} 3.09 \\\\ (0.87) \\end{gathered}$ | $\\begin{gathered} 5.00 \\\\ (1.28) \\end{gathered}$ | $\\begin{gathered} 2.68 \\\\ (0.45) \\end{gathered}$ |\n",
      "| ImageNet | Natural | $\\begin{gathered} 7.77 \\\\ (0.27) \\end{gathered}$ | $\\begin{gathered} 6.50 \\\\ (0.33) \\end{gathered}$ | $\\begin{gathered} 18.13 \\\\ (0.23) \\end{gathered}$ | $\\begin{gathered} 6.02 \\\\ (0.34) \\end{gathered}$ | $\\begin{gathered} 8.13 \\\\ (0.27) \\end{gathered}$ | $\\begin{gathered} 5.76 \\\\ (0.37) \\end{gathered}$ | $\\begin{gathered} 6.23 \\\\ (0.41) \\end{gathered}$ | $\\begin{gathered} 3.88 \\\\ (0.53) \\end{gathered}$ | $\\begin{gathered} 2.17 \\\\ (0.62) \\end{gathered}$ | $\\begin{gathered} 2.06 \\\\ (0.54) \\end{gathered}$ | $\\begin{gathered} 0.80 \\\\ (0.44) \\end{gathered}$ |\n",
      "|  | Synthetic | $\\begin{gathered} 13.39 \\\\ (0.53) \\end{gathered}$ | $\\begin{gathered} 10.12 \\\\ (0.63) \\end{gathered}$ | $\\begin{gathered} 24.62 \\\\ (0.64) \\end{gathered}$ | $\\begin{gathered} 8.51 \\\\ (0.71) \\end{gathered}$ | $\\begin{gathered} 13.55 \\\\ (0.61) \\end{gathered}$ | $\\begin{gathered} 7.90 \\\\ (0.72) \\end{gathered}$ | $\\begin{gathered} 6.32 \\\\ (0.33) \\end{gathered}$ | $\\begin{gathered} 3.34 \\\\ (0.53) \\end{gathered}$ | $\\begin{gathered} 2.53 \\\\ (0.36) \\end{gathered}$ | $\\begin{gathered} 2.61 \\\\ (0.33) \\end{gathered}$ | $\\begin{gathered} 4.89 \\\\ (0.83) \\end{gathered}$ |\n",
      "| FMoW-WILDS | Natural | $\\begin{gathered} 5.53 \\\\ (0.33) \\end{gathered}$ | $\\begin{gathered} 4.31 \\\\ (0.63) \\end{gathered}$ | $\\begin{gathered} 33.53 \\\\ (0.13) \\end{gathered}$ | $\\begin{gathered} 12.84 \\\\ (12.06) \\end{gathered}$ | $\\begin{gathered} 5.94 \\\\ (0.36) \\end{gathered}$ | $\\begin{gathered} 4.45 \\\\ (0.77) \\end{gathered}$ | $\\begin{gathered} 5.74 \\\\ (0.55) \\end{gathered}$ | $\\begin{gathered} 3.06 \\\\ (0.36) \\end{gathered}$ | $\\begin{gathered} 2.70 \\\\ (0.54) \\end{gathered}$ | $\\begin{gathered} 3.02 \\\\ (0.35) \\end{gathered}$ | $\\begin{gathered} 2.72 \\\\ (0.44) \\end{gathered}$ |\n",
      "| RxRx1-WILDS | Natural | $\\begin{gathered} 5.80 \\\\ (0.17) \\end{gathered}$ | $\\begin{gathered} 5.72 \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} 7.90 \\\\ (0.24) \\end{gathered}$ | $\\begin{gathered} 4.84 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} 5.98 \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} 5.98 \\\\ (0.13) \\end{gathered}$ | $\\begin{gathered} 6.03 \\\\ (0.08) \\end{gathered}$ | $\\begin{gathered} 4.66 \\\\ (0.38) \\end{gathered}$ | $\\begin{gathered} 4.56 \\\\ (0.38) \\end{gathered}$ | $\\begin{gathered} 4.41 \\\\ (0.31) \\end{gathered}$ | $\\begin{gathered} 4.47 \\\\ (0.26) \\end{gathered}$ |\n",
      "| Amazon-WILDS | Natural | $\\begin{gathered} 2.40 \\\\ (0.08) \\end{gathered}$ | $\\begin{gathered} 2.29 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} 8.01 \\\\ (0.53) \\end{gathered}$ | $\\begin{gathered} 2.38 \\\\ (0.17) \\end{gathered}$ | $\\begin{gathered} 2.40 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} 2.28 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} 17.87 \\\\ (0.18) \\end{gathered}$ | $\\begin{gathered} 1.65 \\\\ (0.06) \\end{gathered}$ | $\\begin{gathered} 1.62 \\\\ (0.05) \\end{gathered}$ | $\\begin{gathered} 1.60 \\\\ (0.14) \\end{gathered}$ | $\\begin{gathered} 1.59 \\\\ (0.15) \\end{gathered}$ |\n",
      "| CivilCom.-WILDS | Natural | $\\begin{gathered} 12.64 \\\\ (0.52) \\end{gathered}$ | $\\begin{gathered} 10.80 \\\\ (0.48) \\end{gathered}$ | $\\begin{gathered} 16.76 \\\\ (0.53) \\end{gathered}$ | $\\begin{gathered} 11.03 \\\\ (0.49) \\end{gathered}$ | $\\begin{gathered} 13.31 \\\\ (0.52) \\end{gathered}$ | $\\begin{gathered} 10.99 \\\\ (0.49) \\end{gathered}$ | $\\begin{gathered} 16.65 \\\\ (0.25) \\end{gathered}$ |  | $\\begin{gathered} 7.14 \\\\ (0.41) \\end{gathered}$ |  |  |\n",
      "| MNIST | Natural | $\\begin{gathered} 18.48 \\\\ (0.45) \\end{gathered}$ | $\\begin{gathered} 15.99 \\\\ (1.53) \\end{gathered}$ | $\\begin{gathered} 21.17 \\\\ (0.24) \\end{gathered}$ | $\\begin{gathered} 14.81 \\\\ (3.89) \\end{gathered}$ | $\\begin{gathered} 20.19 \\\\ (0.23) \\end{gathered}$ | $\\begin{gathered} 14.56 \\\\ (3.47) \\end{gathered}$ | $\\begin{gathered} 24.42 \\\\ (0.41) \\end{gathered}$ | $\\begin{gathered} 5.02 \\\\ (0.44) \\end{gathered}$ | $\\begin{gathered} 2.40 \\\\ (1.83) \\end{gathered}$ | $\\begin{gathered} 3.14 \\\\ (0.49) \\end{gathered}$ | $\\begin{gathered} 3.50 \\\\ (0.17) \\end{gathered}$ |\n",
      "| EnTITY-13 | Same | $\\begin{gathered} 16.23 \\\\ (0.77) \\end{gathered}$ | $\\begin{gathered} 11.14 \\\\ (0.65) \\end{gathered}$ | $\\begin{gathered} 24.97 \\\\ (0.70) \\end{gathered}$ | $\\begin{gathered} 10.88 \\\\ (0.77) \\end{gathered}$ | $\\begin{gathered} 19.08 \\\\ (0.65) \\end{gathered}$ | $\\begin{gathered} 10.47 \\\\ (0.72) \\end{gathered}$ | $\\begin{gathered} 10.71 \\\\ (0.74) \\end{gathered}$ | $\\begin{gathered} 5.39 \\\\ (0.92) \\end{gathered}$ | $\\begin{gathered} 3.88 \\\\ (0.61) \\end{gathered}$ | $\\begin{gathered} 4.58 \\\\ (0.85) \\end{gathered}$ | $\\begin{gathered} 4.19 \\\\ (0.16) \\end{gathered}$ |\n",
      "|  | Novel | $\\begin{gathered} 28.53 \\\\ (0.82) \\end{gathered}$ | $\\begin{gathered} 22.02 \\\\ (0.68) \\end{gathered}$ | $\\begin{gathered} 38.33 \\\\ (0.75) \\end{gathered}$ | $\\begin{gathered} 21.64 \\\\ (0.86) \\end{gathered}$ | $\\begin{gathered} 32.43 \\\\ (0.69) \\end{gathered}$ | $\\begin{gathered} 21.22 \\\\ (0.80) \\end{gathered}$ | $\\begin{gathered} 20.61 \\\\ (0.60) \\end{gathered}$ | $\\begin{gathered} 13.58 \\\\ (1.15) \\end{gathered}$ | $\\begin{gathered} 10.28 \\\\ (1.34) \\end{gathered}$ | $\\begin{gathered} 12.25 \\\\ (1.21) \\end{gathered}$ | $\\begin{gathered} 6.63 \\\\ (0.93) \\end{gathered}$ |\n",
      "| EnTITY-30 | Same | $\\begin{gathered} 18.59 \\\\ (0.51) \\end{gathered}$ | $\\begin{gathered} 14.46 \\\\ (0.52) \\end{gathered}$ | $\\begin{gathered} 28.82 \\\\ (0.43) \\end{gathered}$ | $\\begin{gathered} 14.30 \\\\ (0.71) \\end{gathered}$ | $\\begin{gathered} 21.63 \\\\ (0.37) \\end{gathered}$ | $\\begin{gathered} 13.46 \\\\ (0.59) \\end{gathered}$ | $\\begin{gathered} 12.92 \\\\ (0.14) \\end{gathered}$ | $\\begin{gathered} 9.12 \\\\ (0.62) \\end{gathered}$ | $\\begin{gathered} 7.75 \\\\ (0.72) \\end{gathered}$ | $\\begin{gathered} 8.15 \\\\ (0.68) \\end{gathered}$ | $\\begin{gathered} 7.64 \\\\ (0.88) \\end{gathered}$ |\n",
      "|  | Novel | $\\begin{gathered} 32.34 \\\\ (0.60) \\end{gathered}$ | $\\begin{gathered} 26.85 \\\\ (0.58) \\end{gathered}$ | $\\begin{gathered} 44.02 \\\\ (0.56) \\end{gathered}$ | $\\begin{gathered} 26.27 \\\\ (0.79) \\end{gathered}$ | $\\begin{gathered} 36.82 \\\\ (0.47) \\end{gathered}$ | $\\begin{gathered} 25.42 \\\\ (0.68) \\end{gathered}$ | $\\begin{gathered} 23.16 \\\\ (0.12) \\end{gathered}$ | $\\begin{gathered} 17.75 \\\\ (0.76) \\end{gathered}$ | $\\begin{gathered} 14.30 \\\\ (0.85) \\end{gathered}$ | $\\begin{gathered} 15.60 \\\\ (0.86) \\end{gathered}$ | $\\begin{gathered} 10.57 \\\\ (0.86) \\end{gathered}$ |\n",
      "| Nonliving-26 | Same | $\\begin{gathered} 18.66 \\\\ (0.76) \\end{gathered}$ | $\\begin{gathered} 17.17 \\\\ (0.74) \\end{gathered}$ | $\\begin{gathered} 26.39 \\\\ (0.82) \\end{gathered}$ | $\\begin{gathered} 16.14 \\\\ (0.81) \\end{gathered}$ | $\\begin{gathered} 19.86 \\\\ (0.67) \\end{gathered}$ | $\\begin{gathered} 15.58 \\\\ (0.76) \\end{gathered}$ | $\\begin{gathered} 16.63 \\\\ (0.45) \\end{gathered}$ | $\\begin{gathered} 10.87 \\\\ (0.98) \\end{gathered}$ | $\\begin{gathered} 10.24 \\\\ (0.83) \\end{gathered}$ | $\\begin{gathered} 10.07 \\\\ (0.92) \\end{gathered}$ | $\\begin{gathered} 10.26 \\\\ (1.18) \\end{gathered}$ |\n",
      "|  | Novel | $\\begin{gathered} 33.43 \\\\ (0.67) \\end{gathered}$ | $\\begin{gathered} 31.53 \\\\ (0.65) \\end{gathered}$ | $\\begin{gathered} 41.66 \\\\ (0.67) \\end{gathered}$ | $\\begin{gathered} 29.87 \\\\ (0.71) \\end{gathered}$ | $\\begin{gathered} 35.13 \\\\ (0.54) \\end{gathered}$ | $\\begin{gathered} 29.31 \\\\ (0.64) \\end{gathered}$ | $\\begin{gathered} 29.56 \\\\ (0.21) \\end{gathered}$ | $\\begin{gathered} 21.70 \\\\ (0.86) \\end{gathered}$ | $\\begin{gathered} 20.12 \\\\ (0.75) \\end{gathered}$ | $\\begin{gathered} 19.08 \\\\ (0.82) \\end{gathered}$ | $\\begin{gathered} 18.26 \\\\ (1.12) \\end{gathered}$ |\n",
      "| Living-17 | Same | $\\begin{gathered} 12.63 \\\\ (1.25) \\end{gathered}$ | $\\begin{gathered} 11.05 \\\\ (1.20) \\end{gathered}$ | $\\begin{gathered} 18.32 \\\\ (1.01) \\end{gathered}$ | $\\begin{gathered} 10.46 \\\\ (1.12) \\end{gathered}$ | $\\begin{gathered} 14.43 \\\\ (1.11) \\end{gathered}$ | $\\begin{gathered} 10.14 \\\\ (1.16) \\end{gathered}$ | $\\begin{gathered} 9.87 \\\\ (0.61) \\end{gathered}$ | $\\begin{gathered} 4.57 \\\\ (0.71) \\end{gathered}$ | $\\begin{gathered} 3.95 \\\\ (0.48) \\end{gathered}$ | $\\begin{gathered} 3.81 \\\\ (0.22) \\end{gathered}$ | $\\begin{gathered} 4.21 \\\\ (0.53) \\end{gathered}$ |\n",
      "|  | Novel | $\\begin{gathered} 29.03 \\\\ (1.44) \\end{gathered}$ | $\\begin{gathered} 26.96 \\\\ (1.38) \\end{gathered}$ | $\\begin{gathered} 35.67 \\\\ (1.09) \\end{gathered}$ | $\\begin{gathered} 26.11 \\\\ (1.27) \\end{gathered}$ | $\\begin{gathered} 31.73 \\\\ (1.19) \\end{gathered}$ | $\\begin{gathered} 25.73 \\\\ (1.35) \\end{gathered}$ | $\\begin{gathered} 23.53 \\\\ (0.52) \\end{gathered}$ | $\\begin{gathered} 16.15 \\\\ (1.36) \\end{gathered}$ | $\\begin{gathered} 14.49 \\\\ (1.46) \\end{gathered}$ | $\\begin{gathered} 12.97 \\\\ (1.52) \\end{gathered}$ | $\\begin{gathered} 11.39 \\\\ (1.72) \\end{gathered}$ |\n",
      "\n",
      "Table 3: Mean Absolute estimation Error (MAE) results for different datasets in our setup grouped by the nature of shift. 'Same' refers to same subpopulation shifts and 'Novel' refers novel subpopulation shifts. We include details about the target sets considered in each shift in Table 2. Post T denotes use of TS calibration on source. For language datasets, we use DistilBERT-base-uncased, for vision dataset we report results with DenseNet model with the exception of MNIST where we use FCN. Across all datasets, we observe that ATC achieves superior performance (lower MAE is better). For GDE post T and pre T estimates match since TS doesn't alter the argmax prediction. Results reported by aggregating MAE numbers over 4 different seeds. Values in parenthesis (i.e., $(\\cdot)$ ) denote standard deviation values.\n",
      "\n",
      "| Dataset | Shift | IM |  | AC |  | DOC |  | GDE | ATC-MC (Ours) |  | ATC-NE (Ours) |  |\n",
      "| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
      "|  |  | Pre T | Post T | Pre T | Post T | Pre T | Post T | Post T | Pre T | Post T | Pre T | Post T |\n",
      "| CIFAR10 | Natural | 7.14 | 6.20 | 10.25 | 7.06 | 7.68 | 6.35 | 5.74 | 4.02 | 3.85 | 3.76 | 3.38 |\n",
      "|  |  | $(0.14)$ | $(0.11)$ | $(0.31)$ | $(0.33)$ | $(0.28)$ | $(0.27)$ | $(0.25)$ | $(0.38)$ | $(0.30)$ | $(0.33)$ | $(0.32)$ |\n",
      "|  | Synthetic | 12.62 | 10.75 | 16.50 | 11.91 | 13.93 | 11.20 | 7.97 | 5.66 | 5.03 | 4.87 | 3.63 |\n",
      "|  |  | $(0.76)$ | $(0.71)$ | $(0.28)$ | $(0.24)$ | $(0.29)$ | $(0.28)$ | $(0.13)$ | $(0.64)$ | $(0.71)$ | $(0.71)$ | $(0.62)$ |\n",
      "| CIFAR100 | Synthetic | 12.77 | 12.34 | 16.89 | 12.73 | 11.18 | 9.63 | 12.00 | 5.61 | 5.55 | 5.65 | 5.76 |\n",
      "|  |  | $(0.43)$ | $(0.68)$ | $(0.20)$ | $(2.59)$ | $(0.35)$ | $(1.25)$ | $(0.48)$ | $(0.51)$ | $(0.55)$ | $(0.35)$ | $(0.27)$ |\n",
      "| ImageNet200 | Natural | 12.63 | 7.99 | 23.08 | 7.22 | 15.40 | 6.33 | 5.00 | 4.60 | 1.80 | 4.06 | 1.38 |\n",
      "|  |  | $(0.59)$ | $(0.47)$ | $(0.31)$ | $(0.22)$ | $(0.42)$ | $(0.24)$ | $(0.36)$ | $(0.63)$ | $(0.17)$ | $(0.69)$ | $(0.29)$ |\n",
      "|  | Synthetic | 20.17 | 11.74 | 33.69 | 9.51 | 25.49 | 8.61 | 4.19 | 5.37 | 2.78 | 4.53 | 3.58 |\n",
      "|  |  | $(0.74)$ | $(0.80)$ | $(0.73)$ | $(0.51)$ | $(0.66)$ | $(0.50)$ | $(0.14)$ | $(0.88)$ | $(0.23)$ | $(0.79)$ | $(0.33)$ |\n",
      "| ImageNet | Natural | 8.09 | 6.42 | 21.66 | 5.91 | 8.53 | 5.21 | 5.90 | 3.93 | 1.89 | 2.45 | 0.73 |\n",
      "|  |  | $(0.25)$ | $(0.28)$ | $(0.38)$ | $(0.22)$ | $(0.26)$ | $(0.25)$ | $(0.44)$ | $(0.26)$ | $(0.21)$ | $(0.16)$ | $(0.10)$ |\n",
      "|  | Synthetic | 13.93 | 9.90 | 28.05 | 7.56 | 13.82 | 6.19 | 6.70 | 3.33 | 2.55 | 2.12 | 5.06 |\n",
      "|  |  | $(0.14)$ | $(0.23)$ | $(0.39)$ | $(0.13)$ | $(0.31)$ | $(0.07)$ | $(0.52)$ | $(0.25)$ | $(0.25)$ | $(0.31)$ | $(0.27)$ |\n",
      "| FMoW-WILDS | Natural | 5.15 | 3.55 | 34.64 | 5.03 | 5.58 | 3.46 | 5.08 | 2.59 | 2.33 | 2.52 | 2.22 |\n",
      "|  |  | $(0.19)$ | $(0.41)$ | $(0.22)$ | $(0.29)$ | $(0.17)$ | $(0.37)$ | $(0.46)$ | $(0.32)$ | $(0.28)$ | $(0.25)$ | $(0.30)$ |\n",
      "| RxRx1-WILDS | Natural | 6.17 | 6.11 | 21.05 | 5.21 | 6.54 | 6.27 | 6.82 | 5.30 | 5.20 | 5.19 | 5.63 |\n",
      "|  |  | $(0.20)$ | $(0.24)$ | $(0.31)$ | $(0.18)$ | $(0.21)$ | $(0.20)$ | $(0.31)$ | $(0.30)$ | $(0.44)$ | $(0.43)$ | $(0.55)$ |\n",
      "| ENTITY-13 | Same | 18.32 | 14.38 | 27.79 | 13.56 | 20.50 | 13.22 | 16.09 | 9.35 | 7.50 | 7.80 | 6.94 |\n",
      "|  |  | $(0.29)$ | $(0.53)$ | $(1.18)$ | $(0.58)$ | $(0.47)$ | $(0.58)$ | $(0.84)$ | $(0.79)$ | $(0.65)$ | $(0.62)$ | $(0.71)$ |\n",
      "|  | Novel | 28.82 | 24.03 | 38.97 | 22.96 | 31.66 | 22.61 | 25.26 | 17.11 | 13.96 | 14.75 | 9.94 |\n",
      "|  |  | $(0.30)$ | $(0.55)$ | $(1.32)$ | $(0.59)$ | $(0.54)$ | $(0.58)$ | $(1.08)$ | $(0.84)$ | $(0.93)$ | $(0.64)$ | $(0.78)$ |\n",
      "| ENTITY-30 | Same | 16.91 | 14.61 | 26.84 | 14.37 | 18.60 | 13.11 | 13.74 | 8.54 | 7.94 | 7.77 | 8.04 |\n",
      "|  |  | $(1.33)$ | $(1.11)$ | $(2.15)$ | $(1.34)$ | $(1.69)$ | $(1.30)$ | $(1.07)$ | $(1.47)$ | $(1.38)$ | $(1.44)$ | $(1.51)$ |\n",
      "|  | Novel | 28.66 | 25.83 | 39.21 | 25.03 | 30.95 | 23.73 | 23.15 | 15.57 | 13.24 | 12.44 | 11.05 |\n",
      "|  |  | $(1.16)$ | $(0.88)$ | $(2.03)$ | $(1.11)$ | $(1.64)$ | $(1.11)$ | $(0.51)$ | $(1.44)$ | $(1.15)$ | $(1.26)$ | $(1.13)$ |\n",
      "| NonLIVING-26 | Same | 17.43 | 15.95 | 27.70 | 15.40 | 18.06 | 14.58 | 16.99 | 10.79 | 10.13 | 10.05 | 10.29 |\n",
      "|  |  | $(0.90)$ | $(0.86)$ | $(0.90)$ | $(0.69)$ | $(1.00)$ | $(0.78)$ | $(1.25)$ | $(0.62)$ | $(0.32)$ | $(0.46)$ | $(0.79)$ |\n",
      "|  | Novel | 29.51 | 27.75 | 40.02 | 26.77 | 30.36 | 25.93 | 27.70 | 19.64 | 17.75 | 16.90 | 15.69 |\n",
      "|  |  | $(0.86)$ | $(0.82)$ | $(0.76)$ | $(0.82)$ | $(0.95)$ | $(0.80)$ | $(1.42)$ | $(0.68)$ | $(0.53)$ | $(0.60)$ | $(0.83)$ |\n",
      "| LIVING-17 | Same | 14.28 | 12.21 | 23.46 | 11.16 | 15.22 | 10.78 | 10.49 | 4.92 | 4.23 | 4.19 | 4.73 |\n",
      "|  |  | $(0.96)$ | $(0.93)$ | $(1.16)$ | $(0.90)$ | $(0.96)$ | $(0.99)$ | $(0.97)$ | $(0.57)$ | $(0.42)$ | $(0.35)$ | $(0.24)$ |\n",
      "|  | Novel | 28.91 | 26.35 | 38.62 | 24.91 | 30.32 | 24.52 | 22.49 | 15.42 | 13.02 | 12.29 | 10.34 |\n",
      "|  |  | $(0.66)$ | $(0.73)$ | $(1.01)$ | $(0.61)$ | $(0.59)$ | $(0.74)$ | $(0.85)$ | $(0.59)$ | $(0.53)$ | $(0.73)$ | $(0.62)$ |\n",
      "\n",
      "Table 4: Mean Absolute estimation Error (MAE) results for different datasets in our setup grouped by the nature of shift for ResNet model. 'Same' refers to same subpopulation shifts and 'Novel' refers novel subpopulation shifts. We include details about the target sets considered in each shift in Table 2. Post T denotes use of TS calibration on source. Across all datasets, we observe that ATC achieves superior performance (lower MAE is better). For GDE post T and pre T estimates match since TS doesn't alter the argmax prediction. Results reported by aggregating MAE numbers over 4 different seeds. Values in parenthesis (i.e., $(-)$ ) denote standard deviation values.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time1 = time.time()\n",
    "total_md = pdf_to_markdown(\"sample.pdf\")\n",
    "\n",
    "print(\"Total time = \", time.time()-time1)\n",
    "\n",
    "print(total_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f38436b-b060-487e-b72a-fa087196e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "chapter_list = [\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Preface\",\n",
    "    \"title\": \"\",\n",
    "    \"starting_page\": 1\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 1\",\n",
    "    \"title\": \"Essential Ideas\",\n",
    "    \"starting_page\": 9\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 2\",\n",
    "    \"title\": \"Atoms, Molecules, and Ions\",\n",
    "    \"starting_page\": 67\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 3\",\n",
    "    \"title\": \"Composition of Substances and Solutions\",\n",
    "    \"starting_page\": 131\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 4\",\n",
    "    \"title\": \"Stoichiometry of Chemical Reactions\",\n",
    "    \"starting_page\": 175\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 5\",\n",
    "    \"title\": \"Thermochemistry\",\n",
    "    \"starting_page\": 231\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 6\",\n",
    "    \"title\": \"Electronic Structure and Periodic Properties of Elements\",\n",
    "    \"starting_page\": 281\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 7\",\n",
    "    \"title\": \"Chemical Bonding and Molecular Geometry\",\n",
    "    \"starting_page\": 343\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 8\",\n",
    "    \"title\": \"Advanced Theories of Covalent Bonding\",\n",
    "    \"starting_page\": 411\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 9\",\n",
    "    \"title\": \"Gases\",\n",
    "    \"starting_page\": 457\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 10\",\n",
    "    \"title\": \"Liquids and Solids\",\n",
    "    \"starting_page\": 521\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 11\",\n",
    "    \"title\": \"Solutions and Colloids\",\n",
    "    \"starting_page\": 599\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 12\",\n",
    "    \"title\": \"Kinetics\",\n",
    "    \"starting_page\": 657\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 13\",\n",
    "    \"title\": \"Fundamental Equilibrium Concepts\",\n",
    "    \"starting_page\": 721\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 14\",\n",
    "    \"title\": \"Acid-Base Equilibria\",\n",
    "    \"starting_page\": 763\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 15\",\n",
    "    \"title\": \"Equilibria of Other Reaction Classes\",\n",
    "    \"starting_page\": 823\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 16\",\n",
    "    \"title\": \"Thermodynamics\",\n",
    "    \"starting_page\": 861\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 17\",\n",
    "    \"title\": \"Electrochemistry\",\n",
    "    \"starting_page\": 897\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 18\",\n",
    "    \"title\": \"Representative Metals, Metalloids, and Nonmetals\",\n",
    "    \"starting_page\": 941\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 19\",\n",
    "    \"title\": \"Transition Metals and Coordination Chemistry\",\n",
    "    \"starting_page\": 1029\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 20\",\n",
    "    \"title\": \"Organic Chemistry\",\n",
    "    \"starting_page\": 1077\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Chapter 21\",\n",
    "    \"title\": \"Nuclear Chemistry\",\n",
    "    \"starting_page\": 1127\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix A\",\n",
    "    \"title\": \"The Periodic Table\",\n",
    "    \"starting_page\": 1189\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix B\",\n",
    "    \"title\": \"Essential Mathematics\",\n",
    "    \"starting_page\": 1191\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix C\",\n",
    "    \"title\": \"Units and Conversion Factors\",\n",
    "    \"starting_page\": 1199\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix D\",\n",
    "    \"title\": \"Fundamental Physical Constants\",\n",
    "    \"starting_page\": 1201\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix E\",\n",
    "    \"title\": \"Water Properties\",\n",
    "    \"starting_page\": 1203\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix F\",\n",
    "    \"title\": \"Composition of Commercial Acids and Bases\",\n",
    "    \"starting_page\": 1209\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix G\",\n",
    "    \"title\": \"Standard Thermodynamic Properties for Selected Substances\",\n",
    "    \"starting_page\": 1211\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix H\",\n",
    "    \"title\": \"Ionization Constants of Weak Acids\",\n",
    "    \"starting_page\": 1225\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix I\",\n",
    "    \"title\": \"Ionization Constants of Weak Bases\",\n",
    "    \"starting_page\": 1229\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix J\",\n",
    "    \"title\": \"Solubility Products\",\n",
    "    \"starting_page\": 1231\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix K\",\n",
    "    \"title\": \"Formation Constants for Complex Ions\",\n",
    "    \"starting_page\": 1235\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix L\",\n",
    "    \"title\": \"Standard Electrode (Half-Cell) Potentials\",\n",
    "    \"starting_page\": 1237\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Appendix M\",\n",
    "    \"title\": \"Half-Lives for Several Radioactive Isotopes\",\n",
    "    \"starting_page\": 1243\n",
    "  },\n",
    "  {\n",
    "    \"chapter_or_appendix\": \"Index\",\n",
    "    \"title\": \"\",\n",
    "    \"starting_page\": 1313\n",
    "  }\n",
    "]\n",
    "\n",
    "starting_pages = []\n",
    "for chapter in chapter_list:\n",
    "    chapter_file = chapter['chapter_or_appendix'].replace(\" \",\"_\")\n",
    "    starting_pages.append((chapter_file, chapter['starting_page'] + 10))\n",
    "    #print(starting_pages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84f91e0-ca80-427a-b940-a64a2d1f30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "import tempfile\n",
    "import time\n",
    "import shutil\n",
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def save_images(images, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved = []\n",
    "    for img in images:\n",
    "        b64 = img.image_base64\n",
    "        if b64.startswith(\"data:image/\"):\n",
    "            b64 = b64.split(\",\", 1)[1]\n",
    "        try:\n",
    "            data = base64.b64decode(b64)\n",
    "        except base64.binascii.Error as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to decode image {img.id}: {e}\")\n",
    "            continue\n",
    "        ext = os.path.splitext(img.id)[1].lstrip(\".\") or \"jpg\"\n",
    "        fname = img.id if img.id.endswith(f\".{ext}\") else f\"{img.id}.{ext}\"\n",
    "        with open(os.path.join(output_dir, fname), \"wb\") as f:\n",
    "            f.write(data)\n",
    "        saved.append(fname)\n",
    "    return saved\n",
    "\n",
    "def extract_pdf_pages(source_path, start_page, end_page):\n",
    "    \"\"\"\n",
    "    Extracts specified page range from source_path and returns path to a temporary file.\n",
    "    start_page and end_page are 1-based, inclusive.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(source_path)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    total_pages = len(reader.pages)\n",
    "    start = max(1, start_page)\n",
    "    end = min(end_page, total_pages)\n",
    "\n",
    "    for i in range(start - 1, end):\n",
    "        writer.add_page(reader.pages[i])\n",
    "\n",
    "    temp_fd, temp_path = tempfile.mkstemp(suffix=\".pdf\")\n",
    "    with os.fdopen(temp_fd, 'wb') as f:\n",
    "        writer.write(f)\n",
    "\n",
    "    return temp_path\n",
    "\n",
    "def chunk_pdf(pdf_path, dest_pdf=\"Chapter.pdf\",start_page=1, end_page=None):\n",
    "    # Step 1: extract subset of PDF pages into a temporary file\n",
    "    source_pdf = extract_pdf_pages(pdf_path, start_page, end_page or start_page)\n",
    "    print(source_pdf)\n",
    "    shutil.move(source_pdf, dest_pdf)\n",
    "\n",
    "def pdf_to_markdown(pdf_path, md_output=\"output.md\", img_dir=\"images\", dest_pdf=\"test.pdf\", start_page=1, end_page=None):\n",
    "    load_dotenv()\n",
    "    client = Mistral(api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
    "\n",
    "    # Step 1: extract subset of PDF pages into a temporary file\n",
    "    temp_pdf = extract_pdf_pages(pdf_path, start_page, end_page or start_page)\n",
    "\n",
    "    # Step 2: Upload only the extracted portion\n",
    "    with open(temp_pdf, \"rb\") as f:\n",
    "        upload = client.files.upload(\n",
    "            file={\"file_name\": \"subset.pdf\", \"content\": f},\n",
    "            purpose=\"ocr\"\n",
    "        )\n",
    "\n",
    "    # Step 3: Get signed URL\n",
    "    signed = client.files.get_signed_url(file_id=upload.id)\n",
    "\n",
    "    # Step 4: Process OCR (no need for page range since we already split)\n",
    "    resp = client.ocr.process(\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        document={\"type\": \"document_url\", \"document_url\": signed.url},\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    # Step 5: Save Markdown and images\n",
    "    doc_md = \"\"\n",
    "    with open(md_output, \"w\", encoding=\"utf-8\") as mdf:\n",
    "        for i, page in enumerate(resp.pages, start=start_page):\n",
    "            print(f\"Processing page {i}\")\n",
    "            imgs = save_images(page.images or [], img_dir)\n",
    "            markdown = page.markdown\n",
    "            for f in imgs:\n",
    "                markdown = re.sub(rf\"!\\[.*?\\]\\({re.escape(f)}\\)\", f\"![Image]({img_dir}/{f})\", markdown)\n",
    "            mdf.write(markdown + \"\\n\\n\")\n",
    "            doc_md += markdown + \"\\n\\n\"\n",
    "\n",
    "    # Save temp file \n",
    "    shutil.move(temp_pdf, dest_pdf)\n",
    "\n",
    "    print(f\"‚úÖ Markdown saved to '{md_output}' for pages {start_page}-{end_page}, images in '{img_dir}/'\")\n",
    "    return doc_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a4bec2-0fff-45d6-9016-a4b353506e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter markdown Preface.md has been created. Skip it\n",
      "Chapter markdown Chapter_1.md has been created. Skip it\n",
      "Chapter markdown Chapter_2.md has been created. Skip it\n",
      "Chapter markdown Chapter_3.md has been created. Skip it\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_4.pdf Chapter_4_images 185 240\n",
      "Processing page 185\n",
      "Processing page 186\n",
      "Processing page 187\n",
      "Processing page 188\n",
      "Processing page 189\n",
      "Processing page 190\n",
      "Processing page 191\n",
      "Processing page 192\n",
      "Processing page 193\n",
      "Processing page 194\n",
      "Processing page 195\n",
      "Processing page 196\n",
      "Processing page 197\n",
      "Processing page 198\n",
      "Processing page 199\n",
      "Processing page 200\n",
      "Processing page 201\n",
      "Processing page 202\n",
      "Processing page 203\n",
      "Processing page 204\n",
      "Processing page 205\n",
      "Processing page 206\n",
      "Processing page 207\n",
      "Processing page 208\n",
      "Processing page 209\n",
      "Processing page 210\n",
      "Processing page 211\n",
      "Processing page 212\n",
      "Processing page 213\n",
      "Processing page 214\n",
      "Processing page 215\n",
      "Processing page 216\n",
      "Processing page 217\n",
      "Processing page 218\n",
      "Processing page 219\n",
      "Processing page 220\n",
      "Processing page 221\n",
      "Processing page 222\n",
      "Processing page 223\n",
      "Processing page 224\n",
      "Processing page 225\n",
      "Processing page 226\n",
      "Processing page 227\n",
      "Processing page 228\n",
      "Processing page 229\n",
      "Processing page 230\n",
      "Processing page 231\n",
      "Processing page 232\n",
      "Processing page 233\n",
      "Processing page 234\n",
      "Processing page 235\n",
      "Processing page 236\n",
      "Processing page 237\n",
      "Processing page 238\n",
      "Processing page 239\n",
      "Processing page 240\n",
      "‚úÖ Markdown saved to 'Chapter_4.md' for pages 185-240, images in 'Chapter_4_images/'\n",
      "Time =  40.52291679382324\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_5.pdf Chapter_5_images 241 290\n",
      "Processing page 241\n",
      "Processing page 242\n",
      "Processing page 243\n",
      "Processing page 244\n",
      "Processing page 245\n",
      "Processing page 246\n",
      "Processing page 247\n",
      "Processing page 248\n",
      "Processing page 249\n",
      "Processing page 250\n",
      "Processing page 251\n",
      "Processing page 252\n",
      "Processing page 253\n",
      "Processing page 254\n",
      "Processing page 255\n",
      "Processing page 256\n",
      "Processing page 257\n",
      "Processing page 258\n",
      "Processing page 259\n",
      "Processing page 260\n",
      "Processing page 261\n",
      "Processing page 262\n",
      "Processing page 263\n",
      "Processing page 264\n",
      "Processing page 265\n",
      "Processing page 266\n",
      "Processing page 267\n",
      "Processing page 268\n",
      "Processing page 269\n",
      "Processing page 270\n",
      "Processing page 271\n",
      "Processing page 272\n",
      "Processing page 273\n",
      "Processing page 274\n",
      "Processing page 275\n",
      "Processing page 276\n",
      "Processing page 277\n",
      "Processing page 278\n",
      "Processing page 279\n",
      "Processing page 280\n",
      "Processing page 281\n",
      "Processing page 282\n",
      "Processing page 283\n",
      "Processing page 284\n",
      "Processing page 285\n",
      "Processing page 286\n",
      "Processing page 287\n",
      "Processing page 288\n",
      "Processing page 289\n",
      "Processing page 290\n",
      "‚úÖ Markdown saved to 'Chapter_5.md' for pages 241-290, images in 'Chapter_5_images/'\n",
      "Time =  46.606894969940186\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_6.pdf Chapter_6_images 291 352\n",
      "Processing page 291\n",
      "Processing page 292\n",
      "Processing page 293\n",
      "Processing page 294\n",
      "Processing page 295\n",
      "Processing page 296\n",
      "Processing page 297\n",
      "Processing page 298\n",
      "Processing page 299\n",
      "Processing page 300\n",
      "Processing page 301\n",
      "Processing page 302\n",
      "Processing page 303\n",
      "Processing page 304\n",
      "Processing page 305\n",
      "Processing page 306\n",
      "Processing page 307\n",
      "Processing page 308\n",
      "Processing page 309\n",
      "Processing page 310\n",
      "Processing page 311\n",
      "Processing page 312\n",
      "Processing page 313\n",
      "Processing page 314\n",
      "Processing page 315\n",
      "Processing page 316\n",
      "Processing page 317\n",
      "Processing page 318\n",
      "Processing page 319\n",
      "Processing page 320\n",
      "Processing page 321\n",
      "Processing page 322\n",
      "Processing page 323\n",
      "Processing page 324\n",
      "Processing page 325\n",
      "Processing page 326\n",
      "Processing page 327\n",
      "Processing page 328\n",
      "Processing page 329\n",
      "Processing page 330\n",
      "Processing page 331\n",
      "Processing page 332\n",
      "Processing page 333\n",
      "Processing page 334\n",
      "Processing page 335\n",
      "Processing page 336\n",
      "Processing page 337\n",
      "Processing page 338\n",
      "Processing page 339\n",
      "Processing page 340\n",
      "Processing page 341\n",
      "Processing page 342\n",
      "Processing page 343\n",
      "Processing page 344\n",
      "Processing page 345\n",
      "Processing page 346\n",
      "Processing page 347\n",
      "Processing page 348\n",
      "Processing page 349\n",
      "Processing page 350\n",
      "Processing page 351\n",
      "Processing page 352\n",
      "‚úÖ Markdown saved to 'Chapter_6.md' for pages 291-352, images in 'Chapter_6_images/'\n",
      "Time =  52.883469104766846\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_7.pdf Chapter_7_images 353 420\n",
      "Processing page 353\n",
      "Processing page 354\n",
      "Processing page 355\n",
      "Processing page 356\n",
      "Processing page 357\n",
      "Processing page 358\n",
      "Processing page 359\n",
      "Processing page 360\n",
      "Processing page 361\n",
      "Processing page 362\n",
      "Processing page 363\n",
      "Processing page 364\n",
      "Processing page 365\n",
      "Processing page 366\n",
      "Processing page 367\n",
      "Processing page 368\n",
      "Processing page 369\n",
      "Processing page 370\n",
      "Processing page 371\n",
      "Processing page 372\n",
      "Processing page 373\n",
      "Processing page 374\n",
      "Processing page 375\n",
      "Processing page 376\n",
      "Processing page 377\n",
      "Processing page 378\n",
      "Processing page 379\n",
      "Processing page 380\n",
      "Processing page 381\n",
      "Processing page 382\n",
      "Processing page 383\n",
      "Processing page 384\n",
      "Processing page 385\n",
      "Processing page 386\n",
      "Processing page 387\n",
      "Processing page 388\n",
      "Processing page 389\n",
      "Processing page 390\n",
      "Processing page 391\n",
      "Processing page 392\n",
      "Processing page 393\n",
      "Processing page 394\n",
      "Processing page 395\n",
      "Processing page 396\n",
      "Processing page 397\n",
      "Processing page 398\n",
      "Processing page 399\n",
      "Processing page 400\n",
      "Processing page 401\n",
      "Processing page 402\n",
      "Processing page 403\n",
      "Processing page 404\n",
      "Processing page 405\n",
      "Processing page 406\n",
      "Processing page 407\n",
      "Processing page 408\n",
      "Processing page 409\n",
      "Processing page 410\n",
      "Processing page 411\n",
      "Processing page 412\n",
      "Processing page 413\n",
      "Processing page 414\n",
      "Processing page 415\n",
      "Processing page 416\n",
      "Processing page 417\n",
      "Processing page 418\n",
      "Processing page 419\n",
      "Processing page 420\n",
      "‚úÖ Markdown saved to 'Chapter_7.md' for pages 353-420, images in 'Chapter_7_images/'\n",
      "Time =  32.94931507110596\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_8.pdf Chapter_8_images 421 466\n",
      "Processing page 421\n",
      "Processing page 422\n",
      "Processing page 423\n",
      "Processing page 424\n",
      "Processing page 425\n",
      "Processing page 426\n",
      "Processing page 427\n",
      "Processing page 428\n",
      "Processing page 429\n",
      "Processing page 430\n",
      "Processing page 431\n",
      "Processing page 432\n",
      "Processing page 433\n",
      "Processing page 434\n",
      "Processing page 435\n",
      "Processing page 436\n",
      "Processing page 437\n",
      "Processing page 438\n",
      "Processing page 439\n",
      "Processing page 440\n",
      "Processing page 441\n",
      "Processing page 442\n",
      "Processing page 443\n",
      "Processing page 444\n",
      "Processing page 445\n",
      "Processing page 446\n",
      "Processing page 447\n",
      "Processing page 448\n",
      "Processing page 449\n",
      "Processing page 450\n",
      "Processing page 451\n",
      "Processing page 452\n",
      "Processing page 453\n",
      "Processing page 454\n",
      "Processing page 455\n",
      "Processing page 456\n",
      "Processing page 457\n",
      "Processing page 458\n",
      "Processing page 459\n",
      "Processing page 460\n",
      "Processing page 461\n",
      "Processing page 462\n",
      "Processing page 463\n",
      "Processing page 464\n",
      "Processing page 465\n",
      "Processing page 466\n",
      "‚úÖ Markdown saved to 'Chapter_8.md' for pages 421-466, images in 'Chapter_8_images/'\n",
      "Time =  29.320015907287598\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_9.pdf Chapter_9_images 467 530\n",
      "Processing page 467\n",
      "Processing page 468\n",
      "Processing page 469\n",
      "Processing page 470\n",
      "Processing page 471\n",
      "Processing page 472\n",
      "Processing page 473\n",
      "Processing page 474\n",
      "Processing page 475\n",
      "Processing page 476\n",
      "Processing page 477\n",
      "Processing page 478\n",
      "Processing page 479\n",
      "Processing page 480\n",
      "Processing page 481\n",
      "Processing page 482\n",
      "Processing page 483\n",
      "Processing page 484\n",
      "Processing page 485\n",
      "Processing page 486\n",
      "Processing page 487\n",
      "Processing page 488\n",
      "Processing page 489\n",
      "Processing page 490\n",
      "Processing page 491\n",
      "Processing page 492\n",
      "Processing page 493\n",
      "Processing page 494\n",
      "Processing page 495\n",
      "Processing page 496\n",
      "Processing page 497\n",
      "Processing page 498\n",
      "Processing page 499\n",
      "Processing page 500\n",
      "Processing page 501\n",
      "Processing page 502\n",
      "Processing page 503\n",
      "Processing page 504\n",
      "Processing page 505\n",
      "Processing page 506\n",
      "Processing page 507\n",
      "Processing page 508\n",
      "Processing page 509\n",
      "Processing page 510\n",
      "Processing page 511\n",
      "Processing page 512\n",
      "Processing page 513\n",
      "Processing page 514\n",
      "Processing page 515\n",
      "Processing page 516\n",
      "Processing page 517\n",
      "Processing page 518\n",
      "Processing page 519\n",
      "Processing page 520\n",
      "Processing page 521\n",
      "Processing page 522\n",
      "Processing page 523\n",
      "Processing page 524\n",
      "Processing page 525\n",
      "Processing page 526\n",
      "Processing page 527\n",
      "Processing page 528\n",
      "Processing page 529\n",
      "Processing page 530\n",
      "‚úÖ Markdown saved to 'Chapter_9.md' for pages 467-530, images in 'Chapter_9_images/'\n",
      "Time =  56.0579469203949\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_10.pdf Chapter_10_images 531 608\n",
      "Processing page 531\n",
      "Processing page 532\n",
      "Processing page 533\n",
      "Processing page 534\n",
      "Processing page 535\n",
      "Processing page 536\n",
      "Processing page 537\n",
      "Processing page 538\n",
      "Processing page 539\n",
      "Processing page 540\n",
      "Processing page 541\n",
      "Processing page 542\n",
      "Processing page 543\n",
      "Processing page 544\n",
      "Processing page 545\n",
      "Processing page 546\n",
      "Processing page 547\n",
      "Processing page 548\n",
      "Processing page 549\n",
      "Processing page 550\n",
      "Processing page 551\n",
      "Processing page 552\n",
      "Processing page 553\n",
      "Processing page 554\n",
      "Processing page 555\n",
      "Processing page 556\n",
      "Processing page 557\n",
      "Processing page 558\n",
      "Processing page 559\n",
      "Processing page 560\n",
      "Processing page 561\n",
      "Processing page 562\n",
      "Processing page 563\n",
      "Processing page 564\n",
      "Processing page 565\n",
      "Processing page 566\n",
      "Processing page 567\n",
      "Processing page 568\n",
      "Processing page 569\n",
      "Processing page 570\n",
      "Processing page 571\n",
      "Processing page 572\n",
      "Processing page 573\n",
      "Processing page 574\n",
      "Processing page 575\n",
      "Processing page 576\n",
      "Processing page 577\n",
      "Processing page 578\n",
      "Processing page 579\n",
      "Processing page 580\n",
      "Processing page 581\n",
      "Processing page 582\n",
      "Processing page 583\n",
      "Processing page 584\n",
      "Processing page 585\n",
      "Processing page 586\n",
      "Processing page 587\n",
      "Processing page 588\n",
      "Processing page 589\n",
      "Processing page 590\n",
      "Processing page 591\n",
      "Processing page 592\n",
      "Processing page 593\n",
      "Processing page 594\n",
      "Processing page 595\n",
      "Processing page 596\n",
      "Processing page 597\n",
      "Processing page 598\n",
      "Processing page 599\n",
      "Processing page 600\n",
      "Processing page 601\n",
      "Processing page 602\n",
      "Processing page 603\n",
      "Processing page 604\n",
      "Processing page 605\n",
      "Processing page 606\n",
      "Processing page 607\n",
      "Processing page 608\n",
      "‚úÖ Markdown saved to 'Chapter_10.md' for pages 531-608, images in 'Chapter_10_images/'\n",
      "Time =  60.59434485435486\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_11.pdf Chapter_11_images 609 666\n",
      "Processing page 609\n",
      "Processing page 610\n",
      "Processing page 611\n",
      "Processing page 612\n",
      "Processing page 613\n",
      "Processing page 614\n",
      "Processing page 615\n",
      "Processing page 616\n",
      "Processing page 617\n",
      "Processing page 618\n",
      "Processing page 619\n",
      "Processing page 620\n",
      "Processing page 621\n",
      "Processing page 622\n",
      "Processing page 623\n",
      "Processing page 624\n",
      "Processing page 625\n",
      "Processing page 626\n",
      "Processing page 627\n",
      "Processing page 628\n",
      "Processing page 629\n",
      "Processing page 630\n",
      "Processing page 631\n",
      "Processing page 632\n",
      "Processing page 633\n",
      "Processing page 634\n",
      "Processing page 635\n",
      "Processing page 636\n",
      "Processing page 637\n",
      "Processing page 638\n",
      "Processing page 639\n",
      "Processing page 640\n",
      "Processing page 641\n",
      "Processing page 642\n",
      "Processing page 643\n",
      "Processing page 644\n",
      "Processing page 645\n",
      "Processing page 646\n",
      "Processing page 647\n",
      "Processing page 648\n",
      "Processing page 649\n",
      "Processing page 650\n",
      "Processing page 651\n",
      "Processing page 652\n",
      "Processing page 653\n",
      "Processing page 654\n",
      "Processing page 655\n",
      "Processing page 656\n",
      "Processing page 657\n",
      "Processing page 658\n",
      "Processing page 659\n",
      "Processing page 660\n",
      "Processing page 661\n",
      "Processing page 662\n",
      "Processing page 663\n",
      "Processing page 664\n",
      "Processing page 665\n",
      "Processing page 666\n",
      "‚úÖ Markdown saved to 'Chapter_11.md' for pages 609-666, images in 'Chapter_11_images/'\n",
      "Time =  61.65857291221619\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_12.pdf Chapter_12_images 667 730\n",
      "Processing page 667\n",
      "Processing page 668\n",
      "Processing page 669\n",
      "Processing page 670\n",
      "Processing page 671\n",
      "Processing page 672\n",
      "Processing page 673\n",
      "Processing page 674\n",
      "Processing page 675\n",
      "Processing page 676\n",
      "Processing page 677\n",
      "Processing page 678\n",
      "Processing page 679\n",
      "Processing page 680\n",
      "Processing page 681\n",
      "Processing page 682\n",
      "Processing page 683\n",
      "Processing page 684\n",
      "Processing page 685\n",
      "Processing page 686\n",
      "Processing page 687\n",
      "Processing page 688\n",
      "Processing page 689\n",
      "Processing page 690\n",
      "Processing page 691\n",
      "Processing page 692\n",
      "Processing page 693\n",
      "Processing page 694\n",
      "Processing page 695\n",
      "Processing page 696\n",
      "Processing page 697\n",
      "Processing page 698\n",
      "Processing page 699\n",
      "Processing page 700\n",
      "Processing page 701\n",
      "Processing page 702\n",
      "Processing page 703\n",
      "Processing page 704\n",
      "Processing page 705\n",
      "Processing page 706\n",
      "Processing page 707\n",
      "Processing page 708\n",
      "Processing page 709\n",
      "Processing page 710\n",
      "Processing page 711\n",
      "Processing page 712\n",
      "Processing page 713\n",
      "Processing page 714\n",
      "Processing page 715\n",
      "Processing page 716\n",
      "Processing page 717\n",
      "Processing page 718\n",
      "Processing page 719\n",
      "Processing page 720\n",
      "Processing page 721\n",
      "Processing page 722\n",
      "Processing page 723\n",
      "Processing page 724\n",
      "Processing page 725\n",
      "Processing page 726\n",
      "Processing page 727\n",
      "Processing page 728\n",
      "Processing page 729\n",
      "Processing page 730\n",
      "‚úÖ Markdown saved to 'Chapter_12.md' for pages 667-730, images in 'Chapter_12_images/'\n",
      "Time =  35.991427183151245\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_13.pdf Chapter_13_images 731 772\n",
      "Processing page 731\n",
      "Processing page 732\n",
      "Processing page 733\n",
      "Processing page 734\n",
      "Processing page 735\n",
      "Processing page 736\n",
      "Processing page 737\n",
      "Processing page 738\n",
      "Processing page 739\n",
      "Processing page 740\n",
      "Processing page 741\n",
      "Processing page 742\n",
      "Processing page 743\n",
      "Processing page 744\n",
      "Processing page 745\n",
      "Processing page 746\n",
      "Processing page 747\n",
      "Processing page 748\n",
      "Processing page 749\n",
      "Processing page 750\n",
      "Processing page 751\n",
      "Processing page 752\n",
      "Processing page 753\n",
      "Processing page 754\n",
      "Processing page 755\n",
      "Processing page 756\n",
      "Processing page 757\n",
      "Processing page 758\n",
      "Processing page 759\n",
      "Processing page 760\n",
      "Processing page 761\n",
      "Processing page 762\n",
      "Processing page 763\n",
      "Processing page 764\n",
      "Processing page 765\n",
      "Processing page 766\n",
      "Processing page 767\n",
      "Processing page 768\n",
      "Processing page 769\n",
      "Processing page 770\n",
      "Processing page 771\n",
      "Processing page 772\n",
      "‚úÖ Markdown saved to 'Chapter_13.md' for pages 731-772, images in 'Chapter_13_images/'\n",
      "Time =  17.687969207763672\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_14.pdf Chapter_14_images 773 832\n",
      "Processing page 773\n",
      "Processing page 774\n",
      "Processing page 775\n",
      "Processing page 776\n",
      "Processing page 777\n",
      "Processing page 778\n",
      "Processing page 779\n",
      "Processing page 780\n",
      "Processing page 781\n",
      "Processing page 782\n",
      "Processing page 783\n",
      "Processing page 784\n",
      "Processing page 785\n",
      "Processing page 786\n",
      "Processing page 787\n",
      "Processing page 788\n",
      "Processing page 789\n",
      "Processing page 790\n",
      "Processing page 791\n",
      "Processing page 792\n",
      "Processing page 793\n",
      "Processing page 794\n",
      "Processing page 795\n",
      "Processing page 796\n",
      "Processing page 797\n",
      "Processing page 798\n",
      "Processing page 799\n",
      "Processing page 800\n",
      "Processing page 801\n",
      "Processing page 802\n",
      "Processing page 803\n",
      "Processing page 804\n",
      "Processing page 805\n",
      "Processing page 806\n",
      "Processing page 807\n",
      "Processing page 808\n",
      "Processing page 809\n",
      "Processing page 810\n",
      "Processing page 811\n",
      "Processing page 812\n",
      "Processing page 813\n",
      "Processing page 814\n",
      "Processing page 815\n",
      "Processing page 816\n",
      "Processing page 817\n",
      "Processing page 818\n",
      "Processing page 819\n",
      "Processing page 820\n",
      "Processing page 821\n",
      "Processing page 822\n",
      "Processing page 823\n",
      "Processing page 824\n",
      "Processing page 825\n",
      "Processing page 826\n",
      "Processing page 827\n",
      "Processing page 828\n",
      "Processing page 829\n",
      "Processing page 830\n",
      "Processing page 831\n",
      "Processing page 832\n",
      "‚úÖ Markdown saved to 'Chapter_14.md' for pages 773-832, images in 'Chapter_14_images/'\n",
      "Time =  53.639549016952515\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_15.pdf Chapter_15_images 833 870\n",
      "Processing page 833\n",
      "Processing page 834\n",
      "Processing page 835\n",
      "Processing page 836\n",
      "Processing page 837\n",
      "Processing page 838\n",
      "Processing page 839\n",
      "Processing page 840\n",
      "Processing page 841\n",
      "Processing page 842\n",
      "Processing page 843\n",
      "Processing page 844\n",
      "Processing page 845\n",
      "Processing page 846\n",
      "Processing page 847\n",
      "Processing page 848\n",
      "Processing page 849\n",
      "Processing page 850\n",
      "Processing page 851\n",
      "Processing page 852\n",
      "Processing page 853\n",
      "Processing page 854\n",
      "Processing page 855\n",
      "Processing page 856\n",
      "Processing page 857\n",
      "Processing page 858\n",
      "Processing page 859\n",
      "Processing page 860\n",
      "Processing page 861\n",
      "Processing page 862\n",
      "Processing page 863\n",
      "Processing page 864\n",
      "Processing page 865\n",
      "Processing page 866\n",
      "Processing page 867\n",
      "Processing page 868\n",
      "Processing page 869\n",
      "Processing page 870\n",
      "‚úÖ Markdown saved to 'Chapter_15.md' for pages 833-870, images in 'Chapter_15_images/'\n",
      "Time =  17.967584133148193\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_16.pdf Chapter_16_images 871 906\n",
      "Processing page 871\n",
      "Processing page 872\n",
      "Processing page 873\n",
      "Processing page 874\n",
      "Processing page 875\n",
      "Processing page 876\n",
      "Processing page 877\n",
      "Processing page 878\n",
      "Processing page 879\n",
      "Processing page 880\n",
      "Processing page 881\n",
      "Processing page 882\n",
      "Processing page 883\n",
      "Processing page 884\n",
      "Processing page 885\n",
      "Processing page 886\n",
      "Processing page 887\n",
      "Processing page 888\n",
      "Processing page 889\n",
      "Processing page 890\n",
      "Processing page 891\n",
      "Processing page 892\n",
      "Processing page 893\n",
      "Processing page 894\n",
      "Processing page 895\n",
      "Processing page 896\n",
      "Processing page 897\n",
      "Processing page 898\n",
      "Processing page 899\n",
      "Processing page 900\n",
      "Processing page 901\n",
      "Processing page 902\n",
      "Processing page 903\n",
      "Processing page 904\n",
      "Processing page 905\n",
      "Processing page 906\n",
      "‚úÖ Markdown saved to 'Chapter_16.md' for pages 871-906, images in 'Chapter_16_images/'\n",
      "Time =  16.862574815750122\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_17.pdf Chapter_17_images 907 950\n",
      "Processing page 907\n",
      "Processing page 908\n",
      "Processing page 909\n",
      "Processing page 910\n",
      "Processing page 911\n",
      "Processing page 912\n",
      "Processing page 913\n",
      "Processing page 914\n",
      "Processing page 915\n",
      "Processing page 916\n",
      "Processing page 917\n",
      "Processing page 918\n",
      "Processing page 919\n",
      "Processing page 920\n",
      "Processing page 921\n",
      "Processing page 922\n",
      "Processing page 923\n",
      "Processing page 924\n",
      "Processing page 925\n",
      "Processing page 926\n",
      "Processing page 927\n",
      "Processing page 928\n",
      "Processing page 929\n",
      "Processing page 930\n",
      "Processing page 931\n",
      "Processing page 932\n",
      "Processing page 933\n",
      "Processing page 934\n",
      "Processing page 935\n",
      "Processing page 936\n",
      "Processing page 937\n",
      "Processing page 938\n",
      "Processing page 939\n",
      "Processing page 940\n",
      "Processing page 941\n",
      "Processing page 942\n",
      "Processing page 943\n",
      "Processing page 944\n",
      "Processing page 945\n",
      "Processing page 946\n",
      "Processing page 947\n",
      "Processing page 948\n",
      "Processing page 949\n",
      "Processing page 950\n",
      "‚úÖ Markdown saved to 'Chapter_17.md' for pages 907-950, images in 'Chapter_17_images/'\n",
      "Time =  22.344467878341675\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_18.pdf Chapter_18_images 951 1038\n",
      "Processing page 951\n",
      "Processing page 952\n",
      "Processing page 953\n",
      "Processing page 954\n",
      "Processing page 955\n",
      "Processing page 956\n",
      "Processing page 957\n",
      "Processing page 958\n",
      "Processing page 959\n",
      "Processing page 960\n",
      "Processing page 961\n",
      "Processing page 962\n",
      "Processing page 963\n",
      "Processing page 964\n",
      "Processing page 965\n",
      "Processing page 966\n",
      "Processing page 967\n",
      "Processing page 968\n",
      "Processing page 969\n",
      "Processing page 970\n",
      "Processing page 971\n",
      "Processing page 972\n",
      "Processing page 973\n",
      "Processing page 974\n",
      "Processing page 975\n",
      "Processing page 976\n",
      "Processing page 977\n",
      "Processing page 978\n",
      "Processing page 979\n",
      "Processing page 980\n",
      "Processing page 981\n",
      "Processing page 982\n",
      "Processing page 983\n",
      "Processing page 984\n",
      "Processing page 985\n",
      "Processing page 986\n",
      "Processing page 987\n",
      "Processing page 988\n",
      "Processing page 989\n",
      "Processing page 990\n",
      "Processing page 991\n",
      "Processing page 992\n",
      "Processing page 993\n",
      "Processing page 994\n",
      "Processing page 995\n",
      "Processing page 996\n",
      "Processing page 997\n",
      "Processing page 998\n",
      "Processing page 999\n",
      "Processing page 1000\n",
      "Processing page 1001\n",
      "Processing page 1002\n",
      "Processing page 1003\n",
      "Processing page 1004\n",
      "Processing page 1005\n",
      "Processing page 1006\n",
      "Processing page 1007\n",
      "Processing page 1008\n",
      "Processing page 1009\n",
      "Processing page 1010\n",
      "Processing page 1011\n",
      "Processing page 1012\n",
      "Processing page 1013\n",
      "Processing page 1014\n",
      "Processing page 1015\n",
      "Processing page 1016\n",
      "Processing page 1017\n",
      "Processing page 1018\n",
      "Processing page 1019\n",
      "Processing page 1020\n",
      "Processing page 1021\n",
      "Processing page 1022\n",
      "Processing page 1023\n",
      "Processing page 1024\n",
      "Processing page 1025\n",
      "Processing page 1026\n",
      "Processing page 1027\n",
      "Processing page 1028\n",
      "Processing page 1029\n",
      "Processing page 1030\n",
      "Processing page 1031\n",
      "Processing page 1032\n",
      "Processing page 1033\n",
      "Processing page 1034\n",
      "Processing page 1035\n",
      "Processing page 1036\n",
      "Processing page 1037\n",
      "Processing page 1038\n",
      "‚úÖ Markdown saved to 'Chapter_18.md' for pages 951-1038, images in 'Chapter_18_images/'\n",
      "Time =  44.920467138290405\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_19.pdf Chapter_19_images 1039 1086\n",
      "Processing page 1039\n",
      "Processing page 1040\n",
      "Processing page 1041\n",
      "Processing page 1042\n",
      "Processing page 1043\n",
      "Processing page 1044\n",
      "Processing page 1045\n",
      "Processing page 1046\n",
      "Processing page 1047\n",
      "Processing page 1048\n",
      "Processing page 1049\n",
      "Processing page 1050\n",
      "Processing page 1051\n",
      "Processing page 1052\n",
      "Processing page 1053\n",
      "Processing page 1054\n",
      "Processing page 1055\n",
      "Processing page 1056\n",
      "Processing page 1057\n",
      "Processing page 1058\n",
      "Processing page 1059\n",
      "Processing page 1060\n",
      "Processing page 1061\n",
      "Processing page 1062\n",
      "Processing page 1063\n",
      "Processing page 1064\n",
      "Processing page 1065\n",
      "Processing page 1066\n",
      "Processing page 1067\n",
      "Processing page 1068\n",
      "Processing page 1069\n",
      "Processing page 1070\n",
      "Processing page 1071\n",
      "Processing page 1072\n",
      "Processing page 1073\n",
      "Processing page 1074\n",
      "Processing page 1075\n",
      "Processing page 1076\n",
      "Processing page 1077\n",
      "Processing page 1078\n",
      "Processing page 1079\n",
      "Processing page 1080\n",
      "Processing page 1081\n",
      "Processing page 1082\n",
      "Processing page 1083\n",
      "Processing page 1084\n",
      "Processing page 1085\n",
      "Processing page 1086\n",
      "‚úÖ Markdown saved to 'Chapter_19.md' for pages 1039-1086, images in 'Chapter_19_images/'\n",
      "Time =  45.26412296295166\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_20.pdf Chapter_20_images 1087 1136\n",
      "Processing page 1087\n",
      "Processing page 1088\n",
      "Processing page 1089\n",
      "Processing page 1090\n",
      "Processing page 1091\n",
      "Processing page 1092\n",
      "Processing page 1093\n",
      "Processing page 1094\n",
      "Processing page 1095\n",
      "Processing page 1096\n",
      "Processing page 1097\n",
      "Processing page 1098\n",
      "Processing page 1099\n",
      "Processing page 1100\n",
      "Processing page 1101\n",
      "Processing page 1102\n",
      "Processing page 1103\n",
      "Processing page 1104\n",
      "Processing page 1105\n",
      "Processing page 1106\n",
      "Processing page 1107\n",
      "Processing page 1108\n",
      "Processing page 1109\n",
      "Processing page 1110\n",
      "Processing page 1111\n",
      "Processing page 1112\n",
      "Processing page 1113\n",
      "Processing page 1114\n",
      "Processing page 1115\n",
      "Processing page 1116\n",
      "Processing page 1117\n",
      "Processing page 1118\n",
      "Processing page 1119\n",
      "Processing page 1120\n",
      "Processing page 1121\n",
      "Processing page 1122\n",
      "Processing page 1123\n",
      "Processing page 1124\n",
      "Processing page 1125\n",
      "Processing page 1126\n",
      "Processing page 1127\n",
      "Processing page 1128\n",
      "Processing page 1129\n",
      "Processing page 1130\n",
      "Processing page 1131\n",
      "Processing page 1132\n",
      "Processing page 1133\n",
      "Processing page 1134\n",
      "Processing page 1135\n",
      "Processing page 1136\n",
      "‚úÖ Markdown saved to 'Chapter_20.md' for pages 1087-1136, images in 'Chapter_20_images/'\n",
      "Time =  32.620686054229736\n",
      "dest_pdf, md_file, image_folder, start, end =  Chapter_21.pdf Chapter_21_images 1137 1198\n",
      "Processing page 1137\n",
      "Processing page 1138\n",
      "Processing page 1139\n",
      "Processing page 1140\n",
      "Processing page 1141\n",
      "Processing page 1142\n",
      "Processing page 1143\n",
      "Processing page 1144\n",
      "Processing page 1145\n",
      "Processing page 1146\n",
      "Processing page 1147\n",
      "Processing page 1148\n",
      "Processing page 1149\n",
      "Processing page 1150\n",
      "Processing page 1151\n",
      "Processing page 1152\n",
      "Processing page 1153\n",
      "Processing page 1154\n",
      "Processing page 1155\n",
      "Processing page 1156\n",
      "Processing page 1157\n",
      "Processing page 1158\n",
      "Processing page 1159\n",
      "Processing page 1160\n",
      "Processing page 1161\n",
      "Processing page 1162\n",
      "Processing page 1163\n",
      "Processing page 1164\n",
      "Processing page 1165\n",
      "Processing page 1166\n",
      "Processing page 1167\n",
      "Processing page 1168\n",
      "Processing page 1169\n",
      "Processing page 1170\n",
      "Processing page 1171\n",
      "Processing page 1172\n",
      "Processing page 1173\n",
      "Processing page 1174\n",
      "Processing page 1175\n",
      "Processing page 1176\n",
      "Processing page 1177\n",
      "Processing page 1178\n",
      "Processing page 1179\n",
      "Processing page 1180\n",
      "Processing page 1181\n",
      "Processing page 1182\n",
      "Processing page 1183\n",
      "Processing page 1184\n",
      "Processing page 1185\n",
      "Processing page 1186\n",
      "Processing page 1187\n",
      "Processing page 1188\n",
      "Processing page 1189\n",
      "Processing page 1190\n",
      "Processing page 1191\n",
      "Processing page 1192\n",
      "Processing page 1193\n",
      "Processing page 1194\n",
      "Processing page 1195\n",
      "Processing page 1196\n",
      "Processing page 1197\n",
      "Processing page 1198\n",
      "‚úÖ Markdown saved to 'Chapter_21.md' for pages 1137-1198, images in 'Chapter_21_images/'\n",
      "Time =  39.2725088596344\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_A.pdf Appendix_A_images 1199 1200\n",
      "Processing page 1199\n",
      "Processing page 1200\n",
      "‚úÖ Markdown saved to 'Appendix_A.md' for pages 1199-1200, images in 'Appendix_A_images/'\n",
      "Time =  6.653908014297485\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_B.pdf Appendix_B_images 1201 1208\n",
      "Processing page 1201\n",
      "Processing page 1202\n",
      "Processing page 1203\n",
      "Processing page 1204\n",
      "Processing page 1205\n",
      "Processing page 1206\n",
      "Processing page 1207\n",
      "Processing page 1208\n",
      "‚úÖ Markdown saved to 'Appendix_B.md' for pages 1201-1208, images in 'Appendix_B_images/'\n",
      "Time =  4.683158874511719\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_C.pdf Appendix_C_images 1209 1210\n",
      "Processing page 1209\n",
      "Processing page 1210\n",
      "‚úÖ Markdown saved to 'Appendix_C.md' for pages 1209-1210, images in 'Appendix_C_images/'\n",
      "Time =  3.5472238063812256\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_D.pdf Appendix_D_images 1211 1212\n",
      "Processing page 1211\n",
      "Processing page 1212\n",
      "‚úÖ Markdown saved to 'Appendix_D.md' for pages 1211-1212, images in 'Appendix_D_images/'\n",
      "Time =  3.31978178024292\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_E.pdf Appendix_E_images 1213 1218\n",
      "Processing page 1213\n",
      "Processing page 1214\n",
      "Processing page 1215\n",
      "Processing page 1216\n",
      "Processing page 1217\n",
      "Processing page 1218\n",
      "‚úÖ Markdown saved to 'Appendix_E.md' for pages 1213-1218, images in 'Appendix_E_images/'\n",
      "Time =  4.039853811264038\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_F.pdf Appendix_F_images 1219 1220\n",
      "Processing page 1219\n",
      "Processing page 1220\n",
      "‚úÖ Markdown saved to 'Appendix_F.md' for pages 1219-1220, images in 'Appendix_F_images/'\n",
      "Time =  2.7300772666931152\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_G.pdf Appendix_G_images 1221 1234\n",
      "Processing page 1221\n",
      "Processing page 1222\n",
      "Processing page 1223\n",
      "Processing page 1224\n",
      "Processing page 1225\n",
      "Processing page 1226\n",
      "Processing page 1227\n",
      "Processing page 1228\n",
      "Processing page 1229\n",
      "Processing page 1230\n",
      "Processing page 1231\n",
      "Processing page 1232\n",
      "Processing page 1233\n",
      "Processing page 1234\n",
      "‚úÖ Markdown saved to 'Appendix_G.md' for pages 1221-1234, images in 'Appendix_G_images/'\n",
      "Time =  6.762809991836548\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_H.pdf Appendix_H_images 1235 1238\n",
      "Processing page 1235\n",
      "Processing page 1236\n",
      "Processing page 1237\n",
      "Processing page 1238\n",
      "‚úÖ Markdown saved to 'Appendix_H.md' for pages 1235-1238, images in 'Appendix_H_images/'\n",
      "Time =  5.261406898498535\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_I.pdf Appendix_I_images 1239 1240\n",
      "Processing page 1239\n",
      "Processing page 1240\n",
      "‚úÖ Markdown saved to 'Appendix_I.md' for pages 1239-1240, images in 'Appendix_I_images/'\n",
      "Time =  3.117548704147339\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_J.pdf Appendix_J_images 1241 1244\n",
      "Processing page 1241\n",
      "Processing page 1242\n",
      "Processing page 1243\n",
      "Processing page 1244\n",
      "‚úÖ Markdown saved to 'Appendix_J.md' for pages 1241-1244, images in 'Appendix_J_images/'\n",
      "Time =  4.658265113830566\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_K.pdf Appendix_K_images 1245 1246\n",
      "Processing page 1245\n",
      "Processing page 1246\n",
      "‚úÖ Markdown saved to 'Appendix_K.md' for pages 1245-1246, images in 'Appendix_K_images/'\n",
      "Time =  4.196781158447266\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_L.pdf Appendix_L_images 1247 1252\n",
      "Processing page 1247\n",
      "Processing page 1248\n",
      "Processing page 1249\n",
      "Processing page 1250\n",
      "Processing page 1251\n",
      "Processing page 1252\n",
      "‚úÖ Markdown saved to 'Appendix_L.md' for pages 1247-1252, images in 'Appendix_L_images/'\n",
      "Time =  4.767870187759399\n",
      "dest_pdf, md_file, image_folder, start, end =  Appendix_M.pdf Appendix_M_images 1253 1322\n",
      "Processing page 1253\n",
      "Processing page 1254\n",
      "Processing page 1255\n",
      "Processing page 1256\n",
      "Processing page 1257\n",
      "Processing page 1258\n",
      "Processing page 1259\n",
      "Processing page 1260\n",
      "Processing page 1261\n",
      "Processing page 1262\n",
      "Processing page 1263\n",
      "Processing page 1264\n",
      "Processing page 1265\n",
      "Processing page 1266\n",
      "Processing page 1267\n",
      "Processing page 1268\n",
      "Processing page 1269\n",
      "Processing page 1270\n",
      "Processing page 1271\n",
      "Processing page 1272\n",
      "Processing page 1273\n",
      "Processing page 1274\n",
      "Processing page 1275\n",
      "Processing page 1276\n",
      "Processing page 1277\n",
      "Processing page 1278\n",
      "Processing page 1279\n",
      "Processing page 1280\n",
      "Processing page 1281\n",
      "Processing page 1282\n",
      "Processing page 1283\n",
      "Processing page 1284\n",
      "Processing page 1285\n",
      "Processing page 1286\n",
      "Processing page 1287\n",
      "Processing page 1288\n",
      "Processing page 1289\n",
      "Processing page 1290\n",
      "Processing page 1291\n",
      "Processing page 1292\n",
      "Processing page 1293\n",
      "Processing page 1294\n",
      "Processing page 1295\n",
      "Processing page 1296\n",
      "Processing page 1297\n",
      "Processing page 1298\n",
      "Processing page 1299\n",
      "Processing page 1300\n",
      "Processing page 1301\n",
      "Processing page 1302\n",
      "Processing page 1303\n",
      "Processing page 1304\n",
      "Processing page 1305\n",
      "Processing page 1306\n",
      "Processing page 1307\n",
      "Processing page 1308\n",
      "Processing page 1309\n",
      "Processing page 1310\n",
      "Processing page 1311\n",
      "Processing page 1312\n",
      "Processing page 1313\n",
      "Processing page 1314\n",
      "Processing page 1315\n",
      "Processing page 1316\n",
      "Processing page 1317\n",
      "Processing page 1318\n",
      "Processing page 1319\n",
      "Processing page 1320\n",
      "Processing page 1321\n",
      "Processing page 1322\n",
      "‚úÖ Markdown saved to 'Appendix_M.md' for pages 1253-1322, images in 'Appendix_M_images/'\n",
      "Time =  139.29327583312988\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(starting_pages)-1):\n",
    "    \n",
    "    start_page = starting_pages[idx][1]\n",
    "    dest_pdf = starting_pages[idx][0] + \".pdf\"\n",
    "    image_folder = starting_pages[idx][0] + \"_images\"\n",
    "    md_file = starting_pages[idx][0] + \".md\"\n",
    "    if (idx+1 < len(starting_pages)):\n",
    "        end_page = starting_pages[idx+1][1]-1\n",
    "    else:\n",
    "        end_page = 1331\n",
    "    \n",
    "    pdf_path = \"Chemistry2e-OP.pdf\"\n",
    "    if os.path.exists(md_file):\n",
    "        print(f\"Chapter markdown {md_file} has been created. Skip it\")\n",
    "        continue\n",
    "\n",
    "    time1 = time.time()\n",
    "    print(\"dest_pdf, md_file, image_folder, start, end = \", dest_pdf, image_folder, start_page, end_page)\n",
    "    #chunk_pdf(pdf_path, dest_pdf, start_page, end_page)\n",
    "    pdf_to_markdown(pdf_path, md_file, image_folder, dest_pdf, start_page, end_page)\n",
    "    \n",
    "    print(\"Time = \", time.time()-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93f3b5-cd03-428d-8af9-07c03deeb107",
   "metadata": {},
   "source": [
    "# Chapter 1 \n",
    "\n",
    "## Essential Ideas\n",
    "\n",
    "![Image](Chapter_1_images/img-0.jpeg)\n",
    "\n",
    "Figure 1.1 Chemical substances and processes are essential for our existence, providing sustenance, keeping us clean and healthy, fabricating electronic devices, enabling transportation, and much more. (credit \"left\": modification of work by \"vxla\"/Flickr; credit \"left middle\": modification of work by \"the Italian voice\"/Flickr; credit \"right middle\": modification of work by Jason Trim; credit \"right\": modification of work by \"gosheshe\"/Flickr)\n",
    "\n",
    "## Chapter Outline\n",
    "\n",
    "1.1 Chemistry in Context\n",
    "1.2 Phases and Classification of Matter\n",
    "1.3 Physical and Chemical Properties\n",
    "1.4 Measurements\n",
    "1.5 Measurement Uncertainty, Accuracy, and Precision\n",
    "1.6 Mathematical Treatment of Measurement Results\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your alarm goes off and, after hitting \"snooze\" once or twice, you pry yourself out of bed. You make a cup of coffee to help you get going, and then you shower, get dressed, eat breakfast, and check your phone for messages. On your way to school, you stop to fill your car's gas tank, almost making you late for the first day of chemistry class. As you find a seat in the classroom, you read the question projected on the screen: \"Welcome to class! Why should we study chemistry?\"\n",
    "\n",
    "Do you have an answer? You may be studying chemistry because it fulfills an academic requirement, but if you consider your daily activities, you might find chemistry interesting for other reasons. Most everything you do and encounter during your day involves chemistry. Making coffee, cooking eggs, and toasting bread involve chemistry. The products you use-like soap and shampoo, the fabrics you wear, the electronics that keep you connected to your world, the gasoline that propels your car-all of these and more involve chemical substances and processes. Whether you are aware or not, chemistry is part of your everyday world. In this course, you will learn many of the essential principles underlying the chemistry of modern-day life.\n",
    "\n",
    "# 1.1 Chemistry in Context \n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "- Outline the historical development of chemistry\n",
    "- Provide examples of the importance of chemistry in everyday life\n",
    "- Describe the scientific method\n",
    "- Differentiate among hypotheses, theories, and laws\n",
    "- Provide examples illustrating macroscopic, microscopic, and symbolic domains\n",
    "\n",
    "Throughout human history, people have tried to convert matter into more useful forms. Our Stone Age ancestors chipped pieces of flint into useful tools and carved wood into statues and toys. These endeavors involved changing the shape of a substance without changing the substance itself. But as our knowledge increased, humans began to change the composition of the substances as well-clay was converted into pottery, hides were cured to make garments, copper ores were transformed into copper tools and weapons, and grain was made into bread.\n",
    "Humans began to practice chemistry when they learned to control fire and use it to cook, make pottery, and smelt metals. Subsequently, they began to separate and use specific components of matter. A variety of drugs such as aloe, myrrh, and opium were isolated from plants. Dyes, such as indigo and Tyrian purple, were extracted from plant and animal matter. Metals were combined to form alloys-for example, copper and tin were mixed together to make bronze-and more elaborate smelting techniques produced iron. Alkalis were extracted from ashes, and soaps were prepared by combining these alkalis with fats. Alcohol was produced by fermentation and purified by distillation.\n",
    "Attempts to understand the behavior of matter extend back for more than 2500 years. As early as the sixth century BC, Greek philosophers discussed a system in which water was the basis of all things. You may have heard of the Greek postulate that matter consists of four elements: earth, air, fire, and water. Subsequently, an amalgamation of chemical technologies and philosophical speculations was spread from Egypt, China, and the eastern Mediterranean by alchemists, who endeavored to transform \"base metals\" such as lead into \"noble metals\" like gold, and to create elixirs to cure disease and extend life (Figure 1.2).\n",
    "\n",
    "![Image](Chapter_1_images/img-1.jpeg)\n",
    "\n",
    "Figure 1.2 This portrayal shows an alchemist's workshop circa 1580. Although alchemy made some useful contributions to how to manipulate matter, it was not scientific by modern standards. (credit: Chemical Heritage Foundation)\n",
    "\n",
    "From alchemy came the historical progressions that led to modern chemistry: the isolation of drugs from natural sources, metallurgy, and the dye industry. Today, chemistry continues to deepen our understanding and improve our ability to harness and control the behavior of matter.\n",
    "\n",
    "# Chemistry: The Central Science \n",
    "\n",
    "Chemistry is sometimes referred to as \"the central science\" due to its interconnectedness with a vast array of other STEM disciplines (STEM stands for areas of study in the science, technology, engineering, and math fields). Chemistry and the language of chemists play vital roles in biology, medicine, materials science, forensics, environmental science, and many other fields (Figure 1.3). The basic principles of physics are essential for understanding many aspects of chemistry, and there is extensive overlap between many subdisciplines within the two fields, such as chemical physics and nuclear chemistry. Mathematics, computer science, and information theory provide important tools that help us calculate, interpret, describe, and generally make sense of the chemical world. Biology and chemistry converge in biochemistry, which is crucial to understanding the many complex factors and processes that keep living organisms (such as us) alive. Chemical engineering, materials science, and nanotechnology combine chemical principles and empirical findings to produce useful substances, ranging from gasoline to fabrics to electronics. Agriculture, food science, veterinary science, and brewing and wine making help provide sustenance in the form of food and drink to the world's population. Medicine, pharmacology, biotechnology, and botany identify and produce substances that help keep us healthy. Environmental science, geology, oceanography, and atmospheric science incorporate many chemical ideas to help us better understand and protect our physical world. Chemical ideas are used to help understand the universe in astronomy and cosmology.\n",
    "\n",
    "![Image](Chapter_1_images/img-2.jpeg)\n",
    "\n",
    "Figure 1.3 Knowledge of chemistry is central to understanding a wide range of scientific disciplines. This diagram shows just some of the interrelationships between chemistry and other fields.\n",
    "\n",
    "What are some changes in matter that are essential to daily life? Digesting and assimilating food, synthesizing polymers that are used to make clothing, containers, cookware, and credit cards, and refining crude oil into gasoline and other products are just a few examples. As you proceed through this course, you will discover many different examples of changes in the composition and structure of matter, how to classify these changes and how they occurred, their causes, the changes in energy that accompany them, and the principles and laws involved. As you learn about these things, you will be learning chemistry, the study of the composition, properties, and interactions of matter. The practice of chemistry is not limited to chemistry books or laboratories: It happens whenever someone is involved in changes in matter or in conditions that may lead to such changes.\n",
    "\n",
    "# The Scientific Method \n",
    "\n",
    "Chemistry is a science based on observation and experimentation. Doing chemistry involves attempting to answer questions and explain observations in terms of the laws and theories of chemistry, using procedures that are accepted by the scientific community. There is no single route to answering a question or explaining an observation, but there is an aspect common to every approach: Each uses knowledge based on experiments that can be reproduced to verify the results. Some routes involve a hypothesis, a tentative explanation of observations that acts as a guide for gathering and checking information. A hypothesis is tested by experimentation, calculation, and/or comparison with the experiments of others and then refined as needed.\n",
    "\n",
    "Some hypotheses are attempts to explain the behavior that is summarized in laws. The laws of science summarize a vast number of experimental observations, and describe or predict some facet of the natural world. If such a hypothesis turns out to be capable of explaining a large body of experimental data, it can reach the status of a theory. Scientific theories are well-substantiated, comprehensive, testable explanations of particular aspects of nature. Theories are accepted because they provide satisfactory explanations, but they can be modified if new data become available. The path of discovery that leads from question and observation to law or hypothesis to theory, combined with experimental verification of the hypothesis and any necessary modification of the theory, is called the scientific method (Figure 1.4).\n",
    "\n",
    "![Image](Chapter_1_images/img-3.jpeg)\n",
    "\n",
    "Figure 1.4 The scientific method follows a process similar to the one shown in this diagram. All the key components are shown, in roughly the right order. Scientific progress is seldom neat and clean: It requires open inquiry and the reworking of questions and ideas in response to findings.\n",
    "\n",
    "# The Domains of Chemistry \n",
    "\n",
    "Chemists study and describe the behavior of matter and energy in three different domains: macroscopic, microscopic, and symbolic. These domains provide different ways of considering and describing chemical behavior.\n",
    "\n",
    "Macro is a Greek word that means \"large.\" The macroscopic domain is familiar to us: It is the realm of everyday things that are large enough to be sensed directly by human sight or touch. In daily life, this includes the food you eat and the breeze you feel on your face. The macroscopic domain includes everyday and laboratory chemistry, where we observe and measure physical and chemical properties such as density, solubility, and flammability.\n",
    "\n",
    "Micro comes from Greek and means \"small.\" The microscopic domain of chemistry is often visited in the imagination. Some aspects of the microscopic domain are visible through standard optical microscopes, for example, many biological cells. More sophisticated instruments are capable of imaging even smaller entities such as molecules and atoms (see Figure $1.5(\\mathbf{b})$ ).\n",
    "\n",
    "However, most of the subjects in the microscopic domain of chemistry are too small to be seen even with the most advanced microscopes and may only be pictured in the mind. Other components of the microscopic domain include ions and electrons, protons and neutrons, and chemical bonds, each of which is far too small to see.\n",
    "\n",
    "The symbolic domain contains the specialized language used to represent components of the macroscopic and microscopic domains. Chemical symbols (such as those used in the periodic table), chemical formulas, and chemical equations are part of the symbolic domain, as are graphs, drawings, and calculations. These symbols play an important role in chemistry because they help interpret the behavior of the macroscopic domain in terms of the components of the microscopic domain. One of the challenges for students learning chemistry is recognizing that the same symbols can represent different things in the macroscopic and microscopic domains, and one of the features that makes chemistry fascinating is the use of a domain that must be imagined to explain behavior in a domain that can be observed.\n",
    "\n",
    "A helpful way to understand the three domains is via the essential and ubiquitous substance of water. That water is a liquid at moderate temperatures, will freeze to form a solid at lower temperatures, and boil to form a gas at higher temperatures (Figure 1.5) are macroscopic observations. But some properties of water fall into the microscopic domain-what cannot be observed with the naked eye. The description of water as comprising two hydrogen atoms and one oxygen atom, and the explanation of freezing and boiling in terms of attractions between these molecules, is within the microscopic arena. The formula $\\mathrm{H}_{2} \\mathrm{O}$, which can describe water at either the macroscopic or microscopic levels, is an example of the symbolic domain. The abbreviations $(g)$ for gas, $(s)$ for solid, and $(l)$ for liquid are also symbolic.\n",
    "![Image](Chapter_1_images/img-4.jpeg)\n",
    "\n",
    "Figure 1.5 (a) Moisture in the air, icebergs, and the ocean represent water in the macroscopic domain. (b) At the molecular level (microscopic domain), gas molecules are far apart and disorganized, solid water molecules are close together and organized, and liquid molecules are close together and disorganized. (c) The formula $\\mathrm{H}_{2} \\mathrm{O}$ symbolizes water, and $(g),(s)$, and $(l)$ symbolize its phases. Note that clouds actually comprise either very small liquid water droplets or solid water crystals; gaseous water in our atmosphere is not visible to the naked eye, although it may be sensed as humidity. (credit a: modification of work by \"Gorkaazk\"/Wikimedia Commons)\n",
    "\n",
    "# 1.2 Phases and Classification of Matter \n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Describe the basic properties of each physical state of matter: solid, liquid, and gas\n",
    "- Distinguish between mass and weight\n",
    "- Apply the law of conservation of matter\n",
    "- Classify matter as an element, compound, homogeneous mixture, or heterogeneous mixture with regard to its physical state and composition\n",
    "- Define and give examples of atoms and molecules\n",
    "\n",
    "Matter is defined as anything that occupies space and has mass, and it is all around us. Solids and liquids are more obviously matter: We can see that they take up space, and their weight tells us that they have mass. Gases are also\n",
    "\n",
    "matter; if gases did not take up space, a balloon would not inflate (increase its volume) when filled with gas.\n",
    "Solids, liquids, and gases are the three states of matter commonly found on earth (Figure 1.6). A solid is rigid and possesses a definite shape. A liquid flows and takes the shape of its container, except that it forms a flat or slightly curved upper surface when acted upon by gravity. (In zero gravity, liquids assume a spherical shape.) Both liquid and solid samples have volumes that are very nearly independent of pressure. A gas takes both the shape and volume of its container.\n",
    "![Image](Chapter_1_images/img-5.jpeg)\n",
    "\n",
    "Figure 1.6 The three most common states or phases of matter are solid, liquid, and gas.\n",
    "\n",
    "A fourth state of matter, plasma, occurs naturally in the interiors of stars. A plasma is a gaseous state of matter that contains appreciable numbers of electrically charged particles (Figure 1.7). The presence of these charged particles imparts unique properties to plasmas that justify their classification as a state of matter distinct from gases. In addition to stars, plasmas are found in some other high-temperature environments (both natural and man-made), such as lightning strikes, certain television screens, and specialized analytical instruments used to detect trace amounts of metals.\n",
    "\n",
    "![Image](Chapter_1_images/img-6.jpeg)\n",
    "\n",
    "Figure 1.7 A plasma torch can be used to cut metal. (credit: \"Hypertherm\"/Wikimedia Commons)\n",
    "\n",
    "# Link to Learning \n",
    "\n",
    "In a tiny cell in a plasma television, the plasma emits ultraviolet light, which in turn causes the display at that location to appear a specific color. The composite of these tiny dots of color makes up the image that you see. Watch this video (http://openstaxcollege.org/1/16plasma) to learn more about plasma and the places you encounter it.\n",
    "\n",
    "Some samples of matter appear to have properties of solids, liquids, and/or gases at the same time. This can occur when the sample is composed of many small pieces. For example, we can pour sand as if it were a liquid because it is composed of many small grains of solid sand. Matter can also have properties of more than one state when it is a mixture, such as with clouds. Clouds appear to behave somewhat like gases, but they are actually mixtures of air (gas) and tiny particles of water (liquid or solid).\n",
    "\n",
    "The mass of an object is a measure of the amount of matter in it. One way to measure an object's mass is to measure the force it takes to accelerate the object. It takes much more force to accelerate a car than a bicycle because the car has much more mass. A more common way to determine the mass of an object is to use a balance to compare its mass with a standard mass.\n",
    "\n",
    "Although weight is related to mass, it is not the same thing. Weight refers to the force that gravity exerts on an object. This force is directly proportional to the mass of the object. The weight of an object changes as the force of gravity changes, but its mass does not. An astronaut's mass does not change just because she goes to the moon. But her weight on the moon is only one-sixth her earth-bound weight because the moon's gravity is only one-sixth that of the earth's. She may feel \"weightless\" during her trip when she experiences negligible external forces (gravitational or any other), although she is, of course, never \"massless.\"\n",
    "\n",
    "The law of conservation of matter summarizes many scientific observations about matter: It states that there is no detectable change in the total quantity of matter present when matter converts from one type to another (a chemical change) or changes among solid, liquid, or gaseous states (a physical change). Brewing beer and the operation of batteries provide examples of the conservation of matter (Figure 1.8). During the brewing of beer, the ingredients (water, yeast, grains, malt, hops, and sugar) are converted into beer (water, alcohol, carbonation, and flavoring substances) with no actual loss of substance. This is most clearly seen during the bottling process, when glucose turns into ethanol and carbon dioxide, and the total mass of the substances does not change. This can also be seen in a\n",
    "\n",
    "lead-acid car battery: The original substances (lead, lead oxide, and sulfuric acid), which are capable of producing electricity, are changed into other substances (lead sulfate and water) that do not produce electricity, with no change in the actual amount of matter.\n",
    "![Image](Chapter_1_images/img-7.jpeg)\n",
    "\n",
    "Figure 1.8 (a) The mass of beer precursor materials is the same as the mass of beer produced: Sugar has become alcohol and carbon dioxide. (b) The mass of the lead, lead oxide, and sulfuric acid consumed by the production of electricity is exactly equal to the mass of lead sulfate and water that is formed.\n",
    "\n",
    "Although this conservation law holds true for all conversions of matter, convincing examples are few and far between because, outside of the controlled conditions in a laboratory, we seldom collect all of the material that is produced during a particular conversion. For example, when you eat, digest, and assimilate food, all of the matter in the original food is preserved. But because some of the matter is incorporated into your body, and much is excreted as various types of waste, it is challenging to verify by measurement.\n",
    "\n",
    "# Classifying Matter \n",
    "\n",
    "Matter can be classified into several categories. Two broad categories are mixtures and pure substances. A pure substance has a constant composition. All specimens of a pure substance have exactly the same makeup and properties. Any sample of sucrose (table sugar) consists of $42.1 \\%$ carbon, $6.5 \\%$ hydrogen, and $51.4 \\%$ oxygen by mass. Any sample of sucrose also has the same physical properties, such as melting point, color, and sweetness, regardless of the source from which it is isolated.\n",
    "\n",
    "Pure substances may be divided into two classes: elements and compounds. Pure substances that cannot be broken down into simpler substances by chemical changes are called elements. Iron, silver, gold, aluminum, sulfur, oxygen, and copper are familiar examples of the more than 100 known elements, of which about 90 occur naturally on the earth, and two dozen or so have been created in laboratories.\n",
    "\n",
    "Pure substances that can be broken down by chemical changes are called compounds. This breakdown may produce either elements or other compounds, or both. Mercury(II) oxide, an orange, crystalline solid, can be broken down by heat into the elements mercury and oxygen (Figure 1.9). When heated in the absence of air, the compound sucrose is broken down into the element carbon and the compound water. (The initial stage of this process, when the sugar is turning brown, is known as caramelization-this is what imparts the characteristic sweet and nutty flavor to caramel apples, caramelized onions, and caramel). Silver(I) chloride is a white solid that can be broken down into its elements, silver and chlorine, by absorption of light. This property is the basis for the use of this compound in photographic\n",
    "\n",
    "films and photochromic eyeglasses (those with lenses that darken when exposed to light).\n",
    "![Image](Chapter_1_images/img-8.jpeg)\n",
    "(a)\n",
    "![Image](Chapter_1_images/img-9.jpeg)\n",
    "(b)\n",
    "![Image](Chapter_1_images/img-10.jpeg)\n",
    "(c)\n",
    "\n",
    "Figure 1.9 (a) The compound mercury(II) oxide, (b) when heated, (c) decomposes into silvery droplets of liquid mercury and invisible oxygen gas. (credit: modification of work by Paul Flowers)\n",
    "\n",
    "# Link to Learning \n",
    "\n",
    "Many compounds break down when heated. This site (http://openstaxcollege.org/1/16mercury) shows the breakdown of mercury oxide, HgO . You can also view an example of the photochemical decomposition of silver chloride (http://openstaxcollege.org/1/16silvchloride) (AgCl), the basis of early photography.\n",
    "\n",
    "The properties of combined elements are different from those in the free, or uncombined, state. For example, white crystalline sugar (sucrose) is a compound resulting from the chemical combination of the element carbon, which is a black solid in one of its uncombined forms, and the two elements hydrogen and oxygen, which are colorless gases when uncombined. Free sodium, an element that is a soft, shiny, metallic solid, and free chlorine, an element that is a yellow-green gas, combine to form sodium chloride (table salt), a compound that is a white, crystalline solid.\n",
    "\n",
    "A mixture is composed of two or more types of matter that can be present in varying amounts and can be separated by physical changes, such as evaporation (you will learn more about this later). A mixture with a composition that varies from point to point is called a heterogeneous mixture. Italian dressing is an example of a heterogeneous mixture (Figure 1.10). Its composition can vary because it may be prepared from varying amounts of oil, vinegar, and herbs. It is not the same from point to point throughout the mixture-one drop may be mostly vinegar, whereas a different drop may be mostly oil or herbs because the oil and vinegar separate and the herbs settle. Other examples of heterogeneous mixtures are chocolate chip cookies (we can see the separate bits of chocolate, nuts, and cookie dough) and granite (we can see the quartz, mica, feldspar, and more).\n",
    "\n",
    "A homogeneous mixture, also called a solution, exhibits a uniform composition and appears visually the same throughout. An example of a solution is a sports drink, consisting of water, sugar, coloring, flavoring, and electrolytes mixed together uniformly (Figure 1.10). Each drop of a sports drink tastes the same because each drop contains the same amounts of water, sugar, and other components. Note that the composition of a sports drink can vary-it could be made with somewhat more or less sugar, flavoring, or other components, and still be a sports drink. Other examples of homogeneous mixtures include air, maple syrup, gasoline, and a solution of salt in water.\n",
    "\n",
    "![Image](Chapter_1_images/img-11.jpeg)\n",
    "\n",
    "Figure 1.10 (a) Oil and vinegar salad dressing is a heterogeneous mixture because its composition is not uniform throughout. (b) A commercial sports drink is a homogeneous mixture because its composition is uniform throughout. (credit a \"left\": modification of work by John Mayer; credit a \"right\": modification of work by Umberto Salvagnin; credit b \"left: modification of work by Jeff Bedford)\n",
    "\n",
    "Although there are just over 100 elements, tens of millions of chemical compounds result from different combinations of these elements. Each compound has a specific composition and possesses definite chemical and physical properties that distinguish it from all other compounds. And, of course, there are innumerable ways to combine elements and compounds to form different mixtures. A summary of how to distinguish between the various major classifications of matter is shown in (Figure 1.11).\n",
    "![Image](Chapter_1_images/img-12.jpeg)\n",
    "\n",
    "Figure 1.11 Depending on its properties, a given substance can be classified as a homogeneous mixture, a heterogeneous mixture, a compound, or an element.\n",
    "\n",
    "Eleven elements make up about 99\\% of the earth's crust and atmosphere (Table 1.1). Oxygen constitutes nearly onehalf and silicon about one-quarter of the total quantity of these elements. A majority of elements on earth are found in chemical combinations with other elements; about one-quarter of the elements are also found in the free state.\n",
    "\n",
    "Elemental Composition of Earth\n",
    "\n",
    "| Element | Symbol | Percent Mass |  | Element | Symbol | Percent Mass |\n",
    "| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
    "| oxygen | O | 49.20 |  | chlorine | Cl | 0.19 |\n",
    "| silicon | Si | 25.67 |  | phosphorus | P | 0.11 |\n",
    "| aluminum | Al | 7.50 |  | manganese | Mn | 0.09 |\n",
    "\n",
    "Table 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a562cb8-1b13-4efd-a4cd-336c9a26df2f",
   "metadata": {},
   "source": [
    "# Chapter 1 - Essential Ideas\n",
    "\n",
    "![Image](Chapter_1_images/img-0.jpeg)\n",
    "\n",
    "Figure 1.1 Chemical substances and processes are essential for our existence, providing sustenance, keeping us clean and healthy, fabricating electronic devices, enabling transportation, and much more. (credit \"left\": modification of work by \"vxla\"/Flickr; credit \"left middle\": modification of work by \"the Italian voice\"/Flickr; credit \"right middle\": modification of work by Jason Trim; credit \"right\": modification of work by \"gosheshe\"/Flickr)\n",
    "\n",
    "## Chapter Outline\n",
    "\n",
    "1.1 Chemistry in Context\n",
    "1.2 Phases and Classification of Matter\n",
    "1.3 Physical and Chemical Properties\n",
    "1.4 Measurements\n",
    "1.5 Measurement Uncertainty, Accuracy, and Precision\n",
    "1.6 Mathematical Treatment of Measurement Results\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your alarm goes off and, after hitting \"snooze\" once or twice, you pry yourself out of bed. You make a cup of coffee to help you get going, and then you shower, get dressed, eat breakfast, and check your phone for messages. On your way to school, you stop to fill your car's gas tank, almost making you late for the first day of chemistry class. As you find a seat in the classroom, you read the question projected on the screen: \"Welcome to class! Why should we study chemistry?\"\n",
    "\n",
    "Do you have an answer? You may be studying chemistry because it fulfills an academic requirement, but if you consider your daily activities, you might find chemistry interesting for other reasons. Most everything you do and encounter during your day involves chemistry. Making coffee, cooking eggs, and toasting bread involve chemistry. The products you use-like soap and shampoo, the fabrics you wear, the electronics that keep you connected to your world, the gasoline that propels your car-all of these and more involve chemical substances and processes. Whether you are aware or not, chemistry is part of your everyday world. In this course, you will learn many of the essential principles underlying the chemistry of modern-day life.\n",
    "\n",
    "# 1.1 Chemistry in Context \n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "- Outline the historical development of chemistry\n",
    "- Provide examples of the importance of chemistry in everyday life\n",
    "- Describe the scientific method\n",
    "- Differentiate among hypotheses, theories, and laws\n",
    "- Provide examples illustrating macroscopic, microscopic, and symbolic domains\n",
    "\n",
    "Throughout human history, people have tried to convert matter into more useful forms. Our Stone Age ancestors chipped pieces of flint into useful tools and carved wood into statues and toys. These endeavors involved changing the shape of a substance without changing the substance itself. But as our knowledge increased, humans began to change the composition of the substances as well-clay was converted into pottery, hides were cured to make garments, copper ores were transformed into copper tools and weapons, and grain was made into bread.\n",
    "Humans began to practice chemistry when they learned to control fire and use it to cook, make pottery, and smelt metals. Subsequently, they began to separate and use specific components of matter. A variety of drugs such as aloe, myrrh, and opium were isolated from plants. Dyes, such as indigo and Tyrian purple, were extracted from plant and animal matter. Metals were combined to form alloys-for example, copper and tin were mixed together to make bronze-and more elaborate smelting techniques produced iron. Alkalis were extracted from ashes, and soaps were prepared by combining these alkalis with fats. Alcohol was produced by fermentation and purified by distillation.\n",
    "Attempts to understand the behavior of matter extend back for more than 2500 years. As early as the sixth century BC, Greek philosophers discussed a system in which water was the basis of all things. You may have heard of the Greek postulate that matter consists of four elements: earth, air, fire, and water. Subsequently, an amalgamation of chemical technologies and philosophical speculations was spread from Egypt, China, and the eastern Mediterranean by alchemists, who endeavored to transform \"base metals\" such as lead into \"noble metals\" like gold, and to create elixirs to cure disease and extend life (Figure 1.2).\n",
    "\n",
    "![Image](Chapter_1_images/img-1.jpeg)\n",
    "\n",
    "Figure 1.2 This portrayal shows an alchemist's workshop circa 1580. Although alchemy made some useful contributions to how to manipulate matter, it was not scientific by modern standards. (credit: Chemical Heritage Foundation)\n",
    "\n",
    "From alchemy came the historical progressions that led to modern chemistry: the isolation of drugs from natural sources, metallurgy, and the dye industry. Today, chemistry continues to deepen our understanding and improve our ability to harness and control the behavior of matter.\n",
    "\n",
    "# Chemistry: The Central Science \n",
    "\n",
    "Chemistry is sometimes referred to as \"the central science\" due to its interconnectedness with a vast array of other STEM disciplines (STEM stands for areas of study in the science, technology, engineering, and math fields). Chemistry and the language of chemists play vital roles in biology, medicine, materials science, forensics, environmental science, and many other fields (Figure 1.3). The basic principles of physics are essential for understanding many aspects of chemistry, and there is extensive overlap between many subdisciplines within the two fields, such as chemical physics and nuclear chemistry. Mathematics, computer science, and information theory provide important tools that help us calculate, interpret, describe, and generally make sense of the chemical world. Biology and chemistry converge in biochemistry, which is crucial to understanding the many complex factors and processes that keep living organisms (such as us) alive. Chemical engineering, materials science, and nanotechnology combine chemical principles and empirical findings to produce useful substances, ranging from gasoline to fabrics to electronics. Agriculture, food science, veterinary science, and brewing and wine making help provide sustenance in the form of food and drink to the world's population. Medicine, pharmacology, biotechnology, and botany identify and produce substances that help keep us healthy. Environmental science, geology, oceanography, and atmospheric science incorporate many chemical ideas to help us better understand and protect our physical world. Chemical ideas are used to help understand the universe in astronomy and cosmology.\n",
    "\n",
    "![Image](Chapter_1_images/img-2.jpeg)\n",
    "\n",
    "Figure 1.3 Knowledge of chemistry is central to understanding a wide range of scientific disciplines. This diagram shows just some of the interrelationships between chemistry and other fields.\n",
    "\n",
    "What are some changes in matter that are essential to daily life? Digesting and assimilating food, synthesizing polymers that are used to make clothing, containers, cookware, and credit cards, and refining crude oil into gasoline and other products are just a few examples. As you proceed through this course, you will discover many different examples of changes in the composition and structure of matter, how to classify these changes and how they occurred, their causes, the changes in energy that accompany them, and the principles and laws involved. As you learn about these things, you will be learning chemistry, the study of the composition, properties, and interactions of matter. The practice of chemistry is not limited to chemistry books or laboratories: It happens whenever someone is involved in changes in matter or in conditions that may lead to such changes.\n",
    "\n",
    "# The Scientific Method \n",
    "\n",
    "Chemistry is a science based on observation and experimentation. Doing chemistry involves attempting to answer questions and explain observations in terms of the laws and theories of chemistry, using procedures that are accepted by the scientific community. There is no single route to answering a question or explaining an observation, but there is an aspect common to every approach: Each uses knowledge based on experiments that can be reproduced to verify the results. Some routes involve a hypothesis, a tentative explanation of observations that acts as a guide for gathering and checking information. A hypothesis is tested by experimentation, calculation, and/or comparison with the experiments of others and then refined as needed.\n",
    "\n",
    "Some hypotheses are attempts to explain the behavior that is summarized in laws. The laws of science summarize a vast number of experimental observations, and describe or predict some facet of the natural world. If such a hypothesis turns out to be capable of explaining a large body of experimental data, it can reach the status of a theory. Scientific theories are well-substantiated, comprehensive, testable explanations of particular aspects of nature. Theories are accepted because they provide satisfactory explanations, but they can be modified if new data become available. The path of discovery that leads from question and observation to law or hypothesis to theory, combined with experimental verification of the hypothesis and any necessary modification of the theory, is called the scientific method (Figure 1.4).\n",
    "\n",
    "![Image](Chapter_1_images/img-3.jpeg)\n",
    "\n",
    "Figure 1.4 The scientific method follows a process similar to the one shown in this diagram. All the key components are shown, in roughly the right order. Scientific progress is seldom neat and clean: It requires open inquiry and the reworking of questions and ideas in response to findings.\n",
    "\n",
    "# The Domains of Chemistry \n",
    "\n",
    "Chemists study and describe the behavior of matter and energy in three different domains: macroscopic, microscopic, and symbolic. These domains provide different ways of considering and describing chemical behavior.\n",
    "\n",
    "Macro is a Greek word that means \"large.\" The macroscopic domain is familiar to us: It is the realm of everyday things that are large enough to be sensed directly by human sight or touch. In daily life, this includes the food you eat and the breeze you feel on your face. The macroscopic domain includes everyday and laboratory chemistry, where we observe and measure physical and chemical properties such as density, solubility, and flammability.\n",
    "\n",
    "Micro comes from Greek and means \"small.\" The microscopic domain of chemistry is often visited in the imagination. Some aspects of the microscopic domain are visible through standard optical microscopes, for example, many biological cells. More sophisticated instruments are capable of imaging even smaller entities such as molecules and atoms (see Figure $1.5(\\mathbf{b})$ ).\n",
    "\n",
    "However, most of the subjects in the microscopic domain of chemistry are too small to be seen even with the most advanced microscopes and may only be pictured in the mind. Other components of the microscopic domain include ions and electrons, protons and neutrons, and chemical bonds, each of which is far too small to see.\n",
    "\n",
    "The symbolic domain contains the specialized language used to represent components of the macroscopic and microscopic domains. Chemical symbols (such as those used in the periodic table), chemical formulas, and chemical equations are part of the symbolic domain, as are graphs, drawings, and calculations. These symbols play an important role in chemistry because they help interpret the behavior of the macroscopic domain in terms of the components of the microscopic domain. One of the challenges for students learning chemistry is recognizing that the same symbols can represent different things in the macroscopic and microscopic domains, and one of the features that makes chemistry fascinating is the use of a domain that must be imagined to explain behavior in a domain that can be observed.\n",
    "\n",
    "A helpful way to understand the three domains is via the essential and ubiquitous substance of water. That water is a liquid at moderate temperatures, will freeze to form a solid at lower temperatures, and boil to form a gas at higher temperatures (Figure 1.5) are macroscopic observations. But some properties of water fall into the microscopic domain-what cannot be observed with the naked eye. The description of water as comprising two hydrogen atoms and one oxygen atom, and the explanation of freezing and boiling in terms of attractions between these molecules, is within the microscopic arena. The formula $\\mathrm{H}_{2} \\mathrm{O}$, which can describe water at either the macroscopic or microscopic levels, is an example of the symbolic domain. The abbreviations $(g)$ for gas, $(s)$ for solid, and $(l)$ for liquid are also symbolic.\n",
    "![Image](Chapter_1_images/img-4.jpeg)\n",
    "\n",
    "Figure 1.5 (a) Moisture in the air, icebergs, and the ocean represent water in the macroscopic domain. (b) At the molecular level (microscopic domain), gas molecules are far apart and disorganized, solid water molecules are close together and organized, and liquid molecules are close together and disorganized. (c) The formula $\\mathrm{H}_{2} \\mathrm{O}$ symbolizes water, and $(g),(s)$, and $(l)$ symbolize its phases. Note that clouds actually comprise either very small liquid water droplets or solid water crystals; gaseous water in our atmosphere is not visible to the naked eye, although it may be sensed as humidity. (credit a: modification of work by \"Gorkaazk\"/Wikimedia Commons)\n",
    "\n",
    "# 1.2 Phases and Classification of Matter \n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Describe the basic properties of each physical state of matter: solid, liquid, and gas\n",
    "- Distinguish between mass and weight\n",
    "- Apply the law of conservation of matter\n",
    "- Classify matter as an element, compound, homogeneous mixture, or heterogeneous mixture with regard to its physical state and composition\n",
    "- Define and give examples of atoms and molecules\n",
    "\n",
    "Matter is defined as anything that occupies space and has mass, and it is all around us. Solids and liquids are more obviously matter: We can see that they take up space, and their weight tells us that they have mass. Gases are also\n",
    "\n",
    "matter; if gases did not take up space, a balloon would not inflate (increase its volume) when filled with gas.\n",
    "Solids, liquids, and gases are the three states of matter commonly found on earth (Figure 1.6). A solid is rigid and possesses a definite shape. A liquid flows and takes the shape of its container, except that it forms a flat or slightly curved upper surface when acted upon by gravity. (In zero gravity, liquids assume a spherical shape.) Both liquid and solid samples have volumes that are very nearly independent of pressure. A gas takes both the shape and volume of its container.\n",
    "![Image](Chapter_1_images/img-5.jpeg)\n",
    "\n",
    "Figure 1.6 The three most common states or phases of matter are solid, liquid, and gas.\n",
    "\n",
    "A fourth state of matter, plasma, occurs naturally in the interiors of stars. A plasma is a gaseous state of matter that contains appreciable numbers of electrically charged particles (Figure 1.7). The presence of these charged particles imparts unique properties to plasmas that justify their classification as a state of matter distinct from gases. In addition to stars, plasmas are found in some other high-temperature environments (both natural and man-made), such as lightning strikes, certain television screens, and specialized analytical instruments used to detect trace amounts of metals.\n",
    "\n",
    "![Image](Chapter_1_images/img-6.jpeg)\n",
    "\n",
    "Figure 1.7 A plasma torch can be used to cut metal. (credit: \"Hypertherm\"/Wikimedia Commons)\n",
    "\n",
    "# Link to Learning \n",
    "\n",
    "In a tiny cell in a plasma television, the plasma emits ultraviolet light, which in turn causes the display at that location to appear a specific color. The composite of these tiny dots of color makes up the image that you see. Watch this video (http://openstaxcollege.org/1/16plasma) to learn more about plasma and the places you encounter it.\n",
    "\n",
    "Some samples of matter appear to have properties of solids, liquids, and/or gases at the same time. This can occur when the sample is composed of many small pieces. For example, we can pour sand as if it were a liquid because it is composed of many small grains of solid sand. Matter can also have properties of more than one state when it is a mixture, such as with clouds. Clouds appear to behave somewhat like gases, but they are actually mixtures of air (gas) and tiny particles of water (liquid or solid).\n",
    "\n",
    "The mass of an object is a measure of the amount of matter in it. One way to measure an object's mass is to measure the force it takes to accelerate the object. It takes much more force to accelerate a car than a bicycle because the car has much more mass. A more common way to determine the mass of an object is to use a balance to compare its mass with a standard mass.\n",
    "\n",
    "Although weight is related to mass, it is not the same thing. Weight refers to the force that gravity exerts on an object. This force is directly proportional to the mass of the object. The weight of an object changes as the force of gravity changes, but its mass does not. An astronaut's mass does not change just because she goes to the moon. But her weight on the moon is only one-sixth her earth-bound weight because the moon's gravity is only one-sixth that of the earth's. She may feel \"weightless\" during her trip when she experiences negligible external forces (gravitational or any other), although she is, of course, never \"massless.\"\n",
    "\n",
    "The law of conservation of matter summarizes many scientific observations about matter: It states that there is no detectable change in the total quantity of matter present when matter converts from one type to another (a chemical change) or changes among solid, liquid, or gaseous states (a physical change). Brewing beer and the operation of batteries provide examples of the conservation of matter (Figure 1.8). During the brewing of beer, the ingredients (water, yeast, grains, malt, hops, and sugar) are converted into beer (water, alcohol, carbonation, and flavoring substances) with no actual loss of substance. This is most clearly seen during the bottling process, when glucose turns into ethanol and carbon dioxide, and the total mass of the substances does not change. This can also be seen in a\n",
    "\n",
    "lead-acid car battery: The original substances (lead, lead oxide, and sulfuric acid), which are capable of producing electricity, are changed into other substances (lead sulfate and water) that do not produce electricity, with no change in the actual amount of matter.\n",
    "![Image](Chapter_1_images/img-7.jpeg)\n",
    "\n",
    "Figure 1.8 (a) The mass of beer precursor materials is the same as the mass of beer produced: Sugar has become alcohol and carbon dioxide. (b) The mass of the lead, lead oxide, and sulfuric acid consumed by the production of electricity is exactly equal to the mass of lead sulfate and water that is formed.\n",
    "\n",
    "Although this conservation law holds true for all conversions of matter, convincing examples are few and far between because, outside of the controlled conditions in a laboratory, we seldom collect all of the material that is produced during a particular conversion. For example, when you eat, digest, and assimilate food, all of the matter in the original food is preserved. But because some of the matter is incorporated into your body, and much is excreted as various types of waste, it is challenging to verify by measurement.\n",
    "\n",
    "# Classifying Matter \n",
    "\n",
    "Matter can be classified into several categories. Two broad categories are mixtures and pure substances. A pure substance has a constant composition. All specimens of a pure substance have exactly the same makeup and properties. Any sample of sucrose (table sugar) consists of $42.1 \\%$ carbon, $6.5 \\%$ hydrogen, and $51.4 \\%$ oxygen by mass. Any sample of sucrose also has the same physical properties, such as melting point, color, and sweetness, regardless of the source from which it is isolated.\n",
    "\n",
    "Pure substances may be divided into two classes: elements and compounds. Pure substances that cannot be broken down into simpler substances by chemical changes are called elements. Iron, silver, gold, aluminum, sulfur, oxygen, and copper are familiar examples of the more than 100 known elements, of which about 90 occur naturally on the earth, and two dozen or so have been created in laboratories.\n",
    "\n",
    "Pure substances that can be broken down by chemical changes are called compounds. This breakdown may produce either elements or other compounds, or both. Mercury(II) oxide, an orange, crystalline solid, can be broken down by heat into the elements mercury and oxygen (Figure 1.9). When heated in the absence of air, the compound sucrose is broken down into the element carbon and the compound water. (The initial stage of this process, when the sugar is turning brown, is known as caramelization-this is what imparts the characteristic sweet and nutty flavor to caramel apples, caramelized onions, and caramel). Silver(I) chloride is a white solid that can be broken down into its elements, silver and chlorine, by absorption of light. This property is the basis for the use of this compound in photographic\n",
    "\n",
    "films and photochromic eyeglasses (those with lenses that darken when exposed to light).\n",
    "![Image](Chapter_1_images/img-8.jpeg)\n",
    "(a)\n",
    "![Image](Chapter_1_images/img-9.jpeg)\n",
    "(b)\n",
    "![Image](Chapter_1_images/img-10.jpeg)\n",
    "(c)\n",
    "\n",
    "Figure 1.9 (a) The compound mercury(II) oxide, (b) when heated, (c) decomposes into silvery droplets of liquid mercury and invisible oxygen gas. (credit: modification of work by Paul Flowers)\n",
    "\n",
    "# Link to Learning \n",
    "\n",
    "Many compounds break down when heated. This site (http://openstaxcollege.org/1/16mercury) shows the breakdown of mercury oxide, HgO . You can also view an example of the photochemical decomposition of silver chloride (http://openstaxcollege.org/1/16silvchloride) (AgCl), the basis of early photography.\n",
    "\n",
    "The properties of combined elements are different from those in the free, or uncombined, state. For example, white crystalline sugar (sucrose) is a compound resulting from the chemical combination of the element carbon, which is a black solid in one of its uncombined forms, and the two elements hydrogen and oxygen, which are colorless gases when uncombined. Free sodium, an element that is a soft, shiny, metallic solid, and free chlorine, an element that is a yellow-green gas, combine to form sodium chloride (table salt), a compound that is a white, crystalline solid.\n",
    "\n",
    "A mixture is composed of two or more types of matter that can be present in varying amounts and can be separated by physical changes, such as evaporation (you will learn more about this later). A mixture with a composition that varies from point to point is called a heterogeneous mixture. Italian dressing is an example of a heterogeneous mixture (Figure 1.10). Its composition can vary because it may be prepared from varying amounts of oil, vinegar, and herbs. It is not the same from point to point throughout the mixture-one drop may be mostly vinegar, whereas a different drop may be mostly oil or herbs because the oil and vinegar separate and the herbs settle. Other examples of heterogeneous mixtures are chocolate chip cookies (we can see the separate bits of chocolate, nuts, and cookie dough) and granite (we can see the quartz, mica, feldspar, and more).\n",
    "\n",
    "A homogeneous mixture, also called a solution, exhibits a uniform composition and appears visually the same throughout. An example of a solution is a sports drink, consisting of water, sugar, coloring, flavoring, and electrolytes mixed together uniformly (Figure 1.10). Each drop of a sports drink tastes the same because each drop contains the same amounts of water, sugar, and other components. Note that the composition of a sports drink can vary-it could be made with somewhat more or less sugar, flavoring, or other components, and still be a sports drink. Other examples of homogeneous mixtures include air, maple syrup, gasoline, and a solution of salt in water.\n",
    "\n",
    "![Image](Chapter_1_images/img-11.jpeg)\n",
    "\n",
    "Figure 1.10 (a) Oil and vinegar salad dressing is a heterogeneous mixture because its composition is not uniform throughout. (b) A commercial sports drink is a homogeneous mixture because its composition is uniform throughout. (credit a \"left\": modification of work by John Mayer; credit a \"right\": modification of work by Umberto Salvagnin; credit b \"left: modification of work by Jeff Bedford)\n",
    "\n",
    "Although there are just over 100 elements, tens of millions of chemical compounds result from different combinations of these elements. Each compound has a specific composition and possesses definite chemical and physical properties that distinguish it from all other compounds. And, of course, there are innumerable ways to combine elements and compounds to form different mixtures. A summary of how to distinguish between the various major classifications of matter is shown in (Figure 1.11).\n",
    "![Image](Chapter_1_images/img-12.jpeg)\n",
    "\n",
    "Figure 1.11 Depending on its properties, a given substance can be classified as a homogeneous mixture, a heterogeneous mixture, a compound, or an element.\n",
    "\n",
    "Eleven elements make up about 99\\% of the earth's crust and atmosphere (Table 1.1). Oxygen constitutes nearly onehalf and silicon about one-quarter of the total quantity of these elements. A majority of elements on earth are found in chemical combinations with other elements; about one-quarter of the elements are also found in the free state.\n",
    "\n",
    "Elemental Composition of Earth\n",
    "\n",
    "| Element | Symbol | Percent Mass |  | Element | Symbol | Percent Mass |\n",
    "| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
    "| oxygen | O | 49.20 |  | chlorine | Cl | 0.19 |\n",
    "| silicon | Si | 25.67 |  | phosphorus | P | 0.11 |\n",
    "| aluminum | Al | 7.50 |  | manganese | Mn | 0.09 |\n",
    "\n",
    "Table 1.1\n",
    "\n",
    "Elemental Composition of Earth\n",
    "\n",
    "| Element | Symbol | Percent Mass |  | Element | Symbol | Percent Mass |\n",
    "| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
    "| iron | Fe | 4.71 |  | carbon | C | 0.08 |\n",
    "| calcium | Ca | 3.39 |  | sulfur | S | 0.06 |\n",
    "| sodium | Na | 2.63 |  | barium | Ba | 0.04 |\n",
    "| potassium | K | 2.40 |  | nitrogen | N | 0.03 |\n",
    "| magnesium | Mg | 1.93 |  | fluorine | F | 0.03 |\n",
    "| hydrogen | H | 0.87 |  | strontium | Sr | 0.02 |\n",
    "| titanium | Ti | 0.58 |  | all others | - | 0.47 |\n",
    "\n",
    "Table 1.1\n",
    "\n",
    "# Atoms and Molecules \n",
    "\n",
    "An atom is the smallest particle of an element that has the properties of that element and can enter into a chemical combination. Consider the element gold, for example. Imagine cutting a gold nugget in half, then cutting one of the halves in half, and repeating this process until a piece of gold remained that was so small that it could not be cut in half (regardless of how tiny your knife may be). This minimally sized piece of gold is an atom (from the Greek atomos, meaning \"indivisible\") (Figure 1.12). This atom would no longer be gold if it were divided any further.\n",
    "![Image](Chapter_1_images/img-13.jpeg)\n",
    "\n",
    "Figure 1.12 (a) This photograph shows a gold nugget. (b) A scanning-tunneling microscope (STM) can generate views of the surfaces of solids, such as this image of a gold crystal. Each sphere represents one gold atom. (credit a: modification of work by United States Geological Survey; credit b: modification of work by \"Erwinrossen\"/Wikimedia Commons)\n",
    "\n",
    "The first suggestion that matter is composed of atoms is attributed to the Greek philosophers Leucippus and Democritus, who developed their ideas in the 5th century BCE. However, it was not until the early nineteenth century that John Dalton (1766-1844), a British schoolteacher with a keen interest in science, supported this hypothesis with quantitative measurements. Since that time, repeated experiments have confirmed many aspects of this hypothesis, and it has become one of the central theories of chemistry. Other aspects of Dalton's atomic theory are still used but with minor revisions (details of Dalton's theory are provided in the chapter on atoms and molecules).\n",
    "\n",
    "An atom is so small that its size is difficult to imagine. One of the smallest things we can see with our unaided eye is a single thread of a spider web: These strands are about $1 / 10,000$ of a centimeter $(0.0001 \\mathrm{~cm})$ in diameter. Although the cross-section of one strand is almost impossible to see without a microscope, it is huge on an atomic scale. A single carbon atom in the web has a diameter of about 0.000000015 centimeter, and it would take about 7000 carbon atoms to span the diameter of the strand. To put this in perspective, if a carbon atom were the size of a dime, the cross-section of one strand would be larger than a football field, which would require about 150 million carbon atom \"dimes\" to cover it. (Figure 1.13) shows increasingly close microscopic and atomic-level views of ordinary cotton.\n",
    "![Image](Chapter_1_images/img-14.jpeg)\n",
    "\n",
    "Figure 1.13 These images provide an increasingly closer view: (a) a cotton boll, (b) a single cotton fiber viewed under an optical microscope (magnified 40 times), (c) an image of a cotton fiber obtained with an electron microscope (much higher magnification than with the optical microscope); and (d and e) atomic-level models of the fiber (spheres of different colors represent atoms of different elements). (credit c: modification of work by \"Featheredtar\"/Wikimedia Commons)\n",
    "\n",
    "An atom is so light that its mass is also difficult to imagine. A billion lead atoms (1,000,000,000 atoms) weigh about $3 \\times 10^{-13}$ grams, a mass that is far too light to be weighed on even the world's most sensitive balances. It would require over $300,000,000,000,000$ lead atoms ( 300 trillion, or $3 \\times 10^{14}$ ) to be weighed, and they would weigh only 0.0000001 gram.\n",
    "\n",
    "It is rare to find collections of individual atoms. Only a few elements, such as the gases helium, neon, and argon, consist of a collection of individual atoms that move about independently of one another. Other elements, such as the gases hydrogen, nitrogen, oxygen, and chlorine, are composed of units that consist of pairs of atoms (Figure 1.14). One form of the element phosphorus consists of units composed of four phosphorus atoms. The element sulfur exists in various forms, one of which consists of units composed of eight sulfur atoms. These units are called molecules. A molecule consists of two or more atoms joined by strong forces called chemical bonds. The atoms in a molecule move around as a unit, much like the cans of soda in a six-pack or a bunch of keys joined together on a single key ring. A molecule may consist of two or more identical atoms, as in the molecules found in the elements hydrogen, oxygen, and sulfur, or it may consist of two or more different atoms, as in the molecules found in water. Each water molecule is a unit that contains two hydrogen atoms and one oxygen atom. Each glucose molecule is a unit that contains 6 carbon atoms, 12 hydrogen atoms, and 6 oxygen atoms. Like atoms, molecules are incredibly small and light. If an ordinary glass of water were enlarged to the size of the earth, the water molecules inside it would be about the size of golf balls.\n",
    "\n",
    "![Image](Chapter_1_images/img-15.jpeg)\n",
    "\n",
    "Figure 1.14 The elements hydrogen, oxygen, phosphorus, and sulfur form molecules consisting of two or more atoms of the same element. The compounds water, carbon dioxide, and glucose consist of combinations of atoms of different elements.\n",
    "\n",
    "# Chemistry in Everyday Life \n",
    "\n",
    "## Decomposition of Water / Production of Hydrogen\n",
    "\n",
    "Water consists of the elements hydrogen and oxygen combined in a 2 to 1 ratio. Water can be broken down into hydrogen and oxygen gases by the addition of energy. One way to do this is with a battery or power supply, as shown in (Figure 1.15).\n",
    "\n",
    "![Image](Chapter_1_images/img-16.jpeg)\n",
    "\n",
    "Figure 1.15 The decomposition of water is shown at the macroscopic, microscopic, and symbolic levels. The battery provides an electric current (microscopic) that decomposes water. At the macroscopic level, the liquid separates into the gases hydrogen (on the left) and oxygen (on the right). Symbolically, this change is presented by showing how liquid $\\mathrm{H}_{2} \\mathrm{O}$ separates into $\\mathrm{H}_{2}$ and $\\mathrm{O}_{2}$ gases.\n",
    "\n",
    "The breakdown of water involves a rearrangement of the atoms in water molecules into different molecules, each composed of two hydrogen atoms and two oxygen atoms, respectively. Two water molecules form one oxygen molecule and two hydrogen molecules. The representation for what occurs, $2 \\mathrm{H}_{2} \\mathrm{O}(l) \\longrightarrow 2 \\mathrm{H}_{2}(g)+\\mathrm{O}_{2}(g)$, will be explored in more depth in later chapters.\n",
    "\n",
    "The two gases produced have distinctly different properties. Oxygen is not flammable but is required for combustion of a fuel, and hydrogen is highly flammable and a potent energy source. How might this knowledge be applied in our world? One application involves research into more fuel-efficient transportation. Fuel-cell vehicles (FCV) run on hydrogen instead of gasoline (Figure 1.16). They are more efficient than vehicles with internal combustion engines, are nonpolluting, and reduce greenhouse gas emissions, making us less dependent on fossil fuels. FCVs are not yet economically viable, however, and current hydrogen production depends on natural gas. If we can develop a process to economically decompose water, or produce hydrogen in another environmentally sound way, FCVs may be the way of the future.\n",
    "\n",
    "![Image](Chapter_1_images/img-17.jpeg)\n",
    "\n",
    "Figure 1.16 A fuel cell generates electrical energy from hydrogen and oxygen via an electrochemical process and produces only water as the waste product.\n",
    "\n",
    "# Chemistry in Everyday Life \n",
    "\n",
    "## Chemistry of Cell Phones\n",
    "\n",
    "Imagine how different your life would be without cell phones (Figure 1.17) and other smart devices. Cell phones are made from numerous chemical substances, which are extracted, refined, purified, and assembled using an extensive and in-depth understanding of chemical principles. About 30\\% of the elements that are found in nature are found within a typical smart phone. The case/body/frame consists of a combination of sturdy, durable polymers composed primarily of carbon, hydrogen, oxygen, and nitrogen [acrylonitrile butadiene styrene (ABS) and polycarbonate thermoplastics], and light, strong, structural metals, such as aluminum, magnesium, and iron. The display screen is made from a specially toughened glass (silica glass strengthened by the addition of aluminum, sodium, and potassium) and coated with a material to make it conductive (such as indium tin oxide). The circuit board uses a semiconductor material (usually silicon); commonly used metals like copper, tin, silver, and gold; and more unfamiliar elements such as yttrium, praseodymium, and gadolinium. The battery relies upon lithium ions and a variety of other materials, including iron, cobalt, copper, polyethylene oxide, and polyacrylonitrile.\n",
    "\n",
    "![Image](Chapter_1_images/img-18.jpeg)\n",
    "\n",
    "Figure 1.17 Almost one-third of naturally occurring elements are used to make a cell phone. (credit: modification of work by John Taylor)\n",
    "\n",
    "# 1.3 Physical and Chemical Properties \n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Identify properties of and changes in matter as physical or chemical\n",
    "- Identify properties of matter as extensive or intensive\n",
    "\n",
    "The characteristics that distinguish one substance from another are called properties. A physical property is a characteristic of matter that is not associated with a change in its chemical composition. Familiar examples of physical properties include density, color, hardness, melting and boiling points, and electrical conductivity. Some physical properties, such as density and color, may be observed without changing the physical state of the matter. Other physical properties, such as the melting temperature of iron or the freezing temperature of water, can only be observed as matter undergoes a physical change. A physical change is a change in the state or properties of matter without any accompanying change in the chemical identities of the substances contained in the matter. Physical changes are observed when wax melts, when sugar dissolves in coffee, and when steam condenses into liquid water (Figure 1.18). Other examples of physical changes include magnetizing and demagnetizing metals (as is done with common antitheft security tags) and grinding solids into powders (which can sometimes yield noticeable changes in color). In each of these examples, there is a change in the physical state, form, or properties of the substance, but no change in its chemical composition.\n",
    "\n",
    "![Image](Chapter_1_images/img-19.jpeg)\n",
    "\n",
    "Figure 1.18 (a) Wax undergoes a physical change when solid wax is heated and forms liquid wax. (b) Steam condensing inside a cooking pot is a physical change, as water vapor is changed into liquid water. (credit a: modification of work by \"95jb14\"/Wikimedia Commons; credit b: modification of work by \"mjneuby\"/Flickr)\n",
    "\n",
    "The change of one type of matter into another type (or the inability to change) is a chemical property. Examples of chemical properties include flammability, toxicity, acidity, and many other types of reactivity. Iron, for example, combines with oxygen in the presence of water to form rust; chromium does not oxidize (Figure 1.19). Nitroglycerin is very dangerous because it explodes easily; neon poses almost no hazard because it is very unreactive.\n",
    "![Image](Chapter_1_images/img-20.jpeg)\n",
    "\n",
    "Figure 1.19 (a) One of the chemical properties of iron is that it rusts; (b) one of the chemical properties of chromium is that it does not. (credit a: modification of work by Tony Hisgett; credit b: modification of work by \"Atoma\"/Wikimedia Commons)\n",
    "\n",
    "A chemical change always produces one or more types of matter that differ from the matter present before the change. The formation of rust is a chemical change because rust is a different kind of matter than the iron, oxygen, and water present before the rust formed. The explosion of nitroglycerin is a chemical change because the gases produced are very different kinds of matter from the original substance. Other examples of chemical changes include reactions that are performed in a lab (such as copper reacting with nitric acid), all forms of combustion (burning), and food being cooked, digested, or rotting (Figure 1.20).\n",
    "\n",
    "![Image](Chapter_1_images/img-21.jpeg)\n",
    "\n",
    "Figure 1.20 (a) Copper and nitric acid undergo a chemical change to form copper nitrate and brown, gaseous nitrogen dioxide. (b) During the combustion of a match, cellulose in the match and oxygen from the air undergo a chemical change to form carbon dioxide and water vapor. (c) Cooking red meat causes a number of chemical changes, including the oxidation of iron in myoglobin that results in the familiar red-to-brown color change. (d) A banana turning brown is a chemical change as new, darker (and less tasty) substances form. (credit b: modification of work by Jeff Turner; credit c: modification of work by Gloria Cabada-Leman; credit d: modification of work by Roberto Verzo)\n",
    "\n",
    "Properties of matter fall into one of two categories. If the property depends on the amount of matter present, it is an extensive property. The mass and volume of a substance are examples of extensive properties; for instance, a gallon of milk has a larger mass than a cup of milk. The value of an extensive property is directly proportional to the amount of matter in question. If the property of a sample of matter does not depend on the amount of matter present, it is an intensive property. Temperature is an example of an intensive property. If the gallon and cup of milk are each at $20^{\\circ} \\mathrm{C}$ (room temperature), when they are combined, the temperature remains at $20^{\\circ} \\mathrm{C}$. As another example, consider the distinct but related properties of heat and temperature. A drop of hot cooking oil spattered on your arm causes brief, minor discomfort, whereas a pot of hot oil yields severe burns. Both the drop and the pot of oil are at the same temperature (an intensive property), but the pot clearly contains much more heat (extensive property).\n",
    "\n",
    "# Chemistry in Everyday Life \n",
    "\n",
    "## Hazard Diamond\n",
    "\n",
    "You may have seen the symbol shown in Figure 1.21 on containers of chemicals in a laboratory or workplace. Sometimes called a \"fire diamond\" or \"hazard diamond,\" this chemical hazard diamond provides valuable information that briefly summarizes the various dangers of which to be aware when working with a particular\n",
    "\n",
    "substance.\n",
    "![Image](Chapter_1_images/img-22.jpeg)\n",
    "\n",
    "Figure 1.21 The National Fire Protection Agency (NFPA) hazard diamond summarizes the major hazards of a chemical substance.\n",
    "\n",
    "The National Fire Protection Agency (NFPA) 704 Hazard Identification System was developed by NFPA to provide safety information about certain substances. The system details flammability, reactivity, health, and other hazards. Within the overall diamond symbol, the top (red) diamond specifies the level of fire hazard (temperature range for flash point). The blue (left) diamond indicates the level of health hazard. The yellow (right) diamond describes reactivity hazards, such as how readily the substance will undergo detonation or a violent chemical change. The white (bottom) diamond points out special hazards, such as if it is an oxidizer (which allows the substance to burn in the absence of air/oxygen), undergoes an unusual or dangerous reaction with water, is corrosive, acidic, alkaline, a biological hazard, radioactive, and so on. Each hazard is rated on a scale from 0 to 4 , with 0 being no hazard and 4 being extremely hazardous.\n",
    "\n",
    "While many elements differ dramatically in their chemical and physical properties, some elements have similar properties. For example, many elements conduct heat and electricity well, whereas others are poor conductors. These properties can be used to sort the elements into three classes: metals (elements that conduct well), nonmetals (elements that conduct poorly), and metalloids (elements that have intermediate conductivities).\n",
    "\n",
    "The periodic table is a table of elements that places elements with similar properties close together (Figure 1.22). You will learn more about the periodic table as you continue your study of chemistry.\n",
    "\n",
    "![Image](Chapter_1_images/img-23.jpeg)\n",
    "\n",
    "Figure 1.22 The periodic table shows how elements may be grouped according to certain similar properties. Note the background color denotes whether an element is a metal, metalloid, or nonmetal, whereas the element symbol color indicates whether it is a solid, liquid, or gas.\n",
    "\n",
    "# 1.4 Measurements \n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Explain the process of measurement\n",
    "- Identify the three basic parts of a quantity\n",
    "- Describe the properties and units of length, mass, volume, density, temperature, and time\n",
    "- Perform basic unit calculations and conversions in the metric and other unit systems\n",
    "\n",
    "Measurements provide much of the information that informs the hypotheses, theories, and laws describing the behavior of matter and energy in both the macroscopic and microscopic domains of chemistry. Every measurement provides three kinds of information: the size or magnitude of the measurement (a number); a standard of comparison for the measurement (a unit); and an indication of the uncertainty of the measurement. While the number and unit are explicitly represented when a quantity is written, the uncertainty is an aspect of the measurement result that is more implicitly represented and will be discussed later.\n",
    "\n",
    "The number in the measurement can be represented in different ways, including decimal form and scientific notation.\n",
    "\n",
    "(Scientific notation is also known as exponential notation; a review of this topic can be found in Appendix B.) For example, the maximum takeoff weight of a Boeing 777-200ER airliner is 298,000 kilograms, which can also be written as $2.98 \\times 10^{5} \\mathrm{~kg}$. The mass of the average mosquito is about 0.0000025 kilograms, which can be written as $2.5 \\times 10^{-6} \\mathrm{~kg}$.\n",
    "\n",
    "Units, such as liters, pounds, and centimeters, are standards of comparison for measurements. A 2-liter bottle of a soft drink contains a volume of beverage that is twice that of the accepted volume of 1 liter. The meat used to prepare a 0.25 -pound hamburger weighs one-fourth as much as the accepted weight of 1 pound. Without units, a number can be meaningless, confusing, or possibly life threatening. Suppose a doctor prescribes phenobarbital to control a patient's seizures and states a dosage of \" 100 \" without specifying units. Not only will this be confusing to the medical professional giving the dose, but the consequences can be dire: 100 mg given three times per day can be effective as an anticonvulsant, but a single dose of 100 g is more than 10 times the lethal amount.\n",
    "\n",
    "The measurement units for seven fundamental properties (\"base units\") are listed in Table 1.2. The standards for these units are fixed by international agreement, and they are called the International System of Units or SI Units (from the French, Le Syst√®me International d'Unit√©s). SI units have been used by the United States National Institute of Standards and Technology (NIST) since 1964. Units for other properties may be derived from these seven base units.\n",
    "\n",
    "Base Units of the SI System\n",
    "\n",
    "| Property Measured | Name of Unit | Symbol of Unit |\n",
    "| :--: | :--: | :--: |\n",
    "| length | meter | m |\n",
    "| mass | kilogram | kg |\n",
    "| time | second | s |\n",
    "| temperature | kelvin | K |\n",
    "| electric current | ampere | A |\n",
    "| amount of substance | mole | mol |\n",
    "| luminous intensity | candela | cd |\n",
    "\n",
    "Table 1.2\n",
    "\n",
    "Everyday measurement units are often defined as fractions or multiples of other units. Milk is commonly packaged in containers of 1 gallon ( 4 quarts), 1 quart ( 0.25 gallon), and one pint ( 0.5 quart). This same approach is used with SI units, but these fractions or multiples are always powers of 10. Fractional or multiple SI units are named using a prefix and the name of the base unit. For example, a length of 1000 meters is also called a kilometer because the prefix kilo means \"one thousand,\" which in scientific notation is $10^{3}$ ( 1 kilometer $=1000 \\mathrm{~m}=10^{3} \\mathrm{~m}$ ). The prefixes used and the powers to which 10 are raised are listed in Table 1.3.\n",
    "\n",
    "# Common Unit Prefixes \n",
    "\n",
    "| Prefix | Symbol | Factor | Example |\n",
    "| :--: | :--: | :--: | :--: |\n",
    "| femto | f | $10^{-15}$ | 1 femtosecond (fs) $=1 \\times 10^{-15} \\mathrm{~s}(0.00000000000001 \\mathrm{~s})$ |\n",
    "| pico | p | $10^{-12}$ | 1 picometer (pm) $=1 \\times 10^{-12} \\mathrm{~m}(0.000000000001 \\mathrm{~m})$ |\n",
    "| nano | n | $10^{-9}$ | 4 nanograms (ng) $=4 \\times 10^{-9} \\mathrm{~g}(0.000000004 \\mathrm{~g})$ |\n",
    "| micro | $\\mu$ | $10^{-6}$ | 1 microliter $(\\mu \\mathrm{L})=1 \\times 10^{-6} \\mathrm{~L}(0.000001 \\mathrm{~L})$ |\n",
    "\n",
    "Table 1.3\n",
    "\n",
    "Common Unit Prefixes\n",
    "\n",
    "| Prefix | Symbol | Factor | Example |\n",
    "| :--: | :--: | :--: | :--: |\n",
    "| milli | m | $10^{-3}$ | 2 millimoles (mmol) $=2 \\times 10^{-3} \\mathrm{~mol}(0.002 \\mathrm{~mol})$ |\n",
    "| centi | c | $10^{-2}$ | 7 centimeters $(\\mathrm{cm})=7 \\times 10^{-2} \\mathrm{~m}(0.07 \\mathrm{~m})$ |\n",
    "| deci | d | $10^{-1}$ | 1 deciliter $(\\mathrm{dL})=1 \\times 10^{-1} \\mathrm{~L}(0.1 \\mathrm{~L})$ |\n",
    "| kilo | k | $10^{3}$ | 1 kilometer $(\\mathrm{km})=1 \\times 10^{3} \\mathrm{~m}(1000 \\mathrm{~m})$ |\n",
    "| mega | M | $10^{6}$ | 3 megahertz $(\\mathrm{MHz})=3 \\times 10^{6} \\mathrm{~Hz}(3,000,000 \\mathrm{~Hz})$ |\n",
    "| giga | G | $10^{9}$ | 8 gigayears $(\\mathrm{Gyr})=8 \\times 10^{9} \\mathrm{yr}(8,000,000,000 \\mathrm{yr})$ |\n",
    "| tera | T | $10^{12}$ | 5 terawatts $(\\mathrm{TW})=5 \\times 10^{12} \\mathrm{~W}(5,000,000,000,000 \\mathrm{~W})$ |\n",
    "\n",
    "Table 1.3\n",
    "\n",
    "# Link to Learning \n",
    "\n",
    "Need a refresher or more practice with scientific notation? Visit this site (http://openstaxcollege.org/1/ 16notation) to go over the basics of scientific notation.\n",
    "\n",
    "## SI Base Units\n",
    "\n",
    "The initial units of the metric system, which eventually evolved into the SI system, were established in France during the French Revolution. The original standards for the meter and the kilogram were adopted there in 1799 and eventually by other countries. This section introduces four of the SI base units commonly used in chemistry. Other SI units will be introduced in subsequent chapters.\n",
    "\n",
    "## Length\n",
    "\n",
    "The standard unit of length in both the SI and original metric systems is the meter (m). A meter was originally specified as $1 / 10,000,000$ of the distance from the North Pole to the equator. It is now defined as the distance light in a vacuum travels in $1 / 299,792,458$ of a second. A meter is about 3 inches longer than a yard (Figure 1.23); one meter is about 39.37 inches or 1.094 yards. Longer distances are often reported in kilometers ( $1 \\mathrm{~km}=1000 \\mathrm{~m}=10^{3}$ m ), whereas shorter distances can be reported in centimeters $\\left(1 \\mathrm{~cm}=0.01 \\mathrm{~m}=10^{-2} \\mathrm{~m}\\right)$ or millimeters $(1 \\mathrm{~mm}=0.001$ $\\mathrm{m}=10^{-3} \\mathrm{~m}$ ).\n",
    "\n",
    "![Image](Chapter_1_images/img-24.jpeg)\n",
    "\n",
    "Figure 1.23 The relative lengths of $1 \\mathrm{~m}, 1 \\mathrm{yd}, 1 \\mathrm{~cm}$, and 1 in . are shown (not actual size), as well as comparisons of 2.54 cm and 1 in ., and of 1 m and 1.094 yd .\n",
    "\n",
    "# Mass \n",
    "\n",
    "The standard unit of mass in the SI system is the kilogram (kg). A kilogram was originally defined as the mass of a liter of water (a cube of water with an edge length of exactly 0.1 meter). It is now defined by a certain cylinder of platinum-iridium alloy, which is kept in France (Figure 1.24). Any object with the same mass as this cylinder is said to have a mass of 1 kilogram. One kilogram is about 2.2 pounds. The gram $(\\mathrm{g})$ is exactly equal to $1 / 1000$ of the mass of the kilogram $\\left(10^{-3} \\mathrm{~kg}\\right)$.\n",
    "![Image](Chapter_1_images/img-25.jpeg)\n",
    "\n",
    "Figure 1.24 This replica prototype kilogram is housed at the National Institute of Standards and Technology (NIST) in Maryland. (credit: National Institutes of Standards and Technology)\n",
    "\n",
    "## Temperature\n",
    "\n",
    "Temperature is an intensive property. The SI unit of temperature is the kelvin (K). The IUPAC convention is to use kelvin (all lowercase) for the word, K (uppercase) for the unit symbol, and neither the word \"degree\" nor the degree\n",
    "\n",
    "symbol $\\left({ }^{\\circ}\\right)$. The degree Celsius $\\left({ }^{\\circ} \\mathbf{C}\\right)$ is also allowed in the SI system, with both the word \"degree\" and the degree symbol used for Celsius measurements. Celsius degrees are the same magnitude as those of kelvin, but the two scales place their zeros in different places. Water freezes at $273.15 \\mathrm{~K}\\left(0^{\\circ} \\mathrm{C}\\right)$ and boils at $373.15 \\mathrm{~K}\\left(100^{\\circ} \\mathrm{C}\\right)$ by definition, and normal human body temperature is approximately $310 \\mathrm{~K}\\left(37^{\\circ} \\mathrm{C}\\right)$. The conversion between these two units and the Fahrenheit scale will be discussed later in this chapter.\n",
    "\n",
    "# Time \n",
    "\n",
    "The SI base unit of time is the second (s). Small and large time intervals can be expressed with the appropriate prefixes; for example, 3 microseconds $=0.000003 \\mathrm{~s}=3 \\times 10^{-6}$ and 5 megaseconds $=5,000,000 \\mathrm{~s}=5 \\times 10^{6} \\mathrm{~s}$. Alternatively, hours, days, and years can be used.\n",
    "\n",
    "## Derived SI Units\n",
    "\n",
    "We can derive many units from the seven SI base units. For example, we can use the base unit of length to define a unit of volume, and the base units of mass and length to define a unit of density.\n",
    "\n",
    "## Volume\n",
    "\n",
    "Volume is the measure of the amount of space occupied by an object. The standard SI unit of volume is defined by the base unit of length (Figure 1.25). The standard volume is a cubic meter $\\left(\\mathbf{m}^{\\mathbf{3}}\\right)$, a cube with an edge length of exactly one meter. To dispense a cubic meter of water, we could build a cubic box with edge lengths of exactly one meter. This box would hold a cubic meter of water or any other substance.\n",
    "\n",
    "A more commonly used unit of volume is derived from the decimeter ( 0.1 m , or 10 cm ). A cube with edge lengths of exactly one decimeter contains a volume of one cubic decimeter $\\left(\\mathrm{dm}^{3}\\right)$. A liter ( $\\mathbf{L}$ ) is the more common name for the cubic decimeter. One liter is about 1.06 quarts.\n",
    "\n",
    "A cubic centimeter $\\left(\\mathbf{c m}^{\\mathbf{3}}\\right)$ is the volume of a cube with an edge length of exactly one centimeter. The abbreviation cc (for cubic centimeter) is often used by health professionals. A cubic centimeter is equivalent to a milliliter (mL) and is $1 / 1000$ of a liter.\n",
    "\n",
    "![Image](Chapter_1_images/img-26.jpeg)\n",
    "\n",
    "Figure 1.25 (a) The relative volumes are shown for cubes of $1 \\mathrm{~m}^{3}, 1 \\mathrm{dm}^{3}(1 \\mathrm{~L})$, and $1 \\mathrm{~cm}^{3}(1 \\mathrm{~mL})$ (not to scale). (b) The diameter of a dime is compared relative to the edge length of a $1-\\mathrm{cm}^{3}(1-\\mathrm{mL})$ cube.\n",
    "\n",
    "# Density \n",
    "\n",
    "We use the mass and volume of a substance to determine its density. Thus, the units of density are defined by the base units of mass and length.\n",
    "\n",
    "The density of a substance is the ratio of the mass of a sample of the substance to its volume. The SI unit for density is the kilogram per cubic meter $\\left(\\mathrm{kg} / \\mathrm{m}^{3}\\right)$. For many situations, however, this as an inconvenient unit, and we often use grams per cubic centimeter $\\left(\\mathrm{g} / \\mathrm{cm}^{3}\\right)$ for the densities of solids and liquids, and grams per liter $(\\mathrm{g} / \\mathrm{L})$ for gases. Although there are exceptions, most liquids and solids have densities that range from about $0.7 \\mathrm{~g} / \\mathrm{cm}^{3}$ (the density of gasoline) to $19 \\mathrm{~g} / \\mathrm{cm}^{3}$ (the density of gold). The density of air is about $1.2 \\mathrm{~g} / \\mathrm{L}$. Table 1.4 shows the densities of some common substances.\n",
    "\n",
    "Densities of Common Substances\n",
    "\n",
    "| Solids | Liquids | Gases (at $25^{\\circ} \\mathrm{C}$ and 1 atm ) |\n",
    "| :--: | :--: | :--: |\n",
    "| ice (at $0^{\\circ} \\mathrm{C}$ ) $0.92 \\mathrm{~g} / \\mathrm{cm}^{3}$ | water $1.0 \\mathrm{~g} / \\mathrm{cm}^{3}$ | dry air $1.20 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| oak (wood) $0.60-0.90 \\mathrm{~g} / \\mathrm{cm}^{3}$ | ethanol $0.79 \\mathrm{~g} / \\mathrm{cm}^{3}$ | oxygen $1.31 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| iron $7.9 \\mathrm{~g} / \\mathrm{cm}^{3}$ | acetone $0.79 \\mathrm{~g} / \\mathrm{cm}^{3}$ | nitrogen $1.14 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| copper $9.0 \\mathrm{~g} / \\mathrm{cm}^{3}$ | glycerin $1.26 \\mathrm{~g} / \\mathrm{cm}^{3}$ | carbon dioxide $1.80 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| lead $11.3 \\mathrm{~g} / \\mathrm{cm}^{3}$ | olive oil $0.92 \\mathrm{~g} / \\mathrm{cm}^{3}$ | helium $0.16 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| silver $10.5 \\mathrm{~g} / \\mathrm{cm}^{3}$ | gasoline $0.70-0.77 \\mathrm{~g} / \\mathrm{cm}^{3}$ | neon $0.83 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "| gold $19.3 \\mathrm{~g} / \\mathrm{cm}^{3}$ | mercury $13.6 \\mathrm{~g} / \\mathrm{cm}^{3}$ | radon $9.1 \\mathrm{~g} / \\mathrm{L}$ |\n",
    "\n",
    "Table 1.4\n",
    "\n",
    "While there are many ways to determine the density of an object, perhaps the most straightforward method involves\n",
    "\n",
    "separately finding the mass and volume of the object, and then dividing the mass of the sample by its volume. In the following example, the mass is found directly by weighing, but the volume is found indirectly through length measurements.\n",
    "\n",
    "$$\n",
    "\\text { density }=\\frac{\\text { mass }}{\\text { volume }}\n",
    "$$\n",
    "\n",
    "# Example 1.1 \n",
    "\n",
    "## Calculation of Density\n",
    "\n",
    "Gold-in bricks, bars, and coins-has been a form of currency for centuries. In order to swindle people into paying for a brick of gold without actually investing in a brick of gold, people have considered filling the centers of hollow gold bricks with lead to fool buyers into thinking that the entire brick is gold. It does not work: Lead is a dense substance, but its density is not as great as that of gold, $19.3 \\mathrm{~g} / \\mathrm{cm}^{3}$. What is the density of lead if a cube of lead has an edge length of 2.00 cm and a mass of 90.7 g ?\n",
    "\n",
    "## Solution\n",
    "\n",
    "The density of a substance can be calculated by dividing its mass by its volume. The volume of a cube is calculated by cubing the edge length.\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\text { volume of lead cube }=2.00 \\mathrm{~cm} \\times 2.00 \\mathrm{~cm} \\times 2.00 \\mathrm{~cm}=8.00 \\mathrm{~cm}^{3} \\\\\n",
    "\\text { density }=\\frac{\\text { mass }}{\\text { volume }}=\\frac{90.7 \\mathrm{~g}}{8.00 \\mathrm{~cm}^{3}}=\\frac{11.3 \\mathrm{~g}}{1.00 \\mathrm{~cm}^{3}}=11.3 \\mathrm{~g} / \\mathrm{cm}^{3}\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "(We will discuss the reason for rounding to the first decimal place in the next section.)\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "(a) To three decimal places, what is the volume of a cube $\\left(\\mathrm{cm}^{3}\\right)$ with an edge length of 0.843 cm ?\n",
    "(b) If the cube in part (a) is copper and has a mass of 5.34 g , what is the density of copper to two decimal places?\n",
    "\n",
    "Answer: (a) $0.599 \\mathrm{~cm}^{3}$; (b) $8.91 \\mathrm{~g} / \\mathrm{cm}^{3}$\n",
    "\n",
    "## Link to Learning\n",
    "\n",
    "To learn more about the relationship between mass, volume, and density, use this interactive simulator (http://openstaxcollege.org///16phetmasvolden) to explore the density of different materials, like wood, ice, brick, and aluminum.\n",
    "\n",
    "## Example 1.2\n",
    "\n",
    "## Using Displacement of Water to Determine Density\n",
    "\n",
    "This PhET simulation (http://openstaxcollege.org///16phetmasvolden) illustrates another way to determine density, using displacement of water. Determine the density of the red and yellow blocks.\n",
    "\n",
    "## Solution\n",
    "\n",
    "When you open the density simulation and select Same Mass, you can choose from several $5.00-\\mathrm{kg}$ colored blocks that you can drop into a tank containing 100.00 L water. The yellow block floats (it is less dense than\n",
    "\n",
    "water), and the water level rises to 105.00 L . While floating, the yellow block displaces 5.00 L water, an amount equal to the weight of the block. The red block sinks (it is more dense than water, which has density $=1.00 \\mathrm{~kg} / \\mathrm{L})$, and the water level rises to 101.25 L .\n",
    "\n",
    "The red block therefore displaces 1.25 L water, an amount equal to the volume of the block. The density of the red block is:\n",
    "\n",
    "$$\n",
    "\\text { density }=\\frac{\\text { mass }}{\\text { volume }}=\\frac{5.00 \\mathrm{~kg}}{1.25 \\mathrm{~L}}=4.00 \\mathrm{~kg} / \\mathrm{L}\n",
    "$$\n",
    "\n",
    "Note that since the yellow block is not completely submerged, you cannot determine its density from this information. But if you hold the yellow block on the bottom of the tank, the water level rises to 110.00 L , which means that it now displaces 10.00 L water, and its density can be found:\n",
    "\n",
    "$$\n",
    "\\text { density }=\\frac{\\text { mass }}{\\text { volume }}=\\frac{5.00 \\mathrm{~kg}}{10.00 \\mathrm{~L}}=0.500 \\mathrm{~kg} / \\mathrm{L}\n",
    "$$\n",
    "\n",
    "# Check Your Learning \n",
    "\n",
    "Remove all of the blocks from the water and add the green block to the tank of water, placing it approximately in the middle of the tank. Determine the density of the green block.\n",
    "\n",
    "Answer: $2.00 \\mathrm{~kg} / \\mathrm{L}$\n",
    "\n",
    "### 1.5 Measurement Uncertainty, Accuracy, and Precision\n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Define accuracy and precision\n",
    "- Distinguish exact and uncertain numbers\n",
    "- Correctly represent uncertainty in quantities using significant figures\n",
    "- Apply proper rounding rules to computed quantities\n",
    "\n",
    "Counting is the only type of measurement that is free from uncertainty, provided the number of objects being counted does not change while the counting process is underway. The result of such a counting measurement is an example of an exact number. By counting the eggs in a carton, one can determine exactly how many eggs the carton contains. The numbers of defined quantities are also exact. By definition, 1 foot is exactly 12 inches, 1 inch is exactly 2.54 centimeters, and 1 gram is exactly 0.001 kilogram. Quantities derived from measurements other than counting, however, are uncertain to varying extents due to practical limitations of the measurement process used.\n",
    "\n",
    "## Significant Figures in Measurement\n",
    "\n",
    "The numbers of measured quantities, unlike defined or directly counted quantities, are not exact. To measure the volume of liquid in a graduated cylinder, you should make a reading at the bottom of the meniscus, the lowest point on the curved surface of the liquid.\n",
    "\n",
    "![Image](Chapter_1_images/img-27.jpeg)\n",
    "\n",
    "Figure 1.26 To measure the volume of liquid in this graduated cylinder, you must mentally subdivide the distance between the 21 and 22 mL marks into tenths of a milliliter, and then make a reading (estimate) at the bottom of the meniscus.\n",
    "\n",
    "Refer to the illustration in Figure 1.26. The bottom of the meniscus in this case clearly lies between the 21 and 22 markings, meaning the liquid volume is certainly greater than 21 mL but less than 22 mL . The meniscus appears to be a bit closer to the $22-\\mathrm{mL}$ mark than to the $21-\\mathrm{mL}$ mark, and so a reasonable estimate of the liquid's volume would be 21.6 mL . In the number 21.6, then, the digits 2 and 1 are certain, but the 6 is an estimate. Some people might estimate the meniscus position to be equally distant from each of the markings and estimate the tenth-place digit as 5 , while others may think it to be even closer to the $22-\\mathrm{mL}$ mark and estimate this digit to be 7 . Note that it would be pointless to attempt to estimate a digit for the hundredths place, given that the tenths-place digit is uncertain. In general, numerical scales such as the one on this graduated cylinder will permit measurements to one-tenth of the smallest scale division. The scale in this case has $1-\\mathrm{mL}$ divisions, and so volumes may be measured to the nearest 0.1 mL .\n",
    "\n",
    "This concept holds true for all measurements, even if you do not actively make an estimate. If you place a quarter on a standard electronic balance, you may obtain a reading of 6.72 g . The digits 6 and 7 are certain, and the 2 indicates that the mass of the quarter is likely between 6.71 and 6.73 grams. The quarter weighs about 6.72 grams, with a nominal uncertainty in the measurement of $\\pm 0.01$ gram. If the coin is weighed on a more sensitive balance, the mass might be 6.723 g . This means its mass lies between 6.722 and 6.724 grams, an uncertainty of 0.001 gram. Every measurement has some uncertainty, which depends on the device used (and the user's ability). All of the digits in a measurement, including the uncertain last digit, are called significant figures or significant digits. Note that zero may be a measured value; for example, if you stand on a scale that shows weight to the nearest pound and it shows \"120,\" then the 1 (hundreds), 2 (tens) and 0 (ones) are all significant (measured) values.\n",
    "A measurement result is properly reported when its significant digits accurately represent the certainty of the measurement process. But what if you were analyzing a reported value and trying to determine what is significant and what is not? Well, for starters, all nonzero digits are significant, and it is only zeros that require some thought. We will use the terms \"leading,\" \"trailing,\" and \"captive\" for the zeros and will consider how to deal with them.\n",
    "\n",
    "![Image](Chapter_1_images/img-28.jpeg)\n",
    "\n",
    "Starting with the first nonzero digit on the left, count this digit and all remaining digits to the right. This is the number of significant figures in the measurement unless the last digit is a trailing zero lying to the left of the decimal point.\n",
    "![Image](Chapter_1_images/img-29.jpeg)\n",
    "\n",
    "Captive zeros result from measurement and are therefore always significant. Leading zeros, however, are never significant-they merely tell us where the decimal point is located.\n",
    "![Image](Chapter_1_images/img-30.jpeg)\n",
    "\n",
    "The leading zeros in this example are not significant. We could use exponential notation (as described in Appendix B) and express the number as $8.32407 \\times 10^{-3}$; then the number 8.32407 contains all of the significant figures, and $10^{-3}$ locates the decimal point.\n",
    "\n",
    "The number of significant figures is uncertain in a number that ends with a zero to the left of the decimal point location. The zeros in the measurement 1,300 grams could be significant or they could simply indicate where the decimal point is located. The ambiguity can be resolved with the use of exponential notation: $1.3 \\times 10^{3}$ (two significant figures), $1.30 \\times 10^{3}$ (three significant figures, if the tens place was measured), or $1.300 \\times 10^{3}$ (four significant figures, if the ones place was also measured). In cases where only the decimal-formatted number is available, it is prudent to assume that all trailing zeros are not significant.\n",
    "![Image](Chapter_1_images/img-31.jpeg)\n",
    "\n",
    "When determining significant figures, be sure to pay attention to reported values and think about the measurement and significant figures in terms of what is reasonable or likely when evaluating whether the value makes sense. For example, the official January 2014 census reported the resident population of the US as $317,297,725$. Do you think the US population was correctly determined to the reported nine significant figures, that is, to the exact number of people? People are constantly being born, dying, or moving into or out of the country, and assumptions are made to account for the large number of people who are not actually counted. Because of these uncertainties, it might be more reasonable to expect that we know the population to within perhaps a million or so, in which case the population should be reported as $3.17 \\times 10^{8}$ people.\n",
    "\n",
    "# Significant Figures in Calculations \n",
    "\n",
    "A second important principle of uncertainty is that results calculated from a measurement are at least as uncertain as\n",
    "\n",
    "the measurement itself. Take the uncertainty in measurements into account to avoid misrepresenting the uncertainty in calculated results. One way to do this is to report the result of a calculation with the correct number of significant figures, which is determined by the following three rules for rounding numbers:\n",
    "\n",
    "1. When adding or subtracting numbers, round the result to the same number of decimal places as the number with the least number of decimal places (the least certain value in terms of addition and subtraction).\n",
    "2. When multiplying or dividing numbers, round the result to the same number of digits as the number with the least number of significant figures (the least certain value in terms of multiplication and division).\n",
    "3. If the digit to be dropped (the one immediately to the right of the digit to be retained) is less than 5, \"round down\" and leave the retained digit unchanged; if it is more than 5, \"round up\" and increase the retained digit by 1 ; if the dropped digit is 5 , round up or down, whichever yields an even value for the retained digit. (The last part of this rule may strike you as a bit odd, but it's based on reliable statistics and is aimed at avoiding any bias when dropping the digit \" 5 ,\" since it is equally close to both possible values of the retained digit.)\n",
    "\n",
    "The following examples illustrate the application of this rule in rounding a few different numbers to three significant figures:\n",
    "\n",
    "- 0.028675 rounds \"up\" to 0.0287 (the dropped digit, 7, is greater than 5)\n",
    "- 18.3384 rounds \"down\" to 18.3 (the dropped digit, 3, is less than 5)\n",
    "- 6.8752 rounds \"up\" to 6.88 (the dropped digit is 5 , and the retained digit is even)\n",
    "- 92.85 rounds \"down\" to 92.8 (the dropped digit is 5 , and the retained digit is even)\n",
    "\n",
    "Let's work through these rules with a few examples.\n",
    "\n",
    "# Example 1.3 \n",
    "\n",
    "## Rounding Numbers\n",
    "\n",
    "Round the following to the indicated number of significant figures:\n",
    "(a) 31.57 (to two significant figures)\n",
    "(b) 8.1649 (to three significant figures)\n",
    "(c) 0.051065 (to four significant figures)\n",
    "(d) 0.90275 (to four significant figures)\n",
    "\n",
    "## Solution\n",
    "\n",
    "(a) 31.57 rounds \"up\" to 32 (the dropped digit is 5 , and the retained digit is even)\n",
    "(b) 8.1649 rounds \"down\" to 8.16 (the dropped digit, 4 , is less than 5 )\n",
    "(c) 0.051065 rounds \"down\" to 0.05106 (the dropped digit is 5 , and the retained digit is even)\n",
    "(d) 0.90275 rounds \"up\" to 0.9028 (the dropped digit is 5 , and the retained digit is even)\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "Round the following to the indicated number of significant figures:\n",
    "(a) 0.424 (to two significant figures)\n",
    "(b) 0.0038661 (to three significant figures)\n",
    "(c) 421.25 (to four significant figures)\n",
    "(d) 28,683.5 (to five significant figures)\n",
    "\n",
    "Answer: (a) 0.42 ; (b) 0.00387 ; (c) 421.2 ; (d) 28,684\n",
    "\n",
    "## Example 1.4\n",
    "\n",
    "## Addition and Subtraction with Significant Figures\n",
    "\n",
    "Rule: When adding or subtracting numbers, round the result to the same number of decimal places as the number with the fewest decimal places (i.e., the least certain value in terms of addition and subtraction).\n",
    "(a) Add 1.0023 g and 4.383 g .\n",
    "(b) Subtract 421.23 g from 486 g .\n",
    "\n",
    "## Solution\n",
    "\n",
    "(a) $\\frac{1.0023 \\mathrm{~g}}{+4.383 \\mathrm{~g}}$\n",
    "\n",
    "Answer is 5.385 g (round to the thousandths place; three decimal places)\n",
    "(b) $\\frac{486 \\mathrm{~g}}{-421.23 \\mathrm{~g}}$\n",
    "\n",
    "Answer is 65 g (round to the ones place; no decimal places)\n",
    "\n",
    "![Image](Chapter_1_images/img-32.jpeg)\n",
    "\n",
    "# Check Your Learning \n",
    "\n",
    "(a) Add 2.334 mL and 0.31 mL .\n",
    "(b) Subtract 55.8752 m from 56.533 m .\n",
    "\n",
    "Answer: (a) 2.64 mL ; (b) 0.658 m\n",
    "\n",
    "## Example 1.5\n",
    "\n",
    "## Multiplication and Division with Significant Figures\n",
    "\n",
    "Rule: When multiplying or dividing numbers, round the result to the same number of digits as the number with the fewest significant figures (the least certain value in terms of multiplication and division).\n",
    "(a) Multiply 0.6238 cm by 6.6 cm .\n",
    "(b) Divide 421.23 g by 486 mL .\n",
    "\n",
    "## Solution\n",
    "\n",
    "(a) $0.6238 \\mathrm{~cm} \\times 6.6 \\mathrm{~cm}=4.11708 \\mathrm{~cm}^{2} \\longrightarrow$ result is $4.1 \\mathrm{~cm}^{2}$ (round to two significant fig es)\n",
    "four significant fig es $\\times$ two significant fig es $\\longrightarrow$ two significant fig es answer\n",
    "$\\frac{421.23 \\mathrm{~g}}{486 \\mathrm{~mL}}=0.86728 \\ldots \\mathrm{~g} / \\mathrm{mL} \\longrightarrow$ result is $0.867 \\mathrm{~g} / \\mathrm{mL}$ (round to three significant fig es)\n",
    "(b) $\\frac{\\text { fi e significant fig es }}{\\text { three significant fig es }} \\longrightarrow$ three significant fig es answer\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "(a) Multiply 2.334 cm and 0.320 cm .\n",
    "(b) Divide 55.8752 m by 56.53 s .\n",
    "\n",
    "Answer: (a) $0.747 \\mathrm{~cm}^{2}$ (b) $0.9884 \\mathrm{~m} / \\mathrm{s}$\n",
    "In the midst of all these technicalities, it is important to keep in mind the reason for these rules about significant figures and rounding - to correctly represent the certainty of the values reported and to ensure that a calculated result is not represented as being more certain than the least certain value used in the calculation.\n",
    "\n",
    "## Example 1.6\n",
    "\n",
    "## Calculation with Significant Figures\n",
    "\n",
    "One common bathtub is 13.44 dm long, 5.920 dm wide, and 2.54 dm deep. Assume that the tub is rectangular and calculate its approximate volume in liters.\n",
    "\n",
    "## Solution\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V & =l \\times w \\times d \\\\\n",
    "& =13.44 \\mathrm{dm} \\times 5.920 \\mathrm{dm} \\times 2.54 \\mathrm{dm} \\\\\n",
    "& =202.09459 \\ldots \\mathrm{dm}^{3}(\\text { value from calculator }) \\\\\n",
    "& =202 \\mathrm{dm}^{3}, \\text { or } 202 \\mathrm{~L}(\\text { answer rounded to three significant fig es) }\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "# Check Your Learning \n",
    "\n",
    "What is the density of a liquid with a mass of 31.1415 g and a volume of $30.13 \\mathrm{~cm}^{3}$ ?\n",
    "Answer: $1.034 \\mathrm{~g} / \\mathrm{mL}$\n",
    "\n",
    "## Example 1.7\n",
    "\n",
    "## Experimental Determination of Density Using Water Displacement\n",
    "\n",
    "A piece of rebar is weighed and then submerged in a graduated cylinder partially filled with water, with results as shown.\n",
    "![Image](Chapter_1_images/img-33.jpeg)\n",
    "(a) Use these values to determine the density of this piece of rebar.\n",
    "(b) Rebar is mostly iron. Does your result in (a) support this statement? How?\n",
    "\n",
    "## Solution\n",
    "\n",
    "The volume of the piece of rebar is equal to the volume of the water displaced:\n",
    "\n",
    "$$\n",
    "\\text { volume }=22.4 \\mathrm{~mL}-13.5 \\mathrm{~mL}=8.9 \\mathrm{~mL}=8.9 \\mathrm{~cm}^{3}\n",
    "$$\n",
    "\n",
    "(rounded to the nearest 0.1 mL , per the rule for addition and subtraction)\n",
    "The density is the mass-to-volume ratio:\n",
    "\n",
    "$$\n",
    "\\text { density }=\\frac{\\text { mass }}{\\text { volume }}=\\frac{69.658 \\mathrm{~g}}{8.9 \\mathrm{~cm}^{3}}=7.8 \\mathrm{~g} / \\mathrm{cm}^{3}\n",
    "$$\n",
    "\n",
    "(rounded to two significant figures, per the rule for multiplication and division)\n",
    "\n",
    "From Table 1.4, the density of iron is $7.9 \\mathrm{~g} / \\mathrm{cm}^{3}$, very close to that of rebar, which lends some support to the fact that rebar is mostly iron.\n",
    "\n",
    "# Check Your Learning \n",
    "\n",
    "An irregularly shaped piece of a shiny yellowish material is weighed and then submerged in a graduated cylinder, with results as shown.\n",
    "![Image](Chapter_1_images/img-34.jpeg)\n",
    "(a) Use these values to determine the density of this material.\n",
    "(b) Do you have any reasonable guesses as to the identity of this material? Explain your reasoning.\n",
    "\n",
    "Answer: (a) $19 \\mathrm{~g} / \\mathrm{cm}^{3}$; (b) It is likely gold; the right appearance for gold and very close to the density given for gold in Table 1.4.\n",
    "\n",
    "## Accuracy and Precision\n",
    "\n",
    "Scientists typically make repeated measurements of a quantity to ensure the quality of their findings and to evaluate both the precision and the accuracy of their results. Measurements are said to be precise if they yield very similar results when repeated in the same manner. A measurement is considered accurate if it yields a result that is very close to the true or accepted value. Precise values agree with each other; accurate values agree with a true value. These characterizations can be extended to other contexts, such as the results of an archery competition (Figure 1.27).\n",
    "\n",
    "![Image](Chapter_1_images/img-35.jpeg)\n",
    "\n",
    "Figure 1.27 (a) These arrows are close to both the bull's eye and one another, so they are both accurate and precise. (b) These arrows are close to one another but not on target, so they are precise but not accurate. (c) These arrows are neither on target nor close to one another, so they are neither accurate nor precise.\n",
    "\n",
    "Suppose a quality control chemist at a pharmaceutical company is tasked with checking the accuracy and precision of three different machines that are meant to dispense 10 ounces ( 296 mL ) of cough syrup into storage bottles. She proceeds to use each machine to fill five bottles and then carefully determines the actual volume dispensed, obtaining the results tabulated in Table 1.5.\n",
    "\n",
    "Volume (mL) of Cough Medicine Delivered by 10-oz (296 mL) Dispensers\n",
    "\n",
    "| Dispenser \\#1 | Dispenser \\#2 | Dispenser \\#3 |\n",
    "| :--: | :--: | :--: |\n",
    "| 283.3 | 298.3 | 296.1 |\n",
    "| 284.1 | 294.2 | 295.9 |\n",
    "| 283.9 | 296.0 | 296.1 |\n",
    "| 284.0 | 297.8 | 296.0 |\n",
    "| 284.1 | 293.9 | 296.1 |\n",
    "\n",
    "Table 1.5\n",
    "\n",
    "Considering these results, she will report that dispenser \\#1 is precise (values all close to one another, within a few tenths of a milliliter) but not accurate (none of the values are close to the target value of 296 mL , each being more than 10 mL too low). Results for dispenser \\#2 represent improved accuracy (each volume is less than 3 mL away from 296 mL ) but worse precision (volumes vary by more than 4 mL ). Finally, she can report that dispenser \\#3 is working well, dispensing cough syrup both accurately (all volumes within 0.1 mL of the target volume) and precisely (volumes differing from each other by no more than 0.2 mL ).\n",
    "\n",
    "# 1.6 Mathematical Treatment of Measurement Results \n",
    "\n",
    "By the end of this section, you will be able to:\n",
    "\n",
    "- Explain the dimensional analysis (factor label) approach to mathematical calculations involving quantities\n",
    "- Use dimensional analysis to carry out unit conversions for a given property and computations involving two or more properties\n",
    "\n",
    "It is often the case that a quantity of interest may not be easy (or even possible) to measure directly but instead must be calculated from other directly measured properties and appropriate mathematical relationships. For example, consider measuring the average speed of an athlete running sprints. This is typically accomplished by measuring the time required for the athlete to run from the starting line to the finish line, and the distance between these two lines, and then computing speed from the equation that relates these three properties:\n",
    "\n",
    "$$\n",
    "\\text { speed }=\\frac{\\text { distance }}{\\text { time }}\n",
    "$$\n",
    "\n",
    "An Olympic-quality sprinter can run 100 m in approximately 10 s , corresponding to an average speed of\n",
    "\n",
    "$$\n",
    "\\frac{100 \\mathrm{~m}}{10 \\mathrm{~s}}=10 \\mathrm{~m} / \\mathrm{s}\n",
    "$$\n",
    "\n",
    "Note that this simple arithmetic involves dividing the numbers of each measured quantity to yield the number of the computed quantity $(100 / 10=10)$ and likewise dividing the units of each measured quantity to yield the unit of the computed quantity $(\\mathrm{m} / \\mathrm{s}=\\mathrm{m} / \\mathrm{s})$. Now, consider using this same relation to predict the time required for a person running at this speed to travel a distance of 25 m . The same relation among the three properties is used, but in this case, the two quantities provided are a speed $(10 \\mathrm{~m} / \\mathrm{s})$ and a distance $(25 \\mathrm{~m})$. To yield the sought property, time, the equation must be rearranged appropriately:\n",
    "\n",
    "$$\n",
    "\\text { time }=\\frac{\\text { distance }}{\\text { speed }}\n",
    "$$\n",
    "\n",
    "The time can then be computed as:\n",
    "\n",
    "$$\n",
    "\\frac{25 \\mathrm{~m}}{10 \\mathrm{~m} / \\mathrm{s}}=2.5 \\mathrm{~s}\n",
    "$$\n",
    "\n",
    "Again, arithmetic on the numbers $(25 / 10=2.5)$ was accompanied by the same arithmetic on the units $(\\mathrm{m} / \\mathrm{m} / \\mathrm{s}=\\mathrm{s})$ to yield the number and unit of the result, 2.5 s . Note that, just as for numbers, when a unit is divided by an identical unit (in this case, $\\mathrm{m} / \\mathrm{m}$ ), the result is \" 1 \"-or, as commonly phrased, the units \"cancel.\"\n",
    "\n",
    "These calculations are examples of a versatile mathematical approach known as dimensional analysis (or the factorlabel method). Dimensional analysis is based on this premise: the units of quantities must be subjected to the same mathematical operations as their associated numbers. This method can be applied to computations ranging from simple unit conversions to more complex, multi-step calculations involving several different quantities.\n",
    "\n",
    "# Conversion Factors and Dimensional Analysis \n",
    "\n",
    "A ratio of two equivalent quantities expressed with different measurement units can be used as a unit conversion factor. For example, the lengths of 2.54 cm and 1 in . are equivalent (by definition), and so a unit conversion factor may be derived from the ratio,\n",
    "\n",
    "$$\n",
    "\\frac{2.54 \\mathrm{~cm}}{1 \\mathrm{in} .}(2.54 \\mathrm{~cm}=1 \\mathrm{in} .) \\text { or } 2.54 \\frac{\\mathrm{~cm}}{\\mathrm{in} .}\n",
    "$$\n",
    "\n",
    "Several other commonly used conversion factors are given in Table 1.6.\n",
    "Common Conversion Factors\n",
    "\n",
    "| Length | Volume | Mass |\n",
    "| :--: | :--: | :--: |\n",
    "| $1 \\mathrm{~m}=1.0936 \\mathrm{yd}$ | $1 \\mathrm{~L}=1.0567 \\mathrm{qt}$ | $1 \\mathrm{~kg}=2.2046 \\mathrm{lb}$ |\n",
    "| $1 \\mathrm{in} .=2.54 \\mathrm{~cm}$ (exact) | $1 \\mathrm{qt}=0.94635 \\mathrm{~L}$ | $1 \\mathrm{lb}=453.59 \\mathrm{~g}$ |\n",
    "| $1 \\mathrm{~km}=0.62137 \\mathrm{mi}$ | $1 \\mathrm{ft}^{3}=28.317 \\mathrm{~L}$ | 1 (avoirdupois) oz $=28.349 \\mathrm{~g}$ |\n",
    "| $1 \\mathrm{mi}=1609.3 \\mathrm{~m}$ | $1 \\mathrm{tbsp}=14.787 \\mathrm{~mL}$ | 1 (troy) oz $=31.103 \\mathrm{~g}$ |\n",
    "\n",
    "Table 1.6\n",
    "\n",
    "When a quantity (such as distance in inches) is multiplied by an appropriate unit conversion factor, the quantity is converted to an equivalent value with different units (such as distance in centimeters). For example, a basketball player's vertical jump of 34 inches can be converted to centimeters by:\n",
    "\n",
    "$$\n",
    "34 \\text { in. } \\times \\frac{2.54 \\mathrm{~cm}}{1 \\mathrm{in}}=86 \\mathrm{~cm}\n",
    "$$\n",
    "\n",
    "Since this simple arithmetic involves quantities, the premise of dimensional analysis requires that we multiply both numbers and units. The numbers of these two quantities are multiplied to yield the number of the product quantity, 86, whereas the units are multiplied to yield $\\frac{\\mathrm{in} . \\times \\mathrm{cm}}{\\mathrm{in} .}$. Just as for numbers, a ratio of identical units is also numerically equal to one, $\\frac{\\mathrm{in} .}{\\mathrm{in} .}=1$, and the unit product thus simplifies to $c m$. (When identical units divide to yield a factor of 1, they are said to \"cancel.\") Dimensional analysis may be used to confirm the proper application of unit conversion factors as demonstrated in the following example.\n",
    "\n",
    "# Example 1.8 \n",
    "\n",
    "## Using a Unit Conversion Factor\n",
    "\n",
    "The mass of a competition frisbee is 125 g . Convert its mass to ounces using the unit conversion factor derived from the relationship $1 \\mathrm{oz}=28.349 \\mathrm{~g}$ (Table 1.6).\n",
    "\n",
    "## Solution\n",
    "\n",
    "Given the conversion factor, the mass in ounces may be derived using an equation similar to the one used for converting length from inches to centimeters.\n",
    "\n",
    "$$\n",
    "x \\mathrm{oz}=125 \\mathrm{~g} \\times \\text { unit conversion factor }\n",
    "$$\n",
    "\n",
    "The unit conversion factor may be represented as:\n",
    "\n",
    "$$\n",
    "\\frac{1 \\mathrm{oz}}{28.349 \\mathrm{~g}} \\text { and } \\frac{28.349 \\mathrm{~g}}{1 \\mathrm{oz}}\n",
    "$$\n",
    "\n",
    "The correct unit conversion factor is the ratio that cancels the units of grams and leaves ounces.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x \\mathrm{oz} & =125 \\# \\times \\frac{1 \\mathrm{oz}}{28.349 \\#} \\\\\n",
    "& =\\left(\\frac{125}{28.349}\\right) \\mathrm{oz} \\\\\n",
    "& =4.41 \\mathrm{oz}(\\text { three significant fig es) }\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "Convert a volume of 9.345 qt to liters.\n",
    "\n",
    "Beyond simple unit conversions, the factor-label method can be used to solve more complex problems involving computations. Regardless of the details, the basic approach is the same-all the factors involved in the calculation must be appropriately oriented to ensure that their labels (units) will appropriately cancel and/or combine to yield the desired unit in the result. As your study of chemistry continues, you will encounter many opportunities to apply this approach.\n",
    "\n",
    "# Example 1.9 \n",
    "\n",
    "## Computing Quantities from Measurement Results and Known Mathematical Relations\n",
    "\n",
    "What is the density of common antifreeze in units of $\\mathrm{g} / \\mathrm{mL}$ ? A $4.00-\\mathrm{qt}$ sample of the antifreeze weighs 9.26 lb .\n",
    "\n",
    "## Solution\n",
    "\n",
    "Since density $=\\frac{\\text { mass }}{\\text { volume }}$, we need to divide the mass in grams by the volume in milliliters. In general: the number of units of $B=$ the number of units of $A \\times$ unit conversion factor. The necessary conversion factors are given in Table 1.6: $1 \\mathrm{lb}=453.59 \\mathrm{~g} ; 1 \\mathrm{~L}=1.0567 \\mathrm{qt} ; 1 \\mathrm{~L}=1,000 \\mathrm{~mL}$. Mass may be converted from pounds to grams as follows:\n",
    "\n",
    "$$\n",
    "9.26 \\# \\times \\frac{453.59 \\mathrm{~g}}{1 \\#}=4.20 \\times 10^{3} \\mathrm{~g}\n",
    "$$\n",
    "\n",
    "Volume may be converted from quarts to millimeters via two steps:\n",
    "Step 1. Convert quarts to liters.\n",
    "\n",
    "$$\n",
    "4.00 \\text { qt } \\times \\frac{1 \\mathrm{~L}}{1.0567 \\text { qt }}=3.78 \\mathrm{~L}\n",
    "$$\n",
    "\n",
    "Step 2. Convert liters to milliliters.\n",
    "\n",
    "$$\n",
    "3.78 \\pm \\times \\frac{1000 \\mathrm{~mL}}{1 \\mathrm{t}}=3.78 \\times 10^{3} \\mathrm{~mL}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\text { density }=\\frac{4.20 \\times 10^{3} \\mathrm{~g}}{3.78 \\times 10^{3} \\mathrm{~mL}}=1.11 \\mathrm{~g} / \\mathrm{mL}\n",
    "$$\n",
    "\n",
    "Alternatively, the calculation could be set up in a way that uses three unit conversion factors sequentially as follows:\n",
    "\n",
    "$$\n",
    "\\frac{9.26 \\#}{4.00 \\text { qt }} \\times \\frac{453.59 \\mathrm{~g}}{1 \\# \\#} \\times \\frac{1.0567 \\text { qt }}{1 \\mathrm{t}} \\times \\frac{1 \\mathrm{t}}{1000 \\mathrm{~mL}}=1.11 \\mathrm{~g} / \\mathrm{mL}\n",
    "$$\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "What is the volume in liters of 1.000 oz , given that $1 \\mathrm{~L}=1.0567 \\mathrm{qt}$ and $1 \\mathrm{qt}=32 \\mathrm{oz}$ (exactly)?\n",
    "Answer: $2.956 \\times 10^{-2} \\mathrm{~L}$\n",
    "\n",
    "## Example 1.10\n",
    "\n",
    "## Computing Quantities from Measurement Results and Known Mathematical Relations\n",
    "\n",
    "While being driven from Philadelphia to Atlanta, a distance of about 1250 km, a 2014 Lamborghini Aventador Roadster uses 213 L gasoline.\n",
    "(a) What (average) fuel economy, in miles per gallon, did the Roadster get during this trip?\n",
    "\n",
    "(b) If gasoline costs $\\$ 3.80$ per gallon, what was the fuel cost for this trip?\n",
    "\n",
    "# Solution \n",
    "\n",
    "(a) First convert distance from kilometers to miles:\n",
    "\n",
    "$$\n",
    "1250 \\mathrm{~km} \\times \\frac{0.62137 \\mathrm{mi}}{1 \\mathrm{~km}}=777 \\mathrm{mi}\n",
    "$$\n",
    "\n",
    "and then convert volume from liters to gallons:\n",
    "\n",
    "$$\n",
    "213 \\mathrm{~L} \\times \\frac{1.0567 \\mathrm{mi}}{1 \\mathrm{~L}} \\times \\frac{1 \\mathrm{gal}}{4 \\mathrm{mi}}=56.3 \\mathrm{gal}\n",
    "$$\n",
    "\n",
    "Finally,\n",
    "\n",
    "$$\n",
    "\\text { (average) mileage }=\\frac{777 \\mathrm{mi}}{56.3 \\mathrm{gal}}=13.8 \\text { miles } / \\text { gallon }=13.8 \\mathrm{mpg}\n",
    "$$\n",
    "\n",
    "Alternatively, the calculation could be set up in a way that uses all the conversion factors sequentially, as follows:\n",
    "\n",
    "$$\n",
    "\\frac{1250 \\mathrm{~km}}{213 \\mathrm{~L}} \\times \\frac{0.62137 \\mathrm{mi}}{1 \\mathrm{~km}} \\times \\frac{1 \\mathrm{~L}}{1.0567 \\mathrm{mi}} \\times \\frac{4 \\mathrm{mi}}{1 \\mathrm{gal}}=13.8 \\mathrm{mpg}\n",
    "$$\n",
    "\n",
    "(b) Using the previously calculated volume in gallons, we find:\n",
    "\n",
    "$$\n",
    "56.3 \\mathrm{gal} \\times \\frac{\\$ 3.80}{1 \\mathrm{gal}}=\\$ 214\n",
    "$$\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "A Toyota Prius Hybrid uses 59.7 L gasoline to drive from San Francisco to Seattle, a distance of 1300 km (two significant digits).\n",
    "(a) What (average) fuel economy, in miles per gallon, did the Prius get during this trip?\n",
    "(b) If gasoline costs $\\$ 3.90$ per gallon, what was the fuel cost for this trip?\n",
    "\n",
    "Answer: (a) 51 mpg ; (b) $\\$ 62$\n",
    "\n",
    "## Conversion of Temperature Units\n",
    "\n",
    "We use the word temperature to refer to the hotness or coldness of a substance. One way we measure a change in temperature is to use the fact that most substances expand when their temperature increases and contract when their temperature decreases. The mercury or alcohol in a common glass thermometer changes its volume as the temperature changes, and the position of the trapped liquid along a printed scale may be used as a measure of temperature.\n",
    "\n",
    "Temperature scales are defined relative to selected reference temperatures: Two of the most commonly used are the freezing and boiling temperatures of water at a specified atmospheric pressure. On the Celsius scale, $0^{\\circ} \\mathrm{C}$ is defined as the freezing temperature of water and $100^{\\circ} \\mathrm{C}$ as the boiling temperature of water. The space between the two temperatures is divided into 100 equal intervals, which we call degrees. On the Fahrenheit scale, the freezing point of water is defined as $32^{\\circ} \\mathrm{F}$ and the boiling temperature as $212^{\\circ} \\mathrm{F}$. The space between these two points on a Fahrenheit thermometer is divided into 180 equal parts (degrees).\n",
    "\n",
    "Defining the Celsius and Fahrenheit temperature scales as described in the previous paragraph results in a slightly more complex relationship between temperature values on these two scales than for different units of measure for other properties. Most measurement units for a given property are directly proportional to one another ( $y=m x$ ). Using familiar length units as one example:\n",
    "\n",
    "$$\n",
    "\\text { length in feet }=\\left(\\frac{1 \\mathrm{ft}}{12 \\mathrm{in}}\\right) \\times \\text { length in inches }\n",
    "$$\n",
    "\n",
    "where $\\mathrm{y}=$ length in feet, $\\mathrm{x}=$ length in inches, and the proportionality constant, m , is the conversion factor. The Celsius\n",
    "\n",
    "and Fahrenheit temperature scales, however, do not share a common zero point, and so the relationship between these two scales is a linear one rather than a proportional one $(\\mathrm{y}=\\mathrm{mx}+\\mathrm{b})$. Consequently, converting a temperature from one of these scales into the other requires more than simple multiplication by a conversion factor, $m$, it also must take into account differences in the scales' zero points (b).\n",
    "\n",
    "The linear equation relating Celsius and Fahrenheit temperatures is easily derived from the two temperatures used to define each scale. Representing the Celsius temperature as $x$ and the Fahrenheit temperature as $y$, the slope, $m$, is computed to be:\n",
    "\n",
    "$$\n",
    "m=\\frac{\\Delta y}{\\Delta x}=\\frac{212}{100}^{\\circ} \\mathrm{F}-\\frac{32}{100}^{\\circ} \\mathrm{F}=\\frac{180}{100}^{\\circ} \\mathrm{F}=\\frac{9}{5}^{\\circ} \\mathrm{F}\n",
    "$$\n",
    "\n",
    "The $y$-intercept of the equation, $b$, is then calculated using either of the equivalent temperature pairs, $\\left(100^{\\circ} \\mathrm{C}, 212^{\\circ} \\mathrm{F}\\right)$ or $\\left(0^{\\circ} \\mathrm{C}, 32^{\\circ} \\mathrm{F}\\right)$, as:\n",
    "\n",
    "$$\n",
    "b=y-m x=32^{\\circ} \\mathrm{F}-\\frac{9}{5}^{\\circ} \\mathrm{F} \\times 0^{\\circ} \\mathrm{C}=32^{\\circ} \\mathrm{F}\n",
    "$$\n",
    "\n",
    "The equation relating the temperature $(T)$ scales is then:\n",
    "\n",
    "$$\n",
    "T_{\\circ \\mathrm{F}}=\\left(\\frac{9}{5}^{\\circ} \\mathrm{F} \\times T_{\\circ} \\mathrm{C}\\right)+32^{\\circ} \\mathrm{C}\n",
    "$$\n",
    "\n",
    "An abbreviated form of this equation that omits the measurement units is:\n",
    "\n",
    "$$\n",
    "T_{\\circ \\mathrm{F}}=\\left(\\frac{9}{5} \\times T_{\\circ} \\mathrm{C}\\right)+32\n",
    "$$\n",
    "\n",
    "Rearrangement of this equation yields the form useful for converting from Fahrenheit to Celsius:\n",
    "\n",
    "$$\n",
    "T_{\\circ} \\mathrm{C}=\\frac{5}{9}\\left(T_{\\circ} \\mathrm{F}-32\\right)\n",
    "$$\n",
    "\n",
    "As mentioned earlier in this chapter, the SI unit of temperature is the kelvin (K). Unlike the Celsius and Fahrenheit scales, the kelvin scale is an absolute temperature scale in which 0 (zero) K corresponds to the lowest temperature that can theoretically be achieved. Since the kelvin temperature scale is absolute, a degree symbol is not included in the unit abbreviation, K. The early 19th-century discovery of the relationship between a gas's volume and temperature suggested that the volume of a gas would be zero at $-273.15^{\\circ} \\mathrm{C}$. In 1848, British physicist William Thompson, who later adopted the title of Lord Kelvin, proposed an absolute temperature scale based on this concept (further treatment of this topic is provided in this text's chapter on gases).\n",
    "\n",
    "The freezing temperature of water on this scale is 273.15 K and its boiling temperature is 373.15 K . Notice the numerical difference in these two reference temperatures is 100 , the same as for the Celsius scale, and so the linear relation between these two temperature scales will exhibit a slope of $1 \\frac{\\mathrm{~K}}{\\circ} \\mathrm{C}$. Following the same approach, the equations for converting between the kelvin and Celsius temperature scales are derived to be:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& T_{\\mathrm{K}}=T_{\\circ \\mathrm{C}}+273.15 \\\\\n",
    "& T_{\\circ} \\mathrm{C}=T_{\\mathrm{K}}-273.15\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The 273.15 in these equations has been determined experimentally, so it is not exact. Figure 1.28 shows the relationship among the three temperature scales.\n",
    "\n",
    "![Image](Chapter_1_images/img-36.jpeg)\n",
    "\n",
    "Figure 1.28 The Fahrenheit, Celsius, and kelvin temperature scales are compared.\n",
    "\n",
    "Although the kelvin (absolute) temperature scale is the official SI temperature scale, Celsius is commonly used in many scientific contexts and is the scale of choice for nonscience contexts in almost all areas of the world. Very few countries (the U.S. and its territories, the Bahamas, Belize, Cayman Islands, and Palau) still use Fahrenheit for weather, medicine, and cooking.\n",
    "\n",
    "# Example 1.11 \n",
    "\n",
    "## Conversion from Celsius\n",
    "\n",
    "Normal body temperature has been commonly accepted as $37.0^{\\circ} \\mathrm{C}$ (although it varies depending on time of day and method of measurement, as well as among individuals). What is this temperature on the kelvin scale and on the Fahrenheit scale?\n",
    "\n",
    "## Solution\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathrm{K}={ }^{\\circ} \\mathrm{C}+273.15=37.0+273.2=310.2 \\mathrm{~K} \\\\\n",
    "{ }^{\\circ} \\mathrm{F}=\\frac{9}{5}{ }^{\\circ} \\mathrm{C}+32.0=\\left(\\frac{9}{5} \\times 37.0\\right)+32.0=66.6+32.0=98.6^{\\circ} \\mathrm{F}\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "Convert $80.92^{\\circ} \\mathrm{C}$ to K and ${ }^{\\circ} \\mathrm{F}$.\n",
    "Answer: $354.07 \\mathrm{~K}, 177.7^{\\circ} \\mathrm{F}$\n",
    "\n",
    "## Example 1.12\n",
    "\n",
    "## Conversion from Fahrenheit\n",
    "\n",
    "Baking a ready-made pizza calls for an oven temperature of $450^{\\circ} \\mathrm{F}$. If you are in Europe, and your oven thermometer uses the Celsius scale, what is the setting? What is the kelvin temperature?\n",
    "\n",
    "## Solution\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "{ }^{\\circ} \\mathrm{C}=\\frac{5}{9}\\left({ }^{\\circ} \\mathrm{F}-32\\right)=\\frac{5}{9}(450-32)=\\frac{5}{9} \\times 418=232^{\\circ} \\mathrm{C} \\longrightarrow \\text { set oven to } 230^{\\circ} \\mathrm{C} \\quad \\text { (two significant fig es) } \\\\\n",
    "\\mathrm{K}={ }^{\\circ} \\mathrm{C}+273.15=230+273=503 \\mathrm{~K} \\longrightarrow 5.0 \\times 10^{2} \\mathrm{~K} \\quad \\text { (two significant fig es) }\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "## Check Your Learning\n",
    "\n",
    "Convert $50^{\\circ} \\mathrm{F}$ to ${ }^{\\circ} \\mathrm{C}$ and K .\n",
    "Answer: $10^{\\circ} \\mathrm{C}, 280 \\mathrm{~K}$\n",
    "\n",
    "# Key Terms \n",
    "\n",
    "accuracy how closely a measurement aligns with a correct value\n",
    "atom smallest particle of an element that can enter into a chemical combination\n",
    "Celsius $\\left({ }^{\\circ} \\mathbf{C}\\right)$ unit of temperature; water freezes at $0^{\\circ} \\mathrm{C}$ and boils at $100^{\\circ} \\mathrm{C}$ on this scale\n",
    "chemical change change producing a different kind of matter from the original kind of matter\n",
    "chemical property behavior that is related to the change of one kind of matter into another kind of matter\n",
    "chemistry study of the composition, properties, and interactions of matter\n",
    "compound pure substance that can be decomposed into two or more elements\n",
    "cubic centimeter $\\left(\\mathbf{c m}^{3}\\right.$ or cc ) volume of a cube with an edge length of exactly 1 cm\n",
    "cubic meter $\\left(\\mathbf{m}^{3}\\right)$ SI unit of volume\n",
    "density ratio of mass to volume for a substance or object\n",
    "dimensional analysis (also, factor-label method) versatile mathematical approach that can be applied to computations ranging from simple unit conversions to more complex, multi-step calculations involving several different quantities\n",
    "element substance that is composed of a single type of atom; a substance that cannot be decomposed by a chemical change\n",
    "exact number number derived by counting or by definition\n",
    "extensive property property of a substance that depends on the amount of the substance\n",
    "Fahrenheit unit of temperature; water freezes at $32^{\\circ} \\mathrm{F}$ and boils at $212^{\\circ} \\mathrm{F}$ on this scale\n",
    "gas state in which matter has neither definite volume nor shape\n",
    "heterogeneous mixture combination of substances with a composition that varies from point to point\n",
    "homogeneous mixture (also, solution) combination of substances with a composition that is uniform throughout\n",
    "hypothesis tentative explanation of observations that acts as a guide for gathering and checking information\n",
    "intensive property property of a substance that is independent of the amount of the substance\n",
    "kelvin (K) SI unit of temperature; $273.15 \\mathrm{~K}=0^{\\circ} \\mathrm{C}$\n",
    "kilogram (kg) standard SI unit of mass; 1 kg = approximately 2.2 pounds\n",
    "law statement that summarizes a vast number of experimental observations, and describes or predicts some aspect of the natural world\n",
    "law of conservation of matter when matter converts from one type to another or changes form, there is no detectable change in the total amount of matter present\n",
    "length measure of one dimension of an object\n",
    "liquid state of matter that has a definite volume but indefinite shape\n",
    "\n",
    "liter (L) (also, cubic decimeter) unit of volume; $1 \\mathrm{~L}=1,000 \\mathrm{~cm}^{3}$\n",
    "macroscopic domain realm of everyday things that are large enough to sense directly by human sight and touch\n",
    "mass fundamental property indicating amount of matter\n",
    "matter anything that occupies space and has mass\n",
    "meter (m) standard metric and SI unit of length; $1 \\mathrm{~m}=$ approximately 1.094 yards\n",
    "microscopic domain realm of things that are much too small to be sensed directly\n",
    "milliliter (mL) 1/1,000 of a liter; equal to $1 \\mathrm{~cm}^{3}$\n",
    "mixture matter that can be separated into its components by physical means\n",
    "molecule bonded collection of two or more atoms of the same or different elements\n",
    "physical change change in the state or properties of matter that does not involve a change in its chemical composition\n",
    "physical property characteristic of matter that is not associated with any change in its chemical composition\n",
    "plasma gaseous state of matter containing a large number of electrically charged atoms and/or molecules\n",
    "precision how closely a measurement matches the same measurement when repeated\n",
    "pure substance homogeneous substance that has a constant composition\n",
    "rounding procedure used to ensure that calculated results properly reflect the uncertainty in the measurements used in the calculation\n",
    "scientific method path of discovery that leads from question and observation to law or hypothesis to theory, combined with experimental verification of the hypothesis and any necessary modification of the theory\n",
    "second (s) SI unit of time\n",
    "SI units (International System of Units) standards fixed by international agreement in the International System of Units (Le Syst√®me International d'Unit√©s)\n",
    "significant figures (also, significant digits) all of the measured digits in a determination, including the uncertain last digit\n",
    "solid state of matter that is rigid, has a definite shape, and has a fairly constant volume\n",
    "symbolic domain specialized language used to represent components of the macroscopic and microscopic domains, such as chemical symbols, chemical formulas, chemical equations, graphs, drawings, and calculations\n",
    "temperature intensive property representing the hotness or coldness of matter\n",
    "theory well-substantiated, comprehensive, testable explanation of a particular aspect of nature\n",
    "uncertainty estimate of amount by which measurement differs from true value\n",
    "unit standard of comparison for measurements\n",
    "unit conversion factor ratio of equivalent quantities expressed with different units; used to convert from one unit to a different unit\n",
    "\n",
    "volume amount of space occupied by an object\n",
    "weight force that gravity exerts on an object\n",
    "\n",
    "# Key Equations \n",
    "\n",
    "- density $=\\frac{\\text { mass }}{\\text { volume }}$\n",
    "- $T_{\\circ C}=\\frac{5}{9} \\times\\left(T_{\\circ F}-32\\right)$\n",
    "- $T_{\\circ F}=\\left(\\frac{9}{5} \\times T_{\\circ}\\right)+32$\n",
    "- $T_{\\mathrm{K}}={ }^{\\circ} \\mathrm{C}+273.15$\n",
    "- $T_{\\circ \\mathrm{C}}=\\mathrm{K}-273.15$\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "### 1.1 Chemistry in Context\n",
    "\n",
    "Chemistry deals with the composition, structure, and properties of matter, and the ways by which various forms of matter may be interconverted. Thus, it occupies a central place in the study and practice of science and technology. Chemists use the scientific method to perform experiments, pose hypotheses, and formulate laws and develop theories, so that they can better understand the behavior of the natural world. To do so, they operate in the macroscopic, microscopic, and symbolic domains. Chemists measure, analyze, purify, and synthesize a wide variety of substances that are important to our lives.\n",
    "\n",
    "### 1.2 Phases and Classification of Matter\n",
    "\n",
    "Matter is anything that occupies space and has mass. The basic building block of matter is the atom, the smallest unit of an element that can enter into combinations with atoms of the same or other elements. In many substances, atoms are combined into molecules. On earth, matter commonly exists in three states: solids, of fixed shape and volume; liquids, of variable shape but fixed volume; and gases, of variable shape and volume. Under high-temperature conditions, matter also can exist as a plasma. Most matter is a mixture: It is composed of two or more types of matter that can be present in varying amounts and can be separated by physical means. Heterogeneous mixtures vary in composition from point to point; homogeneous mixtures have the same composition from point to point. Pure substances consist of only one type of matter. A pure substance can be an element, which consists of only one type of atom and cannot be broken down by a chemical change, or a compound, which consists of two or more types of atoms.\n",
    "\n",
    "### 1.3 Physical and Chemical Properties\n",
    "\n",
    "All substances have distinct physical and chemical properties, and may undergo physical or chemical changes. Physical properties, such as hardness and boiling point, and physical changes, such as melting or freezing, do not involve a change in the composition of matter. Chemical properties, such flammability and acidity, and chemical changes, such as rusting, involve production of matter that differs from that present beforehand.\n",
    "\n",
    "Measurable properties fall into one of two categories. Extensive properties depend on the amount of matter present, for example, the mass of gold. Intensive properties do not depend on the amount of matter present, for example, the density of gold. Heat is an example of an extensive property, and temperature is an example of an intensive property.\n",
    "\n",
    "### 1.4 Measurements\n",
    "\n",
    "Measurements provide quantitative information that is critical in studying and practicing chemistry. Each measurement has an amount, a unit for comparison, and an uncertainty. Measurements can be represented in either decimal or scientific notation. Scientists primarily use SI (International System) units such as meters, seconds, and kilograms, as well as derived units, such as liters (for volume) and $\\mathrm{g} / \\mathrm{cm}^{3}$ (for density). In many cases, it is convenient\n",
    "\n",
    "to use prefixes that yield fractional and multiple units, such as microseconds ( $10^{-6}$ seconds) and megahertz ( $10^{6}$ hertz), respectively.\n",
    "\n",
    "# 1.5 Measurement Uncertainty, Accuracy, and Precision \n",
    "\n",
    "Quantities can be defined or measured. Measured quantities have an associated uncertainty that is represented by the number of significant figures in the quantity's number. The uncertainty of a calculated quantity depends on the uncertainties in the quantities used in the calculation and is reflected in how the value is rounded. Quantities are characterized with regard to accuracy (closeness to a true or accepted value) and precision (variation among replicate measurement results).\n",
    "\n",
    "### 1.6 Mathematical Treatment of Measurement Results\n",
    "\n",
    "Measurements are made using a variety of units. It is often useful or necessary to convert a measured quantity from one unit into another. These conversions are accomplished using unit conversion factors, which are derived by simple applications of a mathematical approach called the factor-label method or dimensional analysis. This strategy is also employed to calculate sought quantities using measured quantities and appropriate mathematical relations.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### 1.1 Chemistry in Context\n",
    "\n",
    "1. Explain how you could experimentally determine whether the outside temperature is higher or lower than $0^{\\circ} \\mathrm{C}$ $\\left(32^{\\circ} \\mathrm{F}\\right)$ without using a thermometer.\n",
    "2. Identify each of the following statements as being most similar to a hypothesis, a law, or a theory. Explain your reasoning.\n",
    "(a) Falling barometric pressure precedes the onset of bad weather.\n",
    "(b) All life on earth has evolved from a common, primitive organism through the process of natural selection.\n",
    "(c) My truck's gas mileage has dropped significantly, probably because it's due for a tune-up.\n",
    "3. Identify each of the following statements as being most similar to a hypothesis, a law, or a theory. Explain your reasoning.\n",
    "(a) The pressure of a sample of gas is directly proportional to the temperature of the gas.\n",
    "(b) Matter consists of tiny particles that can combine in specific ratios to form substances with specific properties.\n",
    "(c) At a higher temperature, solids (such as salt or sugar) will dissolve better in water.\n",
    "4. Identify each of the underlined items as a part of either the macroscopic domain, the microscopic domain, or the symbolic domain of chemistry. For any in the symbolic domain, indicate whether they are symbols for a macroscopic or a microscopic feature.\n",
    "(a) The mass of a lead pipe is 14 lb .\n",
    "(b) The mass of a certain chlorine atom is 35 amu .\n",
    "(c) A bottle with a label that reads $\\underline{\\mathrm{Al}}$ contains aluminum metal.\n",
    "(d) $\\underline{\\mathrm{Al}}$ is the symbol for an aluminum atom.\n",
    "\n",
    "5. Identify each of the underlined items as a part of either the macroscopic domain, the microscopic domain, or the symbolic domain of chemistry. For those in the symbolic domain, indicate whether they are symbols for a macroscopic or a microscopic feature.\n",
    "(a) A certain molecule contains one $\\underline{\\mathrm{H}}$ atom and one Cl atom.\n",
    "(b) Copper wire has a density of about $8 \\mathrm{~g} / \\mathrm{cm}^{3}$.\n",
    "(c) The bottle contains 15 grams of Ni powder.\n",
    "(d) A sulfur molecule is composed of eight sulfur atoms.\n",
    "6. According to one theory, the pressure of a gas increases as its volume decreases because the molecules in the gas have to move a shorter distance to hit the walls of the container. Does this theory follow a macroscopic or microscopic description of chemical behavior? Explain your answer.\n",
    "7. The amount of heat required to melt 2 lbs of ice is twice the amount of heat required to melt 1 lb of ice. Is this observation a macroscopic or microscopic description of chemical behavior? Explain your answer.\n",
    "\n",
    "# 1.2 Phases and Classification of Matter \n",
    "\n",
    "8. Why is an object's mass, rather than its weight, used to indicate the amount of matter it contains?\n",
    "9. What properties distinguish solids from liquids? Liquids from gases? Solids from gases?\n",
    "10. How does a heterogeneous mixture differ from a homogeneous mixture? How are they similar?\n",
    "11. How does a homogeneous mixture differ from a pure substance? How are they similar?\n",
    "12. How does an element differ from a compound? How are they similar?\n",
    "13. How do molecules of elements and molecules of compounds differ? In what ways are they similar?\n",
    "14. How does an atom differ from a molecule? In what ways are they similar?\n",
    "15. Many of the items you purchase are mixtures of pure compounds. Select three of these commercial products and prepare a list of the ingredients that are pure compounds.\n",
    "16. Classify each of the following as an element, a compound, or a mixture:\n",
    "(a) copper\n",
    "(b) water\n",
    "(c) nitrogen\n",
    "(d) sulfur\n",
    "(e) air\n",
    "(f) sucrose\n",
    "(g) a substance composed of molecules each of which contains two iodine atoms\n",
    "(h) gasoline\n",
    "17. Classify each of the following as an element, a compound, or a mixture:\n",
    "(a) iron\n",
    "(b) oxygen\n",
    "(c) mercury oxide\n",
    "(d) pancake syrup\n",
    "(e) carbon dioxide\n",
    "(f) a substance composed of molecules each of which contains one hydrogen atom and one chlorine atom\n",
    "(g) baking soda\n",
    "(h) baking powder\n",
    "18. A sulfur atom and a sulfur molecule are not identical. What is the difference?\n",
    "\n",
    "19. How are the molecules in oxygen gas, the molecules in hydrogen gas, and water molecules similar? How do they differ?\n",
    "20. Why are astronauts in space said to be \"weightless,\" but not \"massless\"?\n",
    "21. Prepare a list of the principal chemicals consumed and produced during the operation of an automobile.\n",
    "22. Matter is everywhere around us. Make a list by name of fifteen different kinds of matter that you encounter every day. Your list should include (and label at least one example of each) the following: a solid, a liquid, a gas, an element, a compound, a homogenous mixture, a heterogeneous mixture, and a pure substance.\n",
    "23. When elemental iron corrodes it combines with oxygen in the air to ultimately form red brown iron(III) oxide called rust. (a) If a shiny iron nail with an initial mass of 23.2 g is weighed after being coated in a layer of rust, would you expect the mass to have increased, decreased, or remained the same? Explain. (b) If the mass of the iron nail increases to 24.1 g , what mass of oxygen combined with the iron?\n",
    "24. As stated in the text, convincing examples that demonstrate the law of conservation of matter outside of the laboratory are few and far between. Indicate whether the mass would increase, decrease, or stay the same for the following scenarios where chemical reactions take place:\n",
    "(a) Exactly one pound of bread dough is placed in a baking tin. The dough is cooked in an oven at $350^{\\circ} \\mathrm{F}$ releasing a wonderful aroma of freshly baked bread during the cooking process. Is the mass of the baked loaf less than, greater than, or the same as the one pound of original dough? Explain.\n",
    "(b) When magnesium burns in air a white flaky ash of magnesium oxide is produced. Is the mass of magnesium oxide less than, greater than, or the same as the original piece of magnesium? Explain.\n",
    "(c) Antoine Lavoisier, the French scientist credited with first stating the law of conservation of matter, heated a mixture of tin and air in a sealed flask to produce tin oxide. Did the mass of the sealed flask and contents decrease, increase, or remain the same after the heating?\n",
    "25. Yeast converts glucose to ethanol and carbon dioxide during anaerobic fermentation as depicted in the simple chemical equation here:\n",
    "glucose $\\longrightarrow$ ethanol + carbon dioxide\n",
    "(a) If 200.0 g of glucose is fully converted, what will be the total mass of ethanol and carbon dioxide produced?\n",
    "(b) If the fermentation is carried out in an open container, would you expect the mass of the container and contents after fermentation to be less than, greater than, or the same as the mass of the container and contents before fermentation? Explain.\n",
    "(c) If 97.7 g of carbon dioxide is produced, what mass of ethanol is produced?\n",
    "\n",
    "# 1.3 Physical and Chemical Properties \n",
    "\n",
    "26. Classify the six underlined properties in the following paragraph as chemical or physical:\n",
    "\n",
    "Fluorine is a pale yellow gas that reacts with most substances. The free element melts at $-220^{\\circ} \\mathrm{C}$ and boils at -188 ${ }^{\\circ} \\mathrm{C}$. Finely divided metals burn in fluorine with a bright flame. Nineteen grams of fluorine will react with 1.0 gram of hydrogen.\n",
    "27. Classify each of the following changes as physical or chemical:\n",
    "(a) condensation of steam\n",
    "(b) burning of gasoline\n",
    "(c) souring of milk\n",
    "(d) dissolving of sugar in water\n",
    "(e) melting of gold\n",
    "\n",
    "28. Classify each of the following changes as physical or chemical:\n",
    "(a) coal burning\n",
    "(b) ice melting\n",
    "(c) mixing chocolate syrup with milk\n",
    "(d) explosion of a firecracker\n",
    "(e) magnetizing of a screwdriver\n",
    "29. The volume of a sample of oxygen gas changed from 10 mL to 11 mL as the temperature changed. Is this a chemical or physical change?\n",
    "30. A 2.0 -liter volume of hydrogen gas combined with 1.0 liter of oxygen gas to produce 2.0 liters of water vapor. Does oxygen undergo a chemical or physical change?\n",
    "31. Explain the difference between extensive properties and intensive properties.\n",
    "32. Identify the following properties as either extensive or intensive.\n",
    "(a) volume\n",
    "(b) temperature\n",
    "(c) humidity\n",
    "(d) heat\n",
    "(e) boiling point\n",
    "33. The density (d) of a substance is an intensive property that is defined as the ratio of its mass (m) to its volume (V). density $=\\frac{\\text { mass }}{\\text { volume }} \\quad \\mathrm{d}=\\frac{\\mathrm{m}}{\\mathrm{V}}$\n",
    "\n",
    "Considering that mass and volume are both extensive properties, explain why their ratio, density, is intensive.\n",
    "\n",
    "# 1.4 Measurements \n",
    "\n",
    "34. Is one liter about an ounce, a pint, a quart, or a gallon?\n",
    "35. Is a meter about an inch, a foot, a yard, or a mile?\n",
    "36. Indicate the SI base units or derived units that are appropriate for the following measurements:\n",
    "(a) the length of a marathon race ( 26 miles 385 yards)\n",
    "(b) the mass of an automobile\n",
    "(c) the volume of a swimming pool\n",
    "(d) the speed of an airplane\n",
    "(e) the density of gold\n",
    "(f) the area of a football field\n",
    "(g) the maximum temperature at the South Pole on April 1, 1913\n",
    "37. Indicate the SI base units or derived units that are appropriate for the following measurements:\n",
    "(a) the mass of the moon\n",
    "(b) the distance from Dallas to Oklahoma City\n",
    "(c) the speed of sound\n",
    "(d) the density of air\n",
    "(e) the temperature at which alcohol boils\n",
    "(f) the area of the state of Delaware\n",
    "(g) the volume of a flu shot or a measles vaccination\n",
    "\n",
    "38. Give the name and symbol of the prefixes used with SI units to indicate multiplication by the following exact quantities.\n",
    "(a) $10^{3}$\n",
    "(b) $10^{-2}$\n",
    "(c) 0.1\n",
    "(d) $10^{-3}$\n",
    "(e) $1,000,000$\n",
    "(f) 0.000001\n",
    "39. Give the name of the prefix and the quantity indicated by the following symbols that are used with SI base units.\n",
    "(a) c\n",
    "(b) d\n",
    "(c) G\n",
    "(d) k\n",
    "(e) m\n",
    "(f) n\n",
    "(g) p\n",
    "(h) T\n",
    "40. A large piece of jewelry has a mass of 132.6 g . A graduated cylinder initially contains 48.6 mL water. When the jewelry is submerged in the graduated cylinder, the total volume increases to 61.2 mL .\n",
    "(a) Determine the density of this piece of jewelry.\n",
    "(b) Assuming that the jewelry is made from only one substance, what substance is it likely to be? Explain.\n",
    "41. Visit this PhET density simulation (http://openstaxcollege.org/I/16phetmasvolden) and select the Same Volume Blocks.\n",
    "(a) What are the mass, volume, and density of the yellow block?\n",
    "(b) What are the mass, volume and density of the red block?\n",
    "(c) List the block colors in order from smallest to largest mass.\n",
    "(d) List the block colors in order from lowest to highest density.\n",
    "(e) How are mass and density related for blocks of the same volume?\n",
    "42. Visit this PhET density simulation (http://openstaxcollege.org/I/16phetmasvolden) and select Custom Blocks and then My Block.\n",
    "(a) Enter mass and volume values for the block such that the mass in kg is less than the volume in L. What does the block do? Why? Is this always the case when mass < volume?\n",
    "(b) Enter mass and volume values for the block such that the mass in kg is more than the volume in L. What does the block do? Why? Is this always the case when mass > volume?\n",
    "(c) How would (a) and (b) be different if the liquid in the tank were ethanol instead of water?\n",
    "(d) How would (a) and (b) be different if the liquid in the tank were mercury instead of water?\n",
    "\n",
    "43. Visit this PhET density simulation (http://openstaxcollege.org/I/16phetmasvolden) and select Mystery Blocks.\n",
    "(a) Pick one of the Mystery Blocks and determine its mass, volume, density, and its likely identity.\n",
    "(b) Pick a different Mystery Block and determine its mass, volume, density, and its likely identity.\n",
    "(c) Order the Mystery Blocks from least dense to most dense. Explain.\n",
    "\n",
    "# 1.5 Measurement Uncertainty, Accuracy, and Precision \n",
    "\n",
    "44. Express each of the following numbers in scientific notation with correct significant figures:\n",
    "(a) 711.0\n",
    "(b) 0.239\n",
    "(c) 90743\n",
    "(d) 134.2\n",
    "(e) 0.05499\n",
    "(f) 10000.0\n",
    "(g) 0.000000738592\n",
    "45. Express each of the following numbers in exponential notation with correct significant figures:\n",
    "(a) 704\n",
    "(b) 0.03344\n",
    "(c) 547.9\n",
    "(d) 22086\n",
    "(e) 1000.00\n",
    "(f) 0.0000000651\n",
    "(g) 0.007157\n",
    "46. Indicate whether each of the following can be determined exactly or must be measured with some degree of uncertainty:\n",
    "(a) the number of eggs in a basket\n",
    "(b) the mass of a dozen eggs\n",
    "(c) the number of gallons of gasoline necessary to fill an automobile gas tank\n",
    "(d) the number of cm in 2 m\n",
    "(e) the mass of a textbook\n",
    "(f) the time required to drive from San Francisco to Kansas City at an average speed of $53 \\mathrm{mi} / \\mathrm{h}$\n",
    "47. Indicate whether each of the following can be determined exactly or must be measured with some degree of uncertainty:\n",
    "(a) the number of seconds in an hour\n",
    "(b) the number of pages in this book\n",
    "(c) the number of grams in your weight\n",
    "(d) the number of grams in 3 kilograms\n",
    "(e) the volume of water you drink in one day\n",
    "(f) the distance from San Francisco to Kansas City\n",
    "\n",
    "48. How many significant figures are contained in each of the following measurements?\n",
    "(a) 38.7 g\n",
    "(b) $2 \\times 10^{18} \\mathrm{~m}$\n",
    "(c) $3,486,002 \\mathrm{~kg}$\n",
    "(d) $9.74150 \\times 10^{-4} \\mathrm{~J}$\n",
    "(e) $0.0613 \\mathrm{~cm}^{3}$\n",
    "(f) 17.0 kg\n",
    "(g) $0.01400 \\mathrm{~g} / \\mathrm{mL}$\n",
    "49. How many significant figures are contained in each of the following measurements?\n",
    "(a) 53 cm\n",
    "(b) $2.05 \\times 10^{8} \\mathrm{~m}$\n",
    "(c) $86,002 \\mathrm{~J}$\n",
    "(d) $9.740 \\times 10^{4} \\mathrm{~m} / \\mathrm{s}$\n",
    "(e) $10.0613 \\mathrm{~m}^{3}$\n",
    "(f) $0.17 \\mathrm{~g} / \\mathrm{mL}$\n",
    "(g) 0.88400 s\n",
    "50. The following quantities were reported on the labels of commercial products. Determine the number of significant figures in each.\n",
    "(a) 0.0055 g active ingredients\n",
    "(b) 12 tablets\n",
    "(c) $3 \\%$ hydrogen peroxide\n",
    "(d) 5.5 ounces\n",
    "(e) 473 mL\n",
    "(f) $1.75 \\%$ bismuth\n",
    "(g) $0.001 \\%$ phosphoric acid\n",
    "(h) $99.80 \\%$ inert ingredients\n",
    "51. Round off each of the following numbers to two significant figures:\n",
    "(a) 0.436\n",
    "(b) 9.000\n",
    "(c) 27.2\n",
    "(d) 135\n",
    "(e) $1.497 \\times 10^{-3}$\n",
    "(f) 0.445\n",
    "\n",
    "52. Round off each of the following numbers to two significant figures:\n",
    "(a) 517\n",
    "(b) 86.3\n",
    "(c) $6.382 \\times 10^{3}$\n",
    "(d) 5.0008\n",
    "(e) 22.497\n",
    "(f) 0.885\n",
    "53. Perform the following calculations and report each answer with the correct number of significant figures.\n",
    "(a) $628 \\times 342$\n",
    "(b) $\\left(5.63 \\times 10^{2}\\right) \\times\\left(7.4 \\times 10^{3}\\right)$\n",
    "(c) $\\frac{28.0}{13.483}$\n",
    "(d) $8119 \\times 0.000023$\n",
    "(e) $14.98+27,340+84.7593$\n",
    "(f) $42.7+0.259$\n",
    "54. Perform the following calculations and report each answer with the correct number of significant figures.\n",
    "(a) $62.8 \\times 34$\n",
    "(b) $0.147+0.0066+0.012$\n",
    "(c) $38 \\times 95 \\times 1.792$\n",
    "(d) $15-0.15-0.6155$\n",
    "(e) $8.78 \\times\\left(\\frac{0.0500}{0.478}\\right)$\n",
    "(f) $140+7.68+0.014$\n",
    "(g) $28.7-0.0483$\n",
    "(h) $\\frac{(88.5-87.57)}{45.13}$\n",
    "\n",
    "55. Consider the results of the archery contest shown in this figure.\n",
    "(a) Which archer is most precise?\n",
    "(b) Which archer is most accurate?\n",
    "(c) Who is both least precise and least accurate?\n",
    "![Image](Chapter_1_images/img-37.jpeg)\n",
    "56. Classify the following sets of measurements as accurate, precise, both, or neither.\n",
    "(a) Checking for consistency in the weight of chocolate chip cookies: $17.27 \\mathrm{~g}, 13.05 \\mathrm{~g}, 19.46 \\mathrm{~g}, 16.92 \\mathrm{~g}$\n",
    "(b) Testing the volume of a batch of $25-\\mathrm{mL}$ pipettes: $27.02 \\mathrm{~mL}, 26.99 \\mathrm{~mL}, 26.97 \\mathrm{~mL}, 27.01 \\mathrm{~mL}$\n",
    "(c) Determining the purity of gold: $99.9999 \\%, 99.9998 \\%, 99.9998 \\%, 99.9999 \\%$\n",
    "\n",
    "# 1.6 Mathematical Treatment of Measurement Results \n",
    "\n",
    "57. Write conversion factors (as ratios) for the number of:\n",
    "(a) yards in 1 meter\n",
    "(b) liters in 1 liquid quart\n",
    "(c) pounds in 1 kilogram\n",
    "58. Write conversion factors (as ratios) for the number of:\n",
    "(a) kilometers in 1 mile\n",
    "(b) liters in 1 cubic foot\n",
    "(c) grams in 1 ounce\n",
    "59. The label on a soft drink bottle gives the volume in two units: 2.0 L and 67.6 fl oz. Use this information to derive a conversion factor between the English and metric units. How many significant figures can you justify in your conversion factor?\n",
    "60. The label on a box of cereal gives the mass of cereal in two units: 978 grams and 34.5 oz. Use this information to find a conversion factor between the English and metric units. How many significant figures can you justify in your conversion factor?\n",
    "61. Soccer is played with a round ball having a circumference between 27 and 28 in. and a weight between 14 and 16 oz. What are these specifications in units of centimeters and grams?\n",
    "62. A woman's basketball has a circumference between 28.5 and 29.0 inches and a maximum weight of 20 ounces (two significant figures). What are these specifications in units of centimeters and grams?\n",
    "63. How many milliliters of a soft drink are contained in a 12.0 -oz can?\n",
    "64. A barrel of oil is exactly 42 gal . How many liters of oil are in a barrel?\n",
    "65. The diameter of a red blood cell is about $3 \\times 10^{-4} \\mathrm{in}$. What is its diameter in centimeters?\n",
    "\n",
    "66. The distance between the centers of the two oxygen atoms in an oxygen molecule is $1.21 \\times 10^{-8} \\mathrm{~cm}$. What is this distance in inches?\n",
    "67. Is a 197-lb weight lifter light enough to compete in a class limited to those weighing 90 kg or less?\n",
    "68. A very good 197-lb weight lifter lifted 192 kg in a move called the clean and jerk. What was the mass of the weight lifted in pounds?\n",
    "69. Many medical laboratory tests are run using $5.0 \\mu \\mathrm{~L}$ blood serum. What is this volume in milliliters?\n",
    "70. If an aspirin tablet contains 325 mg aspirin, how many grams of aspirin does it contain?\n",
    "71. Use scientific (exponential) notation to express the following quantities in terms of the SI base units in Table 1.3:\n",
    "(a) 0.13 g\n",
    "(b) 232 Gg\n",
    "(c) 5.23 pm\n",
    "(d) 86.3 mg\n",
    "(e) 37.6 cm\n",
    "(f) $54 \\mu \\mathrm{~m}$\n",
    "(g) 1 Ts\n",
    "(h) 27 ps\n",
    "(i) 0.15 mK\n",
    "72. Complete the following conversions between SI units.\n",
    "(a) $612 \\mathrm{~g}=$ $\\qquad$ mg\n",
    "(b) $8.160 \\mathrm{~m}=$ $\\qquad$ cm\n",
    "(c) $3779 \\mu \\mathrm{~g}=$ $\\qquad$ g\n",
    "(d) $781 \\mathrm{~mL}=$ $\\qquad$ L\n",
    "(e) $4.18 \\mathrm{~kg}=$ $\\qquad$ g\n",
    "(f) $27.8 \\mathrm{~m}=$ $\\qquad$ km\n",
    "(g) $0.13 \\mathrm{~mL}=$ $\\qquad$ L\n",
    "(h) $1738 \\mathrm{~km}=$ $\\qquad$ m\n",
    "(i) $1.9 \\mathrm{Gg}=$ $\\qquad$ g\n",
    "73. Gasoline is sold by the liter in many countries. How many liters are required to fill a 12.0-gal gas tank?\n",
    "74. Milk is sold by the liter in many countries. What is the volume of exactly $1 / 2$ gal of milk in liters?\n",
    "75. A long ton is defined as exactly 2240 lb . What is this mass in kilograms?\n",
    "76. Make the conversion indicated in each of the following:\n",
    "(a) the men's world record long jump, $29 \\mathrm{ft} 4 \\frac{1}{4}$ in., to meters\n",
    "(b) the greatest depth of the ocean, about 6.5 mi , to kilometers\n",
    "(c) the area of the state of Oregon, $96,981 \\mathrm{mi}^{2}$, to square kilometers\n",
    "(d) the volume of 1 gill (exactly 4 oz ) to milliliters\n",
    "(e) the estimated volume of the oceans, $330,000,000 \\mathrm{mi}^{3}$, to cubic kilometers.\n",
    "(f) the mass of a 3525-lb car to kilograms\n",
    "(g) the mass of a 2.3-oz egg to grams\n",
    "\n",
    "77. Make the conversion indicated in each of the following:\n",
    "(a) the length of a soccer field, 120 m (three significant figures), to feet\n",
    "(b) the height of Mt. Kilimanjaro, at 19,565 ft, the highest mountain in Africa, to kilometers\n",
    "(c) the area of an $8.5-\\times 11$-inch sheet of paper in $\\mathrm{cm}^{2}$\n",
    "(d) the displacement volume of an automobile engine, $161 \\mathrm{in} .^{3}$, to liters\n",
    "(e) the estimated mass of the atmosphere, $5.6 \\times 10^{15}$ tons, to kilograms\n",
    "(f) the mass of a bushel of rye, 32.0 lb , to kilograms\n",
    "(g) the mass of a 5.00-grain aspirin tablet to milligrams ( 1 grain $=0.00229$ oz)\n",
    "78. Many chemistry conferences have held a 50-Trillion Angstrom Run (two significant figures). How long is this run in kilometers and in miles? $\\left(1 \\AA=1 \\times 10^{-10} \\mathrm{~m}\\right)$\n",
    "79. A chemist's 50-Trillion Angstrom Run (see Exercise 1.78) would be an archeologist's 10,900 cubit run. How long is one cubit in meters and in feet? $\\left(1 \\AA=1 \\times 10^{-8} \\mathrm{~cm}\\right)$\n",
    "80. The gas tank of a certain luxury automobile holds 22.3 gallons according to the owner's manual. If the density of gasoline is $0.8206 \\mathrm{~g} / \\mathrm{mL}$, determine the mass in kilograms and pounds of the fuel in a full tank.\n",
    "81. As an instructor is preparing for an experiment, he requires 225 g phosphoric acid. The only container readily available is a $150-\\mathrm{mL}$ Erlenmeyer flask. Is it large enough to contain the acid, whose density is $1.83 \\mathrm{~g} / \\mathrm{mL}$ ?\n",
    "82. To prepare for a laboratory period, a student lab assistant needs 125 g of a compound. A bottle containing 1/4 lb is available. Did the student have enough of the compound?\n",
    "83. A chemistry student is 159 cm tall and weighs 45.8 kg . What is her height in inches and weight in pounds?\n",
    "84. In a recent Grand Prix, the winner completed the race with an average speed of $229.8 \\mathrm{~km} / \\mathrm{h}$. What was his speed in miles per hour, meters per second, and feet per second?\n",
    "85. Solve these problems about lumber dimensions.\n",
    "(a) To describe to a European how houses are constructed in the US, the dimensions of \"two-by-four\" lumber must be converted into metric units. The thickness $\\times$ width $\\times$ length dimensions are $1.50 \\mathrm{in} . \\times 3.50 \\mathrm{in} . \\times 8.00 \\mathrm{ft}$ in the US. What are the dimensions in $\\mathrm{cm} \\times \\mathrm{cm} \\times \\mathrm{m}$ ?\n",
    "(b) This lumber can be used as vertical studs, which are typically placed 16.0 in. apart. What is that distance in centimeters?\n",
    "86. The mercury content of a stream was believed to be above the minimum considered safe-1 part per billion (ppb) by weight. An analysis indicated that the concentration was 0.68 parts per billion. What quantity of mercury in grams was present in 15.0 L of the water, the density of which is $0.998 \\mathrm{~g} / \\mathrm{ml}$ ? ( $1 \\mathrm{ppb} \\mathrm{Hg}=\\frac{1 \\mathrm{ng} \\mathrm{Hg}}{1 \\mathrm{~g} \\text { water }}$ )\n",
    "87. Calculate the density of aluminum if $27.6 \\mathrm{~cm}^{3}$ has a mass of 74.6 g .\n",
    "88. Osmium is one of the densest elements known. What is its density if 2.72 g has a volume of $0.121 \\mathrm{~cm}^{3}$ ?\n",
    "89. Calculate these masses.\n",
    "(a) What is the mass of $6.00 \\mathrm{~cm}^{3}$ of mercury, density $=13.5939 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "(b) What is the mass of 25.0 mL octane, density $=0.702 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "90. Calculate these masses.\n",
    "(a) What is the mass of $4.00 \\mathrm{~cm}^{3}$ of sodium, density $=0.97 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "(b) What is the mass of 125 mL gaseous chlorine, density $=3.16 \\mathrm{~g} / \\mathrm{L}$ ?\n",
    "91. Calculate these volumes.\n",
    "(a) What is the volume of 25 g iodine, density $=4.93 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "(b) What is the volume of 3.28 g gaseous hydrogen, density $=0.089 \\mathrm{~g} / \\mathrm{L}$ ?\n",
    "\n",
    "92. Calculate these volumes.\n",
    "(a) What is the volume of 11.3 g graphite, density $=2.25 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "(b) What is the volume of 39.657 g bromine, density $=2.928 \\mathrm{~g} / \\mathrm{cm}^{3}$ ?\n",
    "93. Convert the boiling temperature of gold, $2966^{\\circ} \\mathrm{C}$, into degrees Fahrenheit and kelvin.\n",
    "94. Convert the temperature of scalding water, $54^{\\circ} \\mathrm{C}$, into degrees Fahrenheit and kelvin.\n",
    "95. Convert the temperature of the coldest area in a freezer, $-10^{\\circ} \\mathrm{F}$, to degrees Celsius and kelvin.\n",
    "96. Convert the temperature of dry ice, $-77^{\\circ} \\mathrm{C}$, into degrees Fahrenheit and kelvin.\n",
    "97. Convert the boiling temperature of liquid ammonia, $-28.1^{\\circ} \\mathrm{F}$, into degrees Celsius and kelvin.\n",
    "98. The label on a pressurized can of spray disinfectant warns against heating the can above $130^{\\circ} \\mathrm{F}$. What are the corresponding temperatures on the Celsius and kelvin temperature scales?\n",
    "99. The weather in Europe was unusually warm during the summer of 1995. The TV news reported temperatures as high as $45^{\\circ} \\mathrm{C}$. What was the temperature on the Fahrenheit scale?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5e195-9dab-4603-b143-57eb0ecf8e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
